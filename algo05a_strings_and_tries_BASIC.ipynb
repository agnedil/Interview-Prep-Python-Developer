{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest Common Prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Word Matching\n",
    "One by one calculate the LCP of each of the given string with the current LCP so far. The final result - longest common prefix of all the strings  \n",
    "Time c. O(MN) where N = # chars in strings & M = length of largest string  \n",
    "Space c. O(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCP =  eur\n"
     ]
    }
   ],
   "source": [
    "# common prefix for 2 strings\n",
    "def common_prefix(str1, str2): \n",
    "  \n",
    "    _res = '' \n",
    "    n1, n2 = len(str1), len(str2)\n",
    "      \n",
    "    # Compare str1 and str2 \n",
    "    i = j = 0\n",
    "    while i <= n1 - 1 and j <= n2 - 1: \n",
    "      \n",
    "        if (str1[i] != str2[j]):\n",
    "            break\n",
    "              \n",
    "        _res += str1[i] \n",
    "        i += 1\n",
    "        j += 1\n",
    "  \n",
    "    return _res \n",
    "  \n",
    "# find longest LCP \n",
    "def LCP(arr): \n",
    "  \n",
    "    prefix = arr[0]  \n",
    "    for i in range (1, len(arr)): \n",
    "        prefix = common_prefix(prefix, arr[i]) \n",
    "  \n",
    "    return prefix \n",
    "  \n",
    "\n",
    "arr = ['eurasia', 'euroasian', 'euran', 'europe'] \n",
    "res = LCP(arr) \n",
    "\n",
    "if ans: \n",
    "    print('LCP = ', res)\n",
    "else: \n",
    "    print('No LCP') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Character matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCP =  eur\n"
     ]
    }
   ],
   "source": [
    "def LCP(arr):      \n",
    "    \n",
    "    minlen = len(arr[0])                                       # find length of shortest string\n",
    "    for i in range(1, len(arr)): \n",
    "        if len(arr[i]) < minlen: \n",
    "            minlen = len(arr[i])\n",
    "            \n",
    "    res = '' \n",
    "    for i in range(minlen):                                    # current char must be same in all strings      \n",
    "        \n",
    "        current = arr[0][i] \n",
    "   \n",
    "        for j in range(1, len(arr)): \n",
    "            if arr[j][i] != current: \n",
    "                return res\n",
    "           \n",
    "        res = res + current\n",
    "\n",
    "\n",
    "arr = ['eurasia', 'euroasian', 'euran', 'europe'] \n",
    "res = LCP(arr) \n",
    "\n",
    "if res: \n",
    "    print('LCP = ', res)\n",
    "else: \n",
    "    print('No LCP') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse string\n",
    "Think of the base case - string length <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse(s):    \n",
    "    \n",
    "    if len(s) <= 1:                       # base case\n",
    "        return s\n",
    "    \n",
    "    return reverse(s[1:]) + s[0]          # recursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlrow olleh\n",
      "987654321\n"
     ]
    }
   ],
   "source": [
    "print(reverse('hello world'))\n",
    "print(reverse('123456789'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all permutations of string\n",
    "If s='abc' => ['abc', 'acb', 'bac', 'bca', 'cab', 'cba']  \n",
    "(If char is repeated - each occurence is distinct; if s='xxx' => list of 6 \"versions\" of 'xxx'\n",
    "\n",
    "* For each char, __set it aside__ and get a list of __all permutations for the remainig string__;\n",
    "* __Add the char set aside__ to each element of that list, and __append the result to final list__. E.g. set aside 'a' in 'abc', get all permitation of 'bc' = ['bc', 'cb'], then add 'a' to each of them = 'abc' and 'acb', add these to final list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute(s):\n",
    "    \n",
    "    out = []\n",
    "    if len(s) == 1:                                         # base case\n",
    "        out = [s]\n",
    "        \n",
    "    else:        \n",
    "        for i, char in enumerate(s):                         # for each char in string            \n",
    "            for perm in permute(s[:i] + s[i+1:]):           # permite string w/out this char                \n",
    "                out += [char + perm]                         # add removed char and append to output\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc', 'acb', 'bac', 'bca', 'cab', 'cba']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permute('abc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse a string without affecting special characters\n",
    "Given string with special chars and letters (a-zA-Z), reverse it without affecting special chars. Example: \"a,b!c\" => \"c,b!a\"  \n",
    "Copying letters to a separate array, revirsing it, then iterating over input and inserting when there is a letter - time c. = O(n) + space c.  \n",
    "A better solution:  \n",
    "* l = 0, r = n-1;\n",
    "* While l < r:  \n",
    "    a) If not str[l].isalpha(): l++  \n",
    "    b) If not str[r].isalpha(): r--  \n",
    "    c) Swap str[l] and str[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input string:  a!!!b.c.d,e'f,ghi\n",
      "Output string:  i!!!h.g.f,e'd,cba\n"
     ]
    }
   ],
   "source": [
    "# time c. O(n), space c. O(1)\n",
    "def reverse_string(text):\n",
    "        \n",
    "    # initiate left and right indices\n",
    "    left = 0\n",
    "    right = len(text) - 1\n",
    "    \n",
    "    while left < right:\n",
    "                \n",
    "        # find actual letters, skip special chars\n",
    "        while not text[left].isalpha():\n",
    "            left += 1\n",
    "        while not text[right].isalpha():\n",
    "            right -= 1\n",
    "            \n",
    "        # swap once found, change left and right indices    \n",
    "        text[left], text[right] = text[right], text[left]\n",
    "        left += 1\n",
    "        right -= 1\n",
    "                \n",
    "    return ''.join(text)\n",
    "   \n",
    "      \n",
    "input_string = \"a!!!b.c.d,e'f,ghi\"\n",
    "print (\" Input string: \", input_string) \n",
    "print (\"Output string: \", reverse_string(list(input_string))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if anagrams\n",
    "Anagrams share exact same characters (rearranged and ignoring spaces / capitalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not optimal\n",
    "def anagram_check(s1, s2):\n",
    "    \n",
    "    # remove spaces and make lowercase\n",
    "    s1 = s1.replace(' ','').lower()\n",
    "    s2 = s2.replace(' ','').lower()\n",
    "        \n",
    "    return sorted(s1) == sorted(s2)\n",
    "\n",
    "\n",
    "# O(N)\n",
    "def anagram_check2(s1, s2):\n",
    "    \n",
    "    # remove spaces and lowercase letters\n",
    "    s1 = s1.replace(' ','').lower()\n",
    "    s2 = s2.replace(' ','').lower()\n",
    "    \n",
    "    # edge case\n",
    "    if len(s1) != len(s2):\n",
    "        return False\n",
    "    \n",
    "    # counting dict (or defaultdict())\n",
    "    count = {}    \n",
    "    \n",
    "        \n",
    "    # iterate over first string (ADD counts)\n",
    "    for letter in s1:\n",
    "        if letter in count:\n",
    "            count[letter] += 1\n",
    "        else:\n",
    "            count[letter] = 1\n",
    "            \n",
    "    # iterate over second string (SUBSTRACT counts)\n",
    "    for letter in s2:\n",
    "        if letter in count:\n",
    "            count[letter] -= 1\n",
    "        else:\n",
    "            count[letter] = 1\n",
    "    \n",
    "    # check if all are 0\n",
    "    for k in count:\n",
    "        if count[k] != 0:\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sort-based aproach:\n",
      "\tTrue for \"public relations AND crap built on lies\"\n",
      "\tTrue for \"dog AND god\"\n",
      "\tTrue for \"clint eastwood AND old west action\"\n",
      "\tFalse for \"dd AND aa\"\n",
      "\n",
      "Using counting aproach:\n",
      "\tTrue for \"public relations AND crap built on lies\"\n",
      "\tTrue for \"dog AND god\"\n",
      "\tTrue for \"clint eastwood AND old west action\"\n",
      "\tFalse for \"dd AND aa\"\n"
     ]
    }
   ],
   "source": [
    "anagrams = [('public relations', 'crap built on lies'), ('dog','god'), ('clint eastwood','old west action'), ('dd','aa')]\n",
    "\n",
    "print('Using sort-based aproach:')\n",
    "for a in anagrams:\n",
    "    print('\\t{} for \"{}\"'.format(anagram_check(*a), ' AND '.join(a)))\n",
    "    \n",
    "print('\\nUsing counting aproach:')\n",
    "for a in anagrams:\n",
    "    print('\\t{} for \"{}\"'.format(anagram_check2(*a), ' AND '.join(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Reversal\n",
    "Print sentence with the word order reversed\n",
    "\n",
    "__Correct solution__: loop over text, extract words, push them to __\"stack\"__, pop them in reverse order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easiest\n",
    "def reverse_sent1(s):\n",
    "    return \" \".join(reversed(s.split()))\n",
    "\n",
    "def reverse_sent2(s):\n",
    "    return \" \".join(s.split()[::-1])\n",
    "\n",
    "# Correct (manual split)\n",
    "def reverse_sent3(s):\n",
    "        \n",
    "    words, spaces = [], [' ']    \n",
    "    \n",
    "    i = 0                                                     # index        \n",
    "    while i < len(s):\n",
    "        \n",
    "        if s[i] not in spaces:                                # if not a space            \n",
    "            start = i                                         # word start            \n",
    "            while i < len(s) and s[i] not in spaces:                \n",
    "                i += 1                                        # word end            \n",
    "            words.append(s[start:i])                          # append word to list        \n",
    "        i += 1                                                # increase index\n",
    "      \n",
    "    return ' '.join(words[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are how John Hello\n",
      "you are how John Hello\n",
      "you are how John Hello\n"
     ]
    }
   ],
   "source": [
    "print(reverse_sent1('   Hello John    how are you   '))\n",
    "print(reverse_sent2('   Hello John    how are you   '))\n",
    "print(reverse_sent3('   Hello John    how are you   '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am who I am and I like pizza\n",
      "pizza like I and am I who am I\n"
     ]
    }
   ],
   "source": [
    "# easiest expanded\n",
    "def reverse_words(string):\n",
    "        \n",
    "    sent = string.strip().split()                                                 # set = list of words\n",
    "    \n",
    "    left = 0\n",
    "    right = len(sent) - 1    \n",
    "    while left < right:\n",
    "        sent[left], sent[right] = sent[right], sent[left]\n",
    "        left += 1\n",
    "        right -= 1    \n",
    "\n",
    "    return ' '.join(sent)\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "string = 'I am who I am and I like pizza'\n",
    "print(string + '\\n' + reverse_words(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String compression\n",
    "Compress 'AAAABBBBCCCCCDDEEEE' into 'A4B4C5D2E4'\n",
    "*  Work off of a list of characters, convert it back to string\n",
    "* Time and space complexity of O(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(s):\n",
    "    \"\"\"\n",
    "    Compresses without checking - RunLength Compression algo\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(s) == 0:   return ''                # edge cases        \n",
    "    elif len(s) == 1: return s + '1'    \n",
    "    \n",
    "    res = ''                                   # run / res is empty\n",
    "    last, count = s[0], 1                      # intialize\n",
    "        \n",
    "    i = 1    \n",
    "    while i < len(s):        \n",
    "        \n",
    "        if s[i] == s[i - 1]:                   # check if same letter            \n",
    "            count += 1\n",
    "        else:            \n",
    "            res = res + s[i - 1] + str(count)  # if not, store previous data\n",
    "            count = 1        \n",
    "        i += 1                                 # to terminate while loop    \n",
    "    \n",
    "    res = res + s[i - 1] + str(count)          # put everything back into run - WHY THIS LINE?\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2B2C3 AABBCCC\n",
      "A5B4C5 AAAAABBBBCCCCC\n",
      "A4B3C7D7 AAAABBBCCCCCCCDDDDDDD\n",
      " \n"
     ]
    }
   ],
   "source": [
    "examples = ['AABBCCC', 'AAAAABBBBCCCCC', 'AAAABBBCCCCCCCDDDDDDD', '']\n",
    "\n",
    "for example in examples:\n",
    "    print(compress(example), example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knuth-Morris-Pratt Algorithm\n",
    "Find a pattern within a piece of text; time c. = O(n + m)\n",
    "\n",
    "Principle: whenever we detect a mismatch in position i of pattern, we already know some of the characters in the text of the next window. We take advantage of this information to avoid matching the characters that we know will anyway match (by shifting to the left only by pi[i].\n",
    "\n",
    "In other words, if a match which had begun at text[m] fails while comparing text[m + i] to pattern[i], then the next possible match must begin at text[m + (i - T[i])] - at a higher index than m, so that pi[i] < i, and this way we skip the portion of the pattern that will match anyway\n",
    "\n",
    "__Precomputing a table of prefixes__:\n",
    "\n",
    "* KMP algorithm preprocesses pattern and constructs an auxiliary pi[] of size m (len(pattern)) which is used to skip characters while matching.\n",
    "* __pi__ is an array of __longest proper prefixes which are also suffixes__ (lpps). Proper prefix - any prefix, but the whole string. For string “ABC”, prefixes = “”, “A”, “AB” and “ABC”, BUT proper prefixes = “”, “A” and “AB”. Suffixes = “”, “C”, “BC” and “ABC”.\n",
    "* We search for lpps in sub-patterns. More clearly we focus on sub-strings of patterns that are either prefix and suffix.\n",
    "* For each sub-pattern pattern[0..i] where i = [0, m-1], __pi[i] stores length of the maximum matching proper prefix which is also a suffix of the sub-pattern pat[0..i]__.\n",
    "\n",
    "Note: pi[i] could also be defined as longest prefix which is also proper suffix. We need to use \"proper\" at one place to make sure that the whole substring is not considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]\n",
      "[]\n",
      "[10]\n",
      "[4]\n",
      "[15]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 0]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return all positions of a substring in a larger string\n",
    "def kmp( pattern='', text='' ):\n",
    "        \n",
    "    n = len(text)\n",
    "    m = len(pattern)\n",
    "    matches = []\n",
    "    pi = get_prefixes(pattern)                                  # table of precomputed prefixes\n",
    "    j = 0                                                       # index for pattern\n",
    "    for i in range(n):                                          # index for text\n",
    "        while j > 0 and pattern[j] != text[i]:\n",
    "            j = pi[j - 1]\n",
    "        if pattern[j] == text[i]:\n",
    "            j = j + 1\n",
    "        if j == m:\n",
    "            matches.append(i - m + 1)\n",
    "            j = pi[j-1]\n",
    "\n",
    "    return matches\n",
    "\n",
    "\n",
    "def get_prefixes(pattern_):\n",
    "        \n",
    "    m = len(pattern_)\n",
    "    pi = [0] * m\n",
    "        \n",
    "    LPP = 0                                                      # longest proper prefix which is also a suffix\n",
    "    for j in range(1, m):\n",
    "        while LPP > 0 and pattern_[LPP] != pattern_[j]:\n",
    "            LPP = pi[LPP - 1]\n",
    "                        \n",
    "        if pattern_[LPP] == pattern_[j]:\n",
    "            LPP = LPP + 1\n",
    "                        \n",
    "        pi[j] = LPP\n",
    "                \n",
    "    return pi\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "# Test 1)\n",
    "pattern = \"abc1abc12\"\n",
    "text1 = \"alskfjaldsabc1abc1abc12k23adsfabcabc\"\n",
    "text2 = \"alskfjaldsk23adsfabcabc\"\n",
    "print(kmp(pattern, text1))\n",
    "print(kmp(pattern, text2))\n",
    "\n",
    "# Test 2)\n",
    "pattern = \"ABABX\"\n",
    "text = \"ABABZABABYABABX\"\n",
    "print(kmp(pattern, text))\n",
    "\n",
    "# Test 3)\n",
    "pattern = \"AAAB\"\n",
    "text = \"ABAAAAAB\"\n",
    "print(kmp(pattern, text))\n",
    "\n",
    "# Test 4)\n",
    "pattern = \"abcdabcy\"\n",
    "text = \"abcxabcdabxabcdabcdabcy\"\n",
    "print(kmp(pattern, text))\n",
    "\n",
    "# Test 5)\n",
    "pattern = \"aaab\"\n",
    "get_prefixes(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest common subsequence (DP)\n",
    "Subsequence - not necessarily contiguous. Example: 'abghed' & 'bhaxyz' have lcs 'abh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 'abcf')\n",
      "(4, 'GTAB')\n"
     ]
    }
   ],
   "source": [
    "def lcs(s1, s2):\n",
    "        \n",
    "    matrix = [ ['' for x in range(len(s2))] for x in range(len(s1)) ]\n",
    "    for i in range(len(s1)):\n",
    "        for j in range(len(s2)):\n",
    "            if s1[i] == s2[j]:\n",
    "                if i == 0 or j == 0:\n",
    "                    matrix[i][j] = s1[i]\n",
    "                else:\n",
    "                    matrix[i][j] = matrix[i-1][j-1] + s1[i]\n",
    "            else:\n",
    "                matrix[i][j] = max(matrix[i-1][j], matrix[i][j-1], key=len)\n",
    "\n",
    "    cs = matrix[-1][-1]\n",
    "\n",
    "    return len(cs), cs\n",
    "\n",
    "print(lcs(\"abcdaf\", \"acbcf\"))\n",
    "\n",
    "X = \"AGGTAB\"\n",
    "Y = \"GXTXAYB\"\n",
    "print(lcs(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest common substring (DP)\n",
    "Time c. O(nm), space c. O(nm) (space can be converted to O(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I went there'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def longest_common_substring(s1, s2):\n",
    "        \n",
    "    m = [[0] * (len(s2) + 1) for i in range(len(s1) + 1)]\n",
    "    length, idx_longest = 0, 0\n",
    "        \n",
    "    for i in range(1, 1 + len(s1)):\n",
    "        for j in range(1, 1 + len(s2)):\n",
    "                        \n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                m[i][j] = m[i - 1][j - 1] + 1\n",
    "                if m[i][j] > length:\n",
    "                    length = m[i][j]\n",
    "                    idx_longest = i\n",
    "            else:\n",
    "                m[i][j] = 0\n",
    "                                \n",
    "    return s1[ idx_longest - length: idx_longest ]\n",
    "\n",
    "\n",
    "s1 = 'I went there'\n",
    "s2 = 'No matter what I went there and found it'\n",
    "longest_common_substring(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest common substring in array of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I went'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIND LONGEST COMMON SUBSTRING\n",
    "def find_stem(arr): \n",
    "  \n",
    "    reference, res = arr[0], ' ' \n",
    "  \n",
    "    for i in range(len(reference)):                              # generate all possible substrings in reference string\n",
    "        for j in range( i + 1, len(reference) + 1):\n",
    "            \n",
    "            stem = reference[i:j] \n",
    "            k = 1\n",
    "            for k in range(1, len(arr)):  \n",
    "                 \n",
    "                if stem not in arr[k]:                           # Check if the generated stem is common to all words\n",
    "                    break              \n",
    "            \n",
    "            if (k + 1 == len(arr) and len(res) < len(stem)):     # If current substr is in all strings and greater than current \n",
    "                res = stem \n",
    "  \n",
    "    return res\n",
    "\n",
    "# incomplete solution - the last elements in arr is not taken into account\n",
    "s1 = 'I went there'\n",
    "s2 = 'No matter what I went there and found it'\n",
    "s3 = \"That's where I went\"\n",
    "s4 = 'I we'\n",
    "find_stem([s1, s2, s3, s4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique characters in string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-in data structure & built in function\n",
    "def uni_char(s):\n",
    "    return len(set(s)) == len(s)\n",
    "\n",
    "#  built-in data structure & look-up method\n",
    "def uni_char2(s):\n",
    "    chars = set()\n",
    "    for char in s:\n",
    "        \n",
    "        if char in chars:                 # check if in set\n",
    "            return False\n",
    "        else:            \n",
    "            chars.add(char)                # add to set\n",
    "                        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "examples = ['', 'goo', 'abcdefg', 'aabbcdddeeeeee', 'abcdeghiklmnop']\n",
    "\n",
    "for example in examples:\n",
    "    print(uni_char(example))\n",
    "print()\n",
    "    \n",
    "for example in examples:\n",
    "    print(uni_char2(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacker Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_substring(string, sub_string):\n",
    "    count = 0\n",
    "    for i in range(len(string)-len(sub_string)+1):\n",
    "        if string[i:i+len(sub_string)] == sub_string:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "count_substring('abababab', 'ab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of steps to make word palindrome\n",
    "Minimum number of operations needed to make the string a palindrome  \n",
    "* One can only reduce the value of a letter by 1, i.e. he can change d to c, but he cannot change c to d or d to b.\n",
    "* Letter a may not be reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "def minimum_reductions(s):\n",
    "    n = len(s)\n",
    "    count = 0\n",
    "    for i in range(n // 2):\n",
    "        left = ord(s[i])\n",
    "        right = ord(s[(n - 1) - i])\n",
    "        if left != right:\n",
    "            if left > right:\n",
    "                count += left - right\n",
    "            else:\n",
    "                count += right - left\n",
    "    return count\n",
    "\n",
    "\n",
    "s = 'gsaldgk'\n",
    "print(minimum_reductions(s))\n",
    "\n",
    "# OR\n",
    "\n",
    "count=0\n",
    "for i in range(len(s)//2):\n",
    "    if s[i]!=s[-i-1]:\n",
    "        count+=abs(ord(s[i])-ord(s[-i-1]))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce string\n",
    "Delete all double letters  \n",
    "Using stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ac'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduce(s):\n",
    "    \n",
    "    stack = []\n",
    "            \n",
    "    for char in s:                                                       # iterate over remaining part of string\n",
    "        if not stack:                                                    # stack can be empty if prev double chars were removed\n",
    "            stack.append(char)\n",
    "        elif char == stack[-1]:                                          # double; stack[-1] = peek()\n",
    "            stack.pop()\n",
    "            continue                                                     # skip this char\n",
    "        else:\n",
    "            stack.append(char)                                           # not a double\n",
    "    return ''.join(stack)\n",
    "\n",
    "\n",
    "sa = \"aaabbcccdddd\"\n",
    "reduce(sa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funny string\n",
    "Funny if absolute difference in the ascii values of the chars at adjacent positions are the same for the string and its reverse string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funny\n",
      "Not Funny\n",
      "Funny\n",
      "Not Funny\n",
      "Funny\n"
     ]
    }
   ],
   "source": [
    "strings = ['acxz', 'bcxz', 'abba', 'abbat', 'tabbat']\n",
    "for string in strings:\n",
    "    reversed_string = string[::-1]\n",
    "    print('Funny' if all((abs(ord(reversed_string[i])-ord(reversed_string[i-1])) == abs(ord(string[i])-ord(string[i-1]))) \\\n",
    "                          for i in range(1,len(string))) else 'Not Funny')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "github\n",
      "zombie-bites\n",
      "cnet\n"
     ]
    }
   ],
   "source": [
    "def domain_name(url):\n",
    "    return url.split(\"//\")[-1].split(\"www.\")[-1].split(\".\")[0]\n",
    "\n",
    "\n",
    "print(domain_name(\"http://github.com/SaadBenn\"))\n",
    "print(domain_name(\"http://www.zombie-bites.com\"))\n",
    "print(domain_name(\"https://www.cnet.com\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete reoccurring characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Google warmup interview question: delete any reoccurring character\n",
    "# time c. O(n)\n",
    "def delete_reoccurring_characters(string):\n",
    "        \n",
    "    seen = set()\n",
    "    output = ''\n",
    "        \n",
    "    for char in string:\n",
    "        if char not in seen:\n",
    "            seen.add(char)\n",
    "            output += char\n",
    "                        \n",
    "    return output\n",
    "\n",
    "delete_reoccurring_characters('aaabbccccddddd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First unique char in string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def first_unique(string):\n",
    "    \n",
    "    count = dict()\n",
    "    for char in string:\n",
    "        if char not in count:\n",
    "            count[char] = 1\n",
    "        else:\n",
    "            count[char] += 1\n",
    "            \n",
    "    for char in string:\n",
    "        if count[char] == 1:\n",
    "            return char\n",
    "        \n",
    "    return -1\n",
    "\n",
    "first_unique('aabbcccddddde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common elements in multiple lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3, 4, 5}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_common_elements(all_lists):\n",
    "        \n",
    "    all_sets = list(map(set, all_lists))\n",
    "    common_elements = set.intersection(*all_sets)\n",
    "        \n",
    "    return common_elements\n",
    "\n",
    "a = [1,2,3,4,5]\n",
    "b = [2,3,4,5,6]\n",
    "c = [3,4,5,6,7]\n",
    "count_common_elements([a, b, c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group anagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['eat', 'tea', 'ate'], ['tan', 'nat'], ['bat']]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if anagrams: hashing (O(n))\n",
    "def anagram_check2(s1, s2):\n",
    "    \n",
    "    # remove spaces and lowercase letters\n",
    "    s1 = s1.replace(' ','').lower()\n",
    "    s2 = s2.replace(' ','').lower()\n",
    "    \n",
    "    # edge case\n",
    "    if len(s1) != len(s2):\n",
    "        return False\n",
    "    \n",
    "    # counting dict (or defaultdict())\n",
    "    count = {}    \n",
    "    \n",
    "        \n",
    "    # iterate over first string (ADD counts)\n",
    "    for letter in s1:\n",
    "        if letter in count:\n",
    "            count[letter] += 1\n",
    "        else:\n",
    "            count[letter] = 1\n",
    "            \n",
    "    # iterate over second string (SUBSTRACT counts)\n",
    "    for letter in s2:\n",
    "        if letter in count:\n",
    "            count[letter] -= 1\n",
    "        else:\n",
    "            count[letter] = 1\n",
    "    \n",
    "    # check if all are 0\n",
    "    for k in count:\n",
    "        if count[k] != 0:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "# group anagrams using sorting (time c. = NlogN)\n",
    "def group_anagrams(strings):\n",
    "    \n",
    "    dict_anagram,  res = {},  []\n",
    "    \n",
    "    idx = 0\n",
    "    for one_string in strings:\n",
    "        sorted_string = ''.join(sorted(one_string))\n",
    "        if sorted_string not in dict_anagram:\n",
    "            dict_anagram[sorted_string] = idx                              # dict value - index in a list of anagrams\n",
    "            idx += 1\n",
    "            res.append([])                                                       # create empty list in the end\n",
    "            res[-1].append(one_string)                                           # add anagram to it\n",
    "        else:\n",
    "            res[dict_anagram[sorted_string]].append(one_string)            # find correct list in big list and add\n",
    "                        \n",
    "    return res\n",
    "\n",
    "\n",
    "# group anagrams using linear-time anagram_check (time c. = O(n))\n",
    "def group_anagrams2(strings):\n",
    "    \n",
    "    dict_anagram,  res = {},  []    \n",
    "    \n",
    "    idx = 0\n",
    "    for one_string in strings:\n",
    "                \n",
    "        key_found = ''\n",
    "        for key in dict_anagram:                                                 # equivalent to \"if sorted_string in dict\"\n",
    "            if anagram_check2(key, one_string):\n",
    "                key_found = key\n",
    "                break            \n",
    "            \n",
    "        if not key_found:\n",
    "            dict_anagram[one_string] = idx                                       # dict value - index in a list of anagrams\n",
    "            idx += 1\n",
    "            res.append([])                                                       # create empty list in the end\n",
    "            res[-1].append(one_string)                                           # add anagram to it\n",
    "        else:\n",
    "            res[dict_anagram[key_found]].append(one_string)                      # find correct list in big list and add\n",
    "                        \n",
    "    return res\n",
    "\n",
    "\n",
    "strings = [\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"]\n",
    "group_anagrams(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer to Roman number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MMXX'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input in range(1, 3999)\n",
    "def int_to_roman(num):\n",
    "    \"\"\"\n",
    "    :type num: int\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    m = [\"\", \"M\", \"MM\", \"MMM\"];\n",
    "    c = [\"\", \"C\", \"CC\", \"CCC\", \"CD\", \"D\", \"DC\", \"DCC\", \"DCCC\", \"CM\"];\n",
    "    x = [\"\", \"X\", \"XX\", \"XXX\", \"XL\", \"L\", \"LX\", \"LXX\", \"LXXX\", \"XC\"];\n",
    "    i = [\"\", \"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\", \"VIII\", \"IX\"];\n",
    "    return m[num//1000] + c[(num%1000)//100] + x[(num%100)//10] + i[num%10]\n",
    "\n",
    "int_to_roman(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is Palindrome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Is a string a palindrome - ignore non letters and cases\n",
    "Example: 'A man, a plan, a canal: Panama' = True, 'race a car' = False\n",
    "Note: ask the interviewer about empty strings. Here an empty string is a valid palindrome\n",
    "\"\"\"\n",
    "from string import ascii_letters\n",
    "\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    \n",
    "    return \"\".join(i.lower() for i in s if i in ascii_letters)\n",
    "\n",
    "\n",
    "# O(n) solution\n",
    "def is_palindrome_two_pointers(s):\n",
    "    \n",
    "    i = 0\n",
    "    j = len(s)-1\n",
    "    while i < j:\n",
    "        while i < j and not s[i].isalnum():\n",
    "            i += 1\n",
    "        while i < j and not s[j].isalnum():\n",
    "            j -= 1\n",
    "        if s[i].lower() != s[j].lower():\n",
    "            return False\n",
    "        i, j = i+1, j-1\n",
    "                \n",
    "    return True\n",
    "\n",
    "\n",
    "# using stack\n",
    "def is_palindrome_stack(s):\n",
    "    \n",
    "    stack = []\n",
    "    s = remove_punctuation(s)\n",
    "\n",
    "    for i in range(len(s)//2, len(s)):\n",
    "        stack.append(s[i])\n",
    "    for i in range(0, len(s)//2):\n",
    "        if s[i] != stack.pop():\n",
    "            return False\n",
    "                \n",
    "    return True\n",
    "\n",
    "\n",
    "a = 'A man, a plan, a canal: Panama'\n",
    "b = 'race a car'\n",
    "\n",
    "print(is_palindrome_two_pointers(a))\n",
    "print(is_palindrome_two_pointers2(a))\n",
    "print(is_palindrome_string_reverse(a))\n",
    "print(is_palindrome_stack(a))\n",
    "\n",
    "print()\n",
    "\n",
    "print(is_palindrome_two_pointers(b))\n",
    "print(is_palindrome_two_pointers2(b))\n",
    "print(is_palindrome_string_reverse(b))\n",
    "print(is_palindrome_stack(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if syllables are rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_rotated(s1, s2):\n",
    "    if len(s1) == len(s2):\n",
    "        return s2 in s1 + s1\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "s1 = 'random'\n",
    "s2 = 'domran'\n",
    "\n",
    "is_rotated(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is isogram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Isogram = word or phrase w/out repeating letters\n",
    "def is_isogram(word):\n",
    "   \n",
    "    letter_list = []                                                         # empty list to append unique letters\n",
    "    for letter in word.lower():\n",
    "        \n",
    "        if letter.isalpha():                                                 # check letters only\n",
    "            if letter in letter_list:\n",
    "                return False\n",
    "            letter_list.append(letter)\n",
    "                        \n",
    "    return True\n",
    "\n",
    "s1 = 'abcdefg'\n",
    "s2 = 'abcbcdefg'\n",
    "\n",
    "print(is_isogram(s1))\n",
    "print(is_isogram(s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash value of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99111109101032111110"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hash_value(string, base):\n",
    "    \"\"\"Calculate the hash value of a string using base.\n",
    "\n",
    "    Example: 'abc' = 97 x base^2 + 98 x base^1 + 99 x base^0\n",
    "    @param s string to compute hash value for\n",
    "    @param base base to use to compute hash value\n",
    "    @return hash value\n",
    "    \"\"\"\n",
    "    hash_value = 0\n",
    "    power = len(string)-1\n",
    "        \n",
    "    for i in range(len(string)):\n",
    "        hash_value += ord(string[i]) * (base ** power)\n",
    "        power -= 1\n",
    "\n",
    "    return hash_value\n",
    "\n",
    "\n",
    "hash_value('come on',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sentences with dictionary\n",
    "For a given string and a dictionary, how many sentences can you make from the string with all the words from the dictionary.  \n",
    "Example: \"applet\", {app, let, apple, t, applet} => 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def make_sentence(string, dictionaries):\n",
    "        \n",
    "    global count\n",
    "    if len(string) == 0:\n",
    "        return True\n",
    "        \n",
    "    for i in range(0, len(string) + 1):\n",
    "        prefix, suffix = string[0:i], string[i:]\n",
    "        if prefix in dictionaries:\n",
    "            if suffix in dictionaries or make_sentence(suffix, dictionaries):\n",
    "                count += 1\n",
    "                                \n",
    "    return True\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "string = \"applet\"\n",
    "dictionary = {'app', 'let', 'apple', 't', 'applet'}\n",
    "\n",
    "string = 'thing'\n",
    "dictionary = {'thing'}\n",
    "make_sentence(string, dictionary)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is pangram\n",
    "A __pangram__ or holoalphabetic sentence is a sentence using __every letter of a given alphabet at least once__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Naive\n",
    "def is_pangram(string):\n",
    "        \n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    for char in alphabet: \n",
    "        if char not in string.lower(): \n",
    "            return False\n",
    "  \n",
    "    return True\n",
    "\n",
    "\n",
    "my_string = 'the quick brown fox jumps over the lazy dog'\n",
    "print(is_pangram(my_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Using set and string module\n",
    "import string\n",
    "\n",
    "def is_pangram(string): \n",
    "    return set(string.lower()) >= alphabet \n",
    "\n",
    "\n",
    "alphabet = set(string.ascii_lowercase)\n",
    "my_string = \"The quick brown fox jumps over the lazy dog\"\n",
    "print(is_pangram(my_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String = multiple copies of substring?\n",
    "Given non-empty string - check if it is composed of multiple copies of one substring.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Input: \"abab\"  \n",
    "Output: True (\"ab\" twice)\n",
    "\n",
    "Input: \"aba\"  \n",
    "Output: False\n",
    "\n",
    "Input: \"abcabcabcabc\"  \n",
    "Output: True (\"abc\" four times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# cool trick!\n",
    "def repeat_substring(s):   \n",
    "    return s in (s + s)[1:-1]\n",
    "\n",
    "print(repeat_substring('abab'))\n",
    "print(repeat_substring('aba'))\n",
    "print(repeat_substring('abcabcabcabc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_matching_naive(text='', pattern=''):\n",
    "    \"\"\"Returns positions where pattern is found in text.\n",
    "\n",
    "    We slide the string to match 'pattern' over the text\n",
    "\n",
    "    O((n-m)m)\n",
    "    Example: text = 'ababbababa', pattern = 'aba'\n",
    "                     string_matching_naive(t, s) returns [0, 5, 7]\n",
    "    @param text text to search inside\n",
    "    @param pattern string to search for\n",
    "    @return list containing offsets (shifts) where pattern is found inside text\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(text)\n",
    "    m = len(pattern)\n",
    "    offsets = []\n",
    "    for i in range(n-m+1):\n",
    "        if pattern == text[i:i+m]:\n",
    "            offsets.append(i)\n",
    "\n",
    "    return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Trie, search complexities can be brought to optimal limit (key length). String search in a well balanced BST - M * log N (M=max string length, N=num keys in tree). Trie search - O(M). Penalty - space.\n",
    "\n",
    "Node => multiple branches, 1 branch => possible character of keys.Mark last node of every key as end of word (node field isEndOfWord).\n",
    "\n",
    "* Insert: every char is Trie node; children = array of pointers to next level trie nodes. Key char = index in array children. Input key new => construct non-existing nodes + mark end of the word. Input key = prefix of existing key => mark last node of key as end of a word (is_leaf). Key length determines Trie depth.\n",
    "\n",
    "* Search for key - similar, but only compare chars and move down.\n",
    "\n",
    "In picture - every char = trie_node_t. E.g. root’s children a, b and t are filled, all other nodes of root will be NULL. Similarly, “a” at next level has one child (“n”), all other children are NULL.\n",
    "\n",
    "__Quick lookup of words/patterns in a set of words, but high space c.__:  \n",
    "* Insert and search time c. = key length\n",
    "* space c. = ALPHABET_SIZE * key_length * N where N = num keys in Trie (O(n^2)?) - impractical, unless space is of no concern\n",
    "* There are efficient representation of trie nodes (e.g. compressed trie, ternary search tree, etc.) to minimize memory requirements of trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "'''\n",
    "                       root\n",
    "                    /   \\    \\\n",
    "                    t   a     b\n",
    "                    |   |     |\n",
    "                    h   n     y\n",
    "                    |   |  \\  |\n",
    "                    e   s  y  e\n",
    "                 /  |   |\n",
    "                 i  r   w\n",
    "                 |  |   |\n",
    "                 r  e   e\n",
    "                        |\n",
    "                        r\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.nodes = dict()  # Mapping from char to TrieNode\n",
    "        self.is_leaf = False\n",
    "\n",
    "    def insert_many(self, words: [str]):  # noqa: E999 This syntax is Python 3 only\n",
    "        \"\"\"\n",
    "        Inserts a list of words into the Trie\n",
    "        :param words: list of string words\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for word in words:\n",
    "            self.insert(word)\n",
    "\n",
    "    def insert(self, word: str):  # noqa: E999 This syntax is Python 3 only\n",
    "        \"\"\"\n",
    "        Inserts a word into the Trie\n",
    "        :param word: word to be inserted\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        curr = self\n",
    "        for char in word:\n",
    "            if char not in curr.nodes:                             # nodes = dict()\n",
    "                curr.nodes[char] = TrieNode()\n",
    "            curr = curr.nodes[char]\n",
    "        curr.is_leaf = True\n",
    "\n",
    "    def find(self, word: str) -> bool:  # noqa: E999 This syntax is Python 3 only\n",
    "        \"\"\"\n",
    "        Tries to find word in a Trie\n",
    "        :param word: word to look for\n",
    "        :return: Returns True if word is found, False otherwise\n",
    "        \"\"\"\n",
    "        curr = self\n",
    "        for char in word:\n",
    "            if char not in curr.nodes:\n",
    "                return False\n",
    "            curr = curr.nodes[char]\n",
    "        return curr.is_leaf\n",
    "\n",
    "\n",
    "def print_words(node: TrieNode, word: str):  # noqa: E999 This syntax is Python 3 only\n",
    "    \"\"\"\n",
    "    Prints all the words in a Trie\n",
    "    :param node: root node of Trie\n",
    "    :param word: Word variable should be empty at start\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if node.is_leaf:\n",
    "        print(word, end=' ')\n",
    "\n",
    "    for key, value in node.nodes.items():\n",
    "        print_words(value, word + key)\n",
    "\n",
    "\n",
    "def test():\n",
    "    words = ['banana', 'bananas', 'bandana', 'band', 'apple', 'all', 'beast']\n",
    "    root = TrieNode()\n",
    "    root.insert_many(words)\n",
    "    # print_words(root, '')\n",
    "    assert root.find('banana')\n",
    "    assert not root.find('bandanas')\n",
    "    assert not root.find('apps')\n",
    "    assert root.find('apple')\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-complete feature using Trie\n",
    "Given trie and a prefix typed in the search query, provide all auto-complete recommendations (trie stores past searches)\n",
    "\n",
    "Example: {“abc”, “abcd”, “aa”, “abbbaba”}, user types “ab”, output = {“abc”, “abcd”, “abbbaba”}.\n",
    "\n",
    "Prerequisite Trie Search and Insert\n",
    "\n",
    "* Search for given query using standard Trie search algorithm.\n",
    "* If query prefix itself is not present, return -1 to indicate the same.\n",
    "* If query is present and is end of word in Trie, print query. This can quickly checked by seeing if last matching node has isEndWord flag set. We use this flag in Trie to mark end of word nodes for purpose of searching.\n",
    "* If last matching node of query has no children, return.\n",
    "* Else recursively print all nodes under subtree of last matching node\n",
    "\n",
    "__Improvements__  \n",
    "The number of matches might just be too large so we have to be selective while displaying them. We can restrict ourselves to display only the relevant results. By relevant, we can consider the past search history and show only the most searched matching strings as relevant results.  \n",
    "Store another value for the each node where isleaf=True which contains the number of hits for that query search. For example if “hat” is searched 10 times, then we store this 10 at the last node for “hat”. Now when we want to show the recommendations, we display the top k matches with the highest hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "help\n",
      "helps\n",
      "helping\n"
     ]
    }
   ],
   "source": [
    "# Python3 program to demonstrate auto-complete  \n",
    "# feature using Trie data structure. \n",
    "# Note: This is a basic implementation of Trie \n",
    "# and not the most optimized one. \n",
    "class TrieNode(): \n",
    "    def __init__(self): \n",
    "          \n",
    "        # Initialising one node for trie \n",
    "        self.children = {} \n",
    "        self.last = False\n",
    "\n",
    "class Trie(): \n",
    "    def __init__(self): \n",
    "          \n",
    "        # Initialising the trie structure. \n",
    "        self.root = TrieNode() \n",
    "        self.word_list = [] \n",
    "  \n",
    "    def formTrie(self, keys): \n",
    "          \n",
    "        # Forms a trie structure with the given set of strings \n",
    "        # if it does not exists already else it merges the key \n",
    "        # into it by extending the structure as required \n",
    "        for key in keys: \n",
    "            self.insert(key) # inserting one key to the trie. \n",
    "  \n",
    "    def insert(self, key): \n",
    "          \n",
    "        # Inserts a key into trie if it does not exist already. \n",
    "        # And if the key is a prefix of the trie node, just  \n",
    "        # marks it as leaf node. \n",
    "        node = self.root \n",
    "  \n",
    "        for a in list(key): \n",
    "            if not node.children.get(a): \n",
    "                node.children[a] = TrieNode() \n",
    "  \n",
    "            node = node.children[a] \n",
    "  \n",
    "        node.last = True\n",
    "  \n",
    "    def search(self, key): \n",
    "          \n",
    "        # Searches the given key in trie for a full match \n",
    "        # and returns True on success else returns False. \n",
    "        node = self.root \n",
    "        found = True\n",
    "  \n",
    "        for a in list(key): \n",
    "            if not node.children.get(a): \n",
    "                found = False\n",
    "                break\n",
    "  \n",
    "            node = node.children[a] \n",
    "  \n",
    "        return node and node.last and found \n",
    "  \n",
    "    def suggestionsRec(self, node, word): \n",
    "          \n",
    "        # Method to recursively traverse the trie \n",
    "        # and return a whole word.  \n",
    "        if node.last: \n",
    "            self.word_list.append(word) \n",
    "  \n",
    "        for a,n in node.children.items(): \n",
    "            self.suggestionsRec(n, word + a) \n",
    "  \n",
    "    def printAutoSuggestions(self, key): \n",
    "          \n",
    "        # Returns all the words in the trie whose common \n",
    "        # prefix is the given key thus listing out all  \n",
    "        # the suggestions for autocomplete. \n",
    "        node = self.root \n",
    "        not_found = False\n",
    "        temp_word = '' \n",
    "  \n",
    "        for a in list(key): \n",
    "            if not node.children.get(a): \n",
    "                not_found = True\n",
    "                break\n",
    "  \n",
    "            temp_word += a \n",
    "            node = node.children[a] \n",
    "  \n",
    "        if not_found: \n",
    "            return 0\n",
    "        elif node.last and not node.children: \n",
    "            return -1\n",
    "  \n",
    "        self.suggestionsRec(node, temp_word) \n",
    "  \n",
    "        for s in self.word_list: \n",
    "            print(s) \n",
    "        return 1\n",
    "    \n",
    "    \n",
    "keys = [\"dog\", \"cat\", \"a\", \"over\", \"help\", \"helps\", \"helping\"]                     # past searches\n",
    "key = \"help\"                                                                       # key for autocomplete suggestions\n",
    "status = [\"Not found\", \"Found\"] \n",
    "  \n",
    "# create trie object \n",
    "t = Trie() \n",
    "  \n",
    "# creating the trie structure with the  \n",
    "# given set of strings. \n",
    "t.formTrie(keys) \n",
    "  \n",
    "# autocompleting the given key using  \n",
    "# our trie structure. \n",
    "comp = t.printAutoSuggestions(key) \n",
    "  \n",
    "if comp == -1: \n",
    "    print(\"No other strings found with this prefix\\n\") \n",
    "elif comp == 0: \n",
    "    print(\"No string found with this prefix\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Break (Famous Google Interview Question) - Trie Solution\n",
    "Can the input string can be segmented into a space-separated sequence of dictionary words - famous Google interview question.\n",
    "\n",
    "Dict: { i, like, sam, sung, samsung, mobile, ice, cream, icecream, man, go, mango}  \n",
    "Input string:  ilikesamsung    \n",
    "Output: Yes \n",
    "The string can be segmented as \"i like samsung\"\n",
    "\n",
    "Extending a DP array-based solution (no Python version) with tries\n",
    "__replace pCrawl with something more coherent (curr? as in the first Trie example above)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n",
      "Yes\n",
      "Yes\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "class Solution(object): \n",
    "    def wordBreak(self, s, wordDict): \n",
    "        \"\"\" \n",
    "        Author : @amitrajitbose \n",
    "        :type s: str \n",
    "        :type wordDict: List[str] \n",
    "        :rtype: bool \n",
    "        \"\"\"\n",
    "        \"\"\"CREATING THE TRIE CLASS\"\"\"\n",
    "  \n",
    "        class TrieNode(object): \n",
    "              \n",
    "            def __init__(self): \n",
    "                self.children = [] #will be of size = 26 \n",
    "                self.isLeaf = False\n",
    "              \n",
    "            def getNode(self): \n",
    "                p = TrieNode() #new trie node \n",
    "                p.children = [] \n",
    "                for i in range(26): \n",
    "                    p.children.append(None) \n",
    "                p.isLeaf = False\n",
    "                return p \n",
    "              \n",
    "            def insert(self, root, key): \n",
    "                key = str(key) \n",
    "                pCrawl = root \n",
    "                for i in key: \n",
    "                    index = ord(i)-97\n",
    "                    if (pCrawl.children[index] == None): \n",
    "                        # node has to be initialised \n",
    "                        pCrawl.children[index] = self.getNode() \n",
    "                    pCrawl = pCrawl.children[index] \n",
    "                pCrawl.isLeaf = True #marking end of word \n",
    "              \n",
    "            def search(self, root, key): \n",
    "                #print(\"Searching %s\" %key) #DEBUG \n",
    "                pCrawl = root \n",
    "                for i in key: \n",
    "                    index = ord(i)-97\n",
    "                    if (pCrawl.children[index] == None): \n",
    "                        return False\n",
    "                    pCrawl = pCrawl.children[index] \n",
    "                if (pCrawl and pCrawl.isLeaf): \n",
    "                    return True\n",
    "          \n",
    "        def checkWordBreak(strr, root):\n",
    "                        \n",
    "            n = len(strr) \n",
    "            if (n == 0): \n",
    "                return True\n",
    "            for i in range(1,n+1): \n",
    "                if (root.search(root, strr[:i]) and checkWordBreak(strr[i:], root)): \n",
    "                    return True\n",
    "            return False\n",
    "          \n",
    "        \"\"\"IMPLEMENT SOLUTION\"\"\"\n",
    "        root = TrieNode().getNode() \n",
    "        for w in wordDict: \n",
    "            root.insert(root, w) \n",
    "        out = checkWordBreak(s, root) \n",
    "        if(out): \n",
    "            return \"Yes\"\n",
    "        else: \n",
    "            return \"No\"\n",
    "\n",
    "print(Solution().wordBreak(\"thequickbrownfox\", [\"the\", \"quick\", \"fox\", \"brown\"])) \n",
    "print(Solution().wordBreak(\"bedbathandbeyond\", [\"bed\", \"bath\", \"bedbath\", \"and\", \"beyond\"])) \n",
    "print(Solution().wordBreak(\"bedbathandbeyond\", [\"teddy\", \"bath\", \"bedbath\", \"and\", \"beyond\"])) \n",
    "print(Solution().wordBreak(\"bedbathandbeyond\", [\"bed\", \"bath\", \"bedbath\", \"and\", \"away\"])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morse code transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "International Morse Code defines a standard encoding where each letter is mapped to\n",
    "a series of dots and dashes, as follows: \"a\" maps to \".-\", \"b\" maps to \"-...\", \"c\"\n",
    "maps to \"-.-.\", and so on.\n",
    "\n",
    "For convenience, the full table for the 26 letters of the English alphabet is given below:\n",
    "        'a':\".-\",\n",
    "        'b':\"-...\",\n",
    "        'c':\"-.-.\",\n",
    "        'd': \"-..\",\n",
    "        'e':\".\",\n",
    "        'f':\"..-.\",\n",
    "        'g':\"--.\",\n",
    "        'h':\"....\",\n",
    "        'i':\"..\",\n",
    "        'j':\".---\",\n",
    "        'k':\"-.-\",\n",
    "        'l':\".-..\",\n",
    "        'm':\"--\",\n",
    "        'n':\"-.\",\n",
    "        'o':\"---\",\n",
    "        'p':\".--.\",\n",
    "        'q':\"--.-\",\n",
    "        'r':\".-.\",\n",
    "        's':\"...\",\n",
    "        't':\"-\",\n",
    "        'u':\"..-\",\n",
    "        'v':\"...-\",\n",
    "        'w':\".--\",\n",
    "        'x':\"-..-\",\n",
    "        'y':\"-.--\",\n",
    "        'z':\"--..\"\n",
    "\n",
    "Now, given a list of words, each word can be written as a concatenation of the\n",
    "Morse code of each letter. For example, \"cab\" can be written as \"-.-.-....-\",\n",
    "(which is the concatenation \"-.-.\" + \"-...\" + \".-\"). We'll call such a\n",
    "concatenation, the transformation of a word.\n",
    "\n",
    "Return the number of different transformations among all words we have.\n",
    "Example:\n",
    "Input: words = [\"gin\", \"zen\", \"gig\", \"msg\"]\n",
    "Output: 2\n",
    "Explanation:\n",
    "The transformation of each word is:\n",
    "\"gin\" -> \"--...-.\"\n",
    "\"zen\" -> \"--...-.\"\n",
    "\"gig\" -> \"--...--.\"\n",
    "\"msg\" -> \"--...--.\"\n",
    "\n",
    "There are 2 different transformations, \"--...-.\" and \"--...--.\".\n",
    "\"\"\"\n",
    "\n",
    "morse_code = {\n",
    "    'a':\".-\",\n",
    "    'b':\"-...\",\n",
    "    'c':\"-.-.\",\n",
    "    'd': \"-..\",\n",
    "    'e':\".\",\n",
    "    'f':\"..-.\",\n",
    "    'g':\"--.\",\n",
    "    'h':\"....\",\n",
    "    'i':\"..\",\n",
    "    'j':\".---\",\n",
    "    'k':\"-.-\",\n",
    "    'l':\".-..\",\n",
    "    'm':\"--\",\n",
    "    'n':\"-.\",\n",
    "    'o':\"---\",\n",
    "    'p':\".--.\",\n",
    "    'q':\"--.-\",\n",
    "    'r':\".-.\",\n",
    "    's':\"...\",\n",
    "    't':\"-\",\n",
    "    'u':\"..-\",\n",
    "    'v':\"...-\",\n",
    "    'w':\".--\",\n",
    "    'x':\"-..-\",\n",
    "    'y':\"-.--\",\n",
    "    'z':\"--..\"\n",
    "}\n",
    "def convert_morse_word(word):\n",
    "    morse_word = \"\"\n",
    "    word = word.lower()\n",
    "    for char in word:\n",
    "        morse_word = morse_word + morse_code[char]\n",
    "    return morse_word\n",
    "\n",
    "def unique_morse(words):\n",
    "    unique_morse_word = []\n",
    "    for word in words:\n",
    "        morse_word = convert_morse_word(word)\n",
    "        if morse_word not in unique_morse_word:\n",
    "            unique_morse_word.append(morse_word)\n",
    "    return len(unique_morse_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
