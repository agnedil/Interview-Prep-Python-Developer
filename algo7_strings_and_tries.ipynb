{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STRINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest Common Prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Word Matching\n",
    "One by one calculate the LCP of each of the given string with the current LCP so far. The final result - longest common prefix of all the strings  \n",
    "Time c. O(MN) where N = # chars in strings & M = length of largest string  \n",
    "Space c. O(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCP =  eur\n"
     ]
    }
   ],
   "source": [
    "# common prefix for 2 strings\n",
    "def common_prefix(str1, str2): \n",
    "  \n",
    "    _res = '' \n",
    "    n1, n2 = len(str1), len(str2)\n",
    "      \n",
    "    # Compare str1 and str2 \n",
    "    i = j = 0\n",
    "    while i <= n1 - 1 and j <= n2 - 1: \n",
    "      \n",
    "        if (str1[i] != str2[j]):\n",
    "            break\n",
    "              \n",
    "        _res += str1[i] \n",
    "        i += 1\n",
    "        j += 1\n",
    "  \n",
    "    return _res \n",
    "  \n",
    "# find longest LCP \n",
    "def LCP(arr): \n",
    "  \n",
    "    prefix = arr[0]  \n",
    "    for i in range (1, len(arr)): \n",
    "        prefix = common_prefix(prefix, arr[i]) \n",
    "  \n",
    "    return prefix \n",
    "  \n",
    "\n",
    "arr = ['eurasia', 'euroasian', 'euran', 'europe'] \n",
    "res = LCP(arr) \n",
    "\n",
    "if ans: \n",
    "    print('LCP = ', res)\n",
    "else: \n",
    "    print('No LCP') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Character matching (looks the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No LCP\n"
     ]
    }
   ],
   "source": [
    "def LCP(arr):      \n",
    "    \n",
    "    minlen = len(arr[0])                                       # find length of shortest string\n",
    "    for i in range(1, len(arr)): \n",
    "        if len(arr[i]) < minlen: \n",
    "            minlen = len(arr[i])\n",
    "            \n",
    "    res = '' \n",
    "    for i in range(minlen):                                    # current char must be same in all strings      \n",
    "        \n",
    "        current = arr[0][i] \n",
    "   \n",
    "        for j in range(1, len(arr)): \n",
    "            if arr[j][i] != current: \n",
    "                return res\n",
    "           \n",
    "        res = res + current\n",
    "\n",
    "\n",
    "arr = ['eurasia', 'aeuroasian', 'ueuran', 'eeurope'] \n",
    "res = LCP(arr) \n",
    "\n",
    "if res: \n",
    "    print('LCP = ', res)\n",
    "else: \n",
    "    print('No LCP') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse string\n",
    "Think of the base case - string length <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse(s):    \n",
    "    \n",
    "    if len(s) <= 1:                       # base case\n",
    "        return s\n",
    "    \n",
    "    return reverse(s[1:]) + s[0]          # recursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlrow olleh\n",
      "987654321\n"
     ]
    }
   ],
   "source": [
    "print(reverse('hello world'))\n",
    "print(reverse('123456789'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all permutations of string\n",
    "If s='abc' => ['abc', 'acb', 'bac', 'bca', 'cab', 'cba']  \n",
    "(If char is repeated - each occurence is distinct; if s='xxx' => list of 6 \"versions\" of 'xxx'\n",
    "\n",
    "* For each char, __set it aside__ and get a list of __all permutations for the remainig string__;\n",
    "* __Add the char set aside__ to each element of that list, and __append the result to final list__. E.g. set aside 'a' in 'abc', get all permitation of 'bc' = ['bc', 'cb'], then add 'a' to each of them = 'abc' and 'acb', add these to final list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute(s):\n",
    "    \n",
    "    out = []\n",
    "    if len(s) == 1:                                         # base case\n",
    "        out = [s]\n",
    "        \n",
    "    else:        \n",
    "        for i, char in enumerate(s):                         # for each char in string            \n",
    "            for perm in permute(s[:i] + s[i+1:]):           # permite string w/out this char                \n",
    "                out += [char + perm]                         # add removed char and append to output\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc', 'acb', 'bac', 'bca', 'cab', 'cba']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permute('abc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse a string without affecting special characters\n",
    "Given string with special chars and letters (a-zA-Z), reverse it without affecting special chars. Example: \"a,b!c\" => \"c,b!a\"  \n",
    "Copying letters to a separate array, revirsing it, then iterating over input and inserting when there is a letter - time c. = O(n) + space c.  \n",
    "A better solution:  \n",
    "* l = 0, r = n-1;\n",
    "* While l < r:  \n",
    "    a) If not str[l].isalpha(): l++  \n",
    "    b) If not str[r].isalpha(): r--  \n",
    "    c) Swap str[l] and str[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input string:  a!!!b.c.d,e'f,ghi\n",
      "Output string:  i!!!h.g.f,e'd,cba\n"
     ]
    }
   ],
   "source": [
    "# time c. O(n), space c. O(1)\n",
    "def reverse_string(text):\n",
    "        \n",
    "    # initiate left and right indices\n",
    "    left = 0\n",
    "    right = len(text) - 1\n",
    "    \n",
    "    while left < right:\n",
    "                \n",
    "        # find actual letters, skip special chars\n",
    "        while not text[left].isalpha():\n",
    "            left += 1\n",
    "        while not text[right].isalpha():\n",
    "            right -= 1\n",
    "            \n",
    "        # swap once found, change left and right indices    \n",
    "        text[left], text[right] = text[right], text[left]\n",
    "        left += 1\n",
    "        right -= 1\n",
    "                \n",
    "    return ''.join(text)\n",
    "   \n",
    "      \n",
    "input_string = \"a!!!b.c.d,e'f,ghi\"\n",
    "print (\" Input string: \", input_string) \n",
    "print (\"Output string: \", reverse_string(list(input_string))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All palindromic partitions of a string\n",
    "All such partitions in which every element is a palindrome string.  \n",
    "Example: \"bcc\" => [[\"b\", \"c\", \"c\"], [\"b\", \"cc\"]] OR \"geeks\" => [[\"g\", \"e\", \"e\", \"k\", \"s\"], [\"g\", \"ee\", \"k\", \"s\"]]\n",
    "\n",
    "Solution:  \n",
    "In recursion, when we are on index i, we incrementally check all substrings starting from i for being palindromic. If found, we recursively solve the problem for the remaining string and add this in our solution.\n",
    "* Maintain a 2D vector to store all possible partitions + temp vector to store current partition, new start index of string to check partitions as we have already checked partitions before this index.\n",
    "* Keep on iterating further on string and check if it is palindrome or not.\n",
    "* If palindrome - add it to current partitions vector and recurse on this new string if it is not the end of the string. After coming back again change the current partition vector to the old one as it might have changed in the recursive step.\n",
    "* If we reach the end of string while iterating - we have our partitions in temp vector so we will add them to results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a b b a c a b b a\n",
      "a b b a c a bb a\n",
      "a b b a c abba\n",
      "a b b aca b b a\n",
      "a b b aca bb a\n",
      "a b bacab b a\n",
      "a bb a c a b b a\n",
      "a bb a c a bb a\n",
      "a bb a c abba\n",
      "a bb aca b b a\n",
      "a bb aca bb a\n",
      "a bb bbacabb a\n",
      "abba c a b b a\n",
      "abba c a bb a\n",
      "abba c abba\n",
      "abba abbacabba\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['a', 'b', 'b', 'a', 'c', 'a', 'b', 'b', 'a'],\n",
       " ['a', 'b', 'b', 'a', 'c', 'a', 'bb', 'a'],\n",
       " ['a', 'b', 'b', 'a', 'c', 'abba'],\n",
       " ['a', 'b', 'b', 'aca', 'b', 'b', 'a'],\n",
       " ['a', 'b', 'b', 'aca', 'bb', 'a'],\n",
       " ['a', 'b', 'bacab', 'b', 'a'],\n",
       " ['a', 'bb', 'a', 'c', 'a', 'b', 'b', 'a'],\n",
       " ['a', 'bb', 'a', 'c', 'a', 'bb', 'a'],\n",
       " ['a', 'bb', 'a', 'c', 'abba'],\n",
       " ['a', 'bb', 'aca', 'b', 'b', 'a'],\n",
       " ['a', 'bb', 'aca', 'bb', 'a'],\n",
       " ['a', 'bb', 'bbacabb', 'a'],\n",
       " ['abba', 'c', 'a', 'b', 'b', 'a'],\n",
       " ['abba', 'c', 'a', 'bb', 'a'],\n",
       " ['abba', 'c', 'abba'],\n",
       " ['abba', 'abbacabba']]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_palindrome(string):\n",
    "        \n",
    "    if not string:\n",
    "        return False\n",
    "    return string == string[::-1]\n",
    "\n",
    "\n",
    "def add_strings(v, s, temp, index): \n",
    "      \n",
    "    # Iterate all indexes, recursively add remaining partitions if current str is palindrome\n",
    "    length = len(s)\n",
    "    string = \"\"\n",
    "  \n",
    "    current = temp[:] \n",
    "  \n",
    "    if index == 0: \n",
    "        temp = [] \n",
    "    for i in range(index, length): \n",
    "        string += s[i] \n",
    "        if check_palindrome(string): \n",
    "            temp.append(string) \n",
    "            if i + 1 < length: \n",
    "                add_strings(v, s, temp[:], i + 1) \n",
    "            else: \n",
    "                v.append(temp) \n",
    "            temp = current \n",
    "            \n",
    "            \n",
    "def partition(s, v):\n",
    "      \n",
    "    # Generate all palindromic partitions of 's' and store result in 'v' \n",
    "    temp = [] \n",
    "    add_strings(v, s, temp[:], 0)\n",
    "    \n",
    "    for item in v:\n",
    "        print(' '.join(item))\n",
    "    \n",
    "    return v\n",
    " \n",
    "s = \"abbacabba\"\n",
    "partitions = [] \n",
    "partition(s, partitions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if anagrams\n",
    "Anagrams share exact same characters (rearranged and ignoring spaces / capitalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting, may not be optimal\n",
    "def anagram_check(s1, s2):\n",
    "    \n",
    "    # remove spaces and make lowercase\n",
    "    s1 = s1.replace(' ','').lower()\n",
    "    s2 = s2.replace(' ','').lower()\n",
    "        \n",
    "    return sorted(s1) == sorted(s2)\n",
    "\n",
    "\n",
    "# counting w/dict() = hash tables\n",
    "def anagram_check2(s1, s2):\n",
    "    \n",
    "    # remove spaces and lowercase letters\n",
    "    s1 = s1.replace(' ','').lower()\n",
    "    s2 = s2.replace(' ','').lower()\n",
    "    \n",
    "    # edge case\n",
    "    if len(s1) != len(s2):\n",
    "        return False\n",
    "    \n",
    "    # counting dict (or defaultdict())\n",
    "    count = {}    \n",
    "    \n",
    "        \n",
    "    # iterate over first string (ADD counts)\n",
    "    for letter in s1:\n",
    "        if letter in count:\n",
    "            count[letter] += 1\n",
    "        else:\n",
    "            count[letter] = 1\n",
    "            \n",
    "    # iterate over second string (SUBSTRACT counts)\n",
    "    for letter in s2:\n",
    "        if letter in count:\n",
    "            count[letter] -= 1\n",
    "        else:\n",
    "            count[letter] = 1\n",
    "    \n",
    "    # check if all are 0\n",
    "    for k in count:\n",
    "        if count[k] != 0:\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sort-based aproach:\n",
      "\tTrue for \"public relations AND crap built on lies\"\n",
      "\tTrue for \"dog AND god\"\n",
      "\tTrue for \"clint eastwood AND old west action\"\n",
      "\tFalse for \"dd AND aa\"\n",
      "\n",
      "Using counting aproach:\n",
      "\tTrue for \"public relations AND crap built on lies\"\n",
      "\tTrue for \"dog AND god\"\n",
      "\tTrue for \"clint eastwood AND old west action\"\n",
      "\tFalse for \"dd AND aa\"\n"
     ]
    }
   ],
   "source": [
    "anagrams = [('public relations', 'crap built on lies'), ('dog','god'), ('clint eastwood','old west action'), ('dd','aa')]\n",
    "\n",
    "print('Using sort-based aproach:')\n",
    "for a in anagrams:\n",
    "    print('\\t{} for \"{}\"'.format(anagram_check(*a), ' AND '.join(a)))\n",
    "    \n",
    "print('\\nUsing counting aproach:')\n",
    "for a in anagrams:\n",
    "    print('\\t{} for \"{}\"'.format(anagram_check2(*a), ' AND '.join(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Reversal\n",
    "Print sentence with the word order reversed\n",
    "\n",
    "__Correct solution__: loop over text, extract words, push them to __\"stack\"__, pop them in reverse order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easiest\n",
    "def reverse_sent1(s):\n",
    "    return \" \".join(reversed(s.split()))\n",
    "\n",
    "def reverse_sent2(s):\n",
    "    return \" \".join(s.split()[::-1])\n",
    "\n",
    "# Correct (manual split)\n",
    "def reverse_sent3(s):\n",
    "        \n",
    "    words, spaces = [], [' ']    \n",
    "    \n",
    "    i = 0                                                     # index        \n",
    "    while i < len(s):\n",
    "        \n",
    "        if s[i] not in spaces:                                # if not a space            \n",
    "            start = i                                         # word start            \n",
    "            while i < len(s) and s[i] not in spaces:                \n",
    "                i += 1                                        # word end            \n",
    "            words.append(s[start:i])                          # append word to list        \n",
    "        i += 1                                                # increase index\n",
    "      \n",
    "    return ' '.join(words[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are how John Hello\n",
      "you are how John Hello\n",
      "you are how John Hello\n"
     ]
    }
   ],
   "source": [
    "print(reverse_sent1('   Hello John    how are you   '))\n",
    "print(reverse_sent2('   Hello John    how are you   '))\n",
    "print(reverse_sent3('   Hello John    how are you   '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am who I am and I like pizza\n",
      "pizza like I and am I who am I\n"
     ]
    }
   ],
   "source": [
    "# easiest expanded\n",
    "def reverse_words(string):\n",
    "        \n",
    "    sent = string.strip().split()                                                 # set = list of words\n",
    "    \n",
    "    left = 0\n",
    "    right = len(sent) - 1    \n",
    "    while left < right:\n",
    "        sent[left], sent[right] = sent[right], sent[left]\n",
    "        left += 1\n",
    "        right -= 1    \n",
    "\n",
    "    return ' '.join(sent)\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "string = 'I am who I am and I like pizza'\n",
    "print(string + '\\n' + reverse_words(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String compression\n",
    "Compress 'AAAABBBBCCCCCDDEEEE' into 'A4B4C5D2E4'\n",
    "*  Work off of a list of characters, convert it back to string\n",
    "* Time and space complexity of O(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(s):\n",
    "    \"\"\"\n",
    "    Compresses without checking - RunLength Compression algo\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(s) == 0:   return ''                # edge cases        \n",
    "    elif len(s) == 1: return s + '1'    \n",
    "    \n",
    "    res = ''                                   # run / res is empty\n",
    "    last, count = s[0], 1                      # intialize\n",
    "        \n",
    "    i = 1    \n",
    "    while i < len(s):        \n",
    "        \n",
    "        if s[i] == s[i - 1]:                   # check if same letter            \n",
    "            count += 1\n",
    "        else:            \n",
    "            res = res + s[i - 1] + str(count)  # if not, store previous data\n",
    "            count = 1        \n",
    "        i += 1                                 # to terminate while loop    \n",
    "    \n",
    "    res = res + s[i - 1] + str(count)          # put everything back into run - WHY THIS LINE?\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2B2C3 AABBCCC\n",
      "A5B4C5 AAAAABBBBCCCCC\n",
      "A4B3C7D7 AAAABBBCCCCCCCDDDDDDD\n",
      " \n"
     ]
    }
   ],
   "source": [
    "examples = ['AABBCCC', 'AAAAABBBBCCCCC', 'AAAABBBCCCCCCCDDDDDDD', '']\n",
    "\n",
    "for example in examples:\n",
    "    print(compress(example), example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knuth-Morris-Pratt Algorithm\n",
    "Find a pattern within a piece of text; time c. = O(n + m)\n",
    "\n",
    "Principle: whenever we detect a mismatch in position i of pattern, we already know some of the characters in the text of the next window. We take advantage of this information to avoid matching the characters that we know will anyway match (by shifting to the left only by pi[i].\n",
    "\n",
    "In other words, if a match which had begun at text[m] fails while comparing text[m + i] to pattern[i], then the next possible match must begin at text[m + (i - T[i])] - at a higher index than m, so that pi[i] < i, and this way we skip the portion of the pattern that will match anyway\n",
    "\n",
    "__Precomputing a table of prefixes__:\n",
    "\n",
    "* KMP algorithm preprocesses pattern and constructs an auxiliary pi[] of size m (len(pattern)) which is used to skip characters while matching.\n",
    "* __pi__ is an array of __longest proper prefixes which are also suffixes__ (lpps). Proper prefix - any prefix, but the whole string. For string “ABC”, prefixes = “”, “A”, “AB” and “ABC”, BUT proper prefixes = “”, “A” and “AB”. Suffixes = “”, “C”, “BC” and “ABC”.\n",
    "* We search for lpps in sub-patterns. More clearly we focus on sub-strings of patterns that are either prefix and suffix.\n",
    "* For each sub-pattern pattern[0..i] where i = [0, m-1], __pi[i] stores length of the maximum matching proper prefix which is also a suffix of the sub-pattern pat[0..i]__.\n",
    "\n",
    "Note: pi[i] could also be defined as longest prefix which is also proper suffix. We need to use \"proper\" at one place to make sure that the whole substring is not considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]\n",
      "[]\n",
      "[10]\n",
      "[4]\n",
      "[15]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 0]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return all positions of a substring in a larger string\n",
    "def kmp( pattern='', text='' ):\n",
    "        \n",
    "    n = len(text)\n",
    "    m = len(pattern)\n",
    "    matches = []\n",
    "    pi = get_prefixes(pattern)                                  # table of precomputed prefixes\n",
    "    j = 0                                                       # index for pattern\n",
    "    for i in range(n):                                          # index for text\n",
    "        while j > 0 and pattern[j] != text[i]:\n",
    "            j = pi[j - 1]\n",
    "        if pattern[j] == text[i]:\n",
    "            j = j + 1\n",
    "        if j == m:\n",
    "            matches.append(i - m + 1)\n",
    "            j = pi[j-1]\n",
    "\n",
    "    return matches\n",
    "\n",
    "\n",
    "def get_prefixes(pattern_):\n",
    "        \n",
    "    m = len(pattern_)\n",
    "    pi = [0] * m\n",
    "        \n",
    "    LPP = 0                                                      # longest proper prefix which is also a suffix\n",
    "    for j in range(1, m):\n",
    "        while LPP > 0 and pattern_[LPP] != pattern_[j]:\n",
    "            LPP = pi[LPP - 1]\n",
    "                        \n",
    "        if pattern_[LPP] == pattern_[j]:\n",
    "            LPP = LPP + 1\n",
    "                        \n",
    "        pi[j] = LPP\n",
    "                \n",
    "    return pi\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "# Test 1)\n",
    "pattern = \"abc1abc12\"\n",
    "text1 = \"alskfjaldsabc1abc1abc12k23adsfabcabc\"\n",
    "text2 = \"alskfjaldsk23adsfabcabc\"\n",
    "print(kmp(pattern, text1))\n",
    "print(kmp(pattern, text2))\n",
    "\n",
    "# Test 2)\n",
    "pattern = \"ABABX\"\n",
    "text = \"ABABZABABYABABX\"\n",
    "print(kmp(pattern, text))\n",
    "\n",
    "# Test 3)\n",
    "pattern = \"AAAB\"\n",
    "text = \"ABAAAAAB\"\n",
    "print(kmp(pattern, text))\n",
    "\n",
    "# Test 4)\n",
    "pattern = \"abcdabcy\"\n",
    "text = \"abcxabcdabxabcdabcdabcy\"\n",
    "print(kmp(pattern, text))\n",
    "\n",
    "# Test 5)\n",
    "pattern = \"aaab\"\n",
    "get_prefixes(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest common subsequence (DP)\n",
    "Subsequence - not necessarily contiguous. Example: 'abghed' & 'bhaxyz' have lcs 'abh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 'abcf')\n",
      "(4, 'GTAB')\n"
     ]
    }
   ],
   "source": [
    "def lcs(s1, s2):\n",
    "        \n",
    "    matrix = [ ['' for x in range(len(s2))] for x in range(len(s1)) ]\n",
    "    for i in range(len(s1)):\n",
    "        for j in range(len(s2)):\n",
    "            if s1[i] == s2[j]:\n",
    "                if i == 0 or j == 0:\n",
    "                    matrix[i][j] = s1[i]\n",
    "                else:\n",
    "                    matrix[i][j] = matrix[i-1][j-1] + s1[i]\n",
    "            else:\n",
    "                matrix[i][j] = max(matrix[i-1][j], matrix[i][j-1], key=len)\n",
    "\n",
    "    cs = matrix[-1][-1]\n",
    "\n",
    "    return len(cs), cs\n",
    "\n",
    "print(lcs(\"abcdaf\", \"acbcf\"))\n",
    "\n",
    "X = \"AGGTAB\"\n",
    "Y = \"GXTXAYB\"\n",
    "print(lcs(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest common substring (DP)\n",
    "Time c. O(nm), space c. O(nm) (space can be converted to O(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I went there'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def longest_common_substring(s1, s2):\n",
    "        \n",
    "    m = [[0] * (len(s2) + 1) for i in range(len(s1) + 1)]\n",
    "    length, idx_longest = 0, 0\n",
    "        \n",
    "    for i in range(1, 1 + len(s1)):\n",
    "        for j in range(1, 1 + len(s2)):\n",
    "                        \n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                m[i][j] = m[i - 1][j - 1] + 1\n",
    "                if m[i][j] > length:\n",
    "                    length = m[i][j]\n",
    "                    idx_longest = i\n",
    "            else:\n",
    "                m[i][j] = 0\n",
    "                                \n",
    "    return s1[ idx_longest - length: idx_longest ]\n",
    "\n",
    "\n",
    "s1 = 'I went there'\n",
    "s2 = 'No matter what I went there and found it'\n",
    "longest_common_substring(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest common substring in array of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I went'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIND LONGEST COMMON SUBSTRING\n",
    "def find_stem(arr): \n",
    "  \n",
    "    reference, res = arr[0], ' ' \n",
    "  \n",
    "    for i in range(len(reference)):                              # generate all possible substrings in reference string\n",
    "        for j in range( i + 1, len(reference) + 1):\n",
    "            \n",
    "            stem = reference[i:j] \n",
    "            k = 1\n",
    "            for k in range(1, len(arr)):  \n",
    "                 \n",
    "                if stem not in arr[k]:                           # Check if the generated stem is common to all words\n",
    "                    break              \n",
    "            \n",
    "            if (k + 1 == len(arr) and len(res) < len(stem)):     # If current substr is in all strings and greater than current \n",
    "                res = stem \n",
    "  \n",
    "    return res\n",
    "\n",
    "# incomplete solution - the last elements in arr is not taken into account\n",
    "s1 = 'I went there'\n",
    "s2 = 'No matter what I went there and found it'\n",
    "s3 = \"That's where I went\"\n",
    "s4 = 'I we'\n",
    "find_stem([s1, s2, s3, s4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique characters in string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-in data structure & built in function\n",
    "def uni_char(s):\n",
    "    return len(set(s)) == len(s)\n",
    "\n",
    "#  built-in data structure & look-up method\n",
    "def uni_char2(s):\n",
    "    chars = set()\n",
    "    for char in s:\n",
    "        \n",
    "        if char in chars:                 # check if in set\n",
    "            return False\n",
    "        else:            \n",
    "            chars.add(char)                # add to set\n",
    "                        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "examples = ['', 'goo', 'abcdefg', 'aabbcdddeeeeee', 'abcdeghiklmnop']\n",
    "\n",
    "for example in examples:\n",
    "    print(uni_char(example))\n",
    "print()\n",
    "    \n",
    "for example in examples:\n",
    "    print(uni_char2(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hacker Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_substring(string, sub_string):\n",
    "    count = 0\n",
    "    for i in range(len(string)-len(sub_string)+1):\n",
    "        if string[i:i+len(sub_string)] == sub_string:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "count_substring('abababab', 'ab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of steps to make word palindrome\n",
    "Minimum number of operations needed to make the string a palindrome  \n",
    "* One can only reduce the value of a letter by 1, i.e. he can change d to c, but he cannot change c to d or d to b.\n",
    "* Letter a may not be reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "def minimum_reductions(s):\n",
    "    n = len(s)\n",
    "    count = 0\n",
    "    for i in range(n // 2):\n",
    "        left = ord(s[i])\n",
    "        right = ord(s[(n - 1) - i])\n",
    "        if left != right:\n",
    "            if left > right:\n",
    "                count += left - right\n",
    "            else:\n",
    "                count += right - left\n",
    "    return count\n",
    "\n",
    "\n",
    "s = 'gsaldgk'\n",
    "print(minimum_reductions(s))\n",
    "\n",
    "# OR\n",
    "\n",
    "count=0\n",
    "for i in range(len(s)//2):\n",
    "    if s[i]!=s[-i-1]:\n",
    "        count+=abs(ord(s[i])-ord(s[-i-1]))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce string\n",
    "Delete all double letters  \n",
    "Using stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ac'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduce(s):\n",
    "    \n",
    "    stack = []\n",
    "            \n",
    "    for char in s:                                                       # iterate over remaining part of string\n",
    "        if not stack:                                                    # stack can be empty if prev double chars were removed\n",
    "            stack.append(char)\n",
    "        elif char == stack[-1]:                                          # double; stack[-1] = peek()\n",
    "            stack.pop()\n",
    "            continue                                                     # skip this char\n",
    "        else:\n",
    "            stack.append(char)                                           # not a double\n",
    "    return ''.join(stack)\n",
    "\n",
    "\n",
    "sa = \"aaabbcccdddd\"\n",
    "reduce(sa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funny string\n",
    "Funny if absolute difference in the ascii values of the chars at adjacent positions are the same for the string and its reverse string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funny\n",
      "Not Funny\n",
      "Funny\n",
      "Not Funny\n",
      "Funny\n"
     ]
    }
   ],
   "source": [
    "strings = ['acxz', 'bcxz', 'abba', 'abbat', 'tabbat']\n",
    "for string in strings:\n",
    "    reversed_string = string[::-1]\n",
    "    print('Funny' if all((abs(ord(reversed_string[i])-ord(reversed_string[i-1])) == abs(ord(string[i])-ord(string[i-1]))) \\\n",
    "                          for i in range(1,len(string))) else 'Not Funny')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "github\n",
      "zombie-bites\n",
      "cnet\n"
     ]
    }
   ],
   "source": [
    "def domain_name(url):\n",
    "    return url.split(\"//\")[-1].split(\"www.\")[-1].split(\".\")[0]\n",
    "\n",
    "\n",
    "print(domain_name(\"http://github.com/SaadBenn\"))\n",
    "print(domain_name(\"http://www.zombie-bites.com\"))\n",
    "print(domain_name(\"https://www.cnet.com\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete reoccurring characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Google warmup interview question: delete any reoccurring character\n",
    "# time c. O(n)\n",
    "def delete_reoccurring_characters(string):\n",
    "        \n",
    "    seen = set()\n",
    "    output = ''\n",
    "        \n",
    "    for char in string:\n",
    "        if char not in seen:\n",
    "            seen.add(char)\n",
    "            output += char\n",
    "                        \n",
    "    return output\n",
    "\n",
    "delete_reoccurring_characters('aaabbccccddddd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First unique char in string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def first_unique(string):\n",
    "    \n",
    "    count = dict()\n",
    "    for char in string:\n",
    "        if char not in count:\n",
    "            count[char] = 1\n",
    "        else:\n",
    "            count[char] += 1\n",
    "            \n",
    "    for char in string:\n",
    "        if count[char] == 1:\n",
    "            return char\n",
    "        \n",
    "    return -1\n",
    "\n",
    "first_unique('aabbcccddddde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common elements in multiple lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3, 4, 5}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_common_elements(all_lists):\n",
    "        \n",
    "    all_sets = list(map(set, all_lists))\n",
    "    common_elements = set.intersection(*all_sets)\n",
    "        \n",
    "    return common_elements\n",
    "\n",
    "a = [1,2,3,4,5]\n",
    "b = [2,3,4,5,6]\n",
    "c = [3,4,5,6,7]\n",
    "count_common_elements([a, b, c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group anagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['eat', 'tea', 'ate'], ['tan', 'nat'], ['bat']]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if anagrams: hashing (O(n))\n",
    "def anagram_check2(s1, s2):\n",
    "    \n",
    "    # remove spaces and lowercase letters\n",
    "    s1 = s1.replace(' ','').lower()\n",
    "    s2 = s2.replace(' ','').lower()\n",
    "    \n",
    "    # edge case\n",
    "    if len(s1) != len(s2):\n",
    "        return False\n",
    "    \n",
    "    # counting dict (or defaultdict())\n",
    "    count = {}    \n",
    "    \n",
    "        \n",
    "    # iterate over first string (ADD counts)\n",
    "    for letter in s1:\n",
    "        if letter in count:\n",
    "            count[letter] += 1\n",
    "        else:\n",
    "            count[letter] = 1\n",
    "            \n",
    "    # iterate over second string (SUBSTRACT counts)\n",
    "    for letter in s2:\n",
    "        if letter in count:\n",
    "            count[letter] -= 1\n",
    "        else:\n",
    "            count[letter] = 1\n",
    "    \n",
    "    # check if all are 0\n",
    "    for k in count:\n",
    "        if count[k] != 0:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "# group anagrams using sorting (time c. = NlogN)\n",
    "def group_anagrams(strings):\n",
    "    \n",
    "    dict_anagram,  res = {},  []\n",
    "    \n",
    "    idx = 0\n",
    "    for one_string in strings:\n",
    "        sorted_string = ''.join(sorted(one_string))\n",
    "        if sorted_string not in dict_anagram:\n",
    "            dict_anagram[sorted_string] = idx                              # dict value - index in a list of anagrams\n",
    "            idx += 1\n",
    "            res.append([])                                                       # create empty list in the end\n",
    "            res[-1].append(one_string)                                           # add anagram to it\n",
    "        else:\n",
    "            res[dict_anagram[sorted_string]].append(one_string)            # find correct list in big list and add\n",
    "                        \n",
    "    return res\n",
    "\n",
    "\n",
    "# group anagrams using linear-time anagram_check (time c. = O(n))\n",
    "def group_anagrams2(strings):\n",
    "    \n",
    "    dict_anagram,  res = {},  []    \n",
    "    \n",
    "    idx = 0\n",
    "    for one_string in strings:\n",
    "                \n",
    "        key_found = ''\n",
    "        for key in dict_anagram:                                                 # equivalent to \"if sorted_string in dict\"\n",
    "            if anagram_check2(key, one_string):\n",
    "                key_found = key\n",
    "                break            \n",
    "            \n",
    "        if not key_found:\n",
    "            dict_anagram[one_string] = idx                                       # dict value - index in a list of anagrams\n",
    "            idx += 1\n",
    "            res.append([])                                                       # create empty list in the end\n",
    "            res[-1].append(one_string)                                           # add anagram to it\n",
    "        else:\n",
    "            res[dict_anagram[key_found]].append(one_string)                      # find correct list in big list and add\n",
    "                        \n",
    "    return res\n",
    "\n",
    "\n",
    "strings = [\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"]\n",
    "group_anagrams(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer to Roman number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MMXX'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input in range(1, 3999)\n",
    "def int_to_roman(num):\n",
    "    \"\"\"\n",
    "    :type num: int\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    m = [\"\", \"M\", \"MM\", \"MMM\"];\n",
    "    c = [\"\", \"C\", \"CC\", \"CCC\", \"CD\", \"D\", \"DC\", \"DCC\", \"DCCC\", \"CM\"];\n",
    "    x = [\"\", \"X\", \"XX\", \"XXX\", \"XL\", \"L\", \"LX\", \"LXX\", \"LXXX\", \"XC\"];\n",
    "    i = [\"\", \"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\", \"VIII\", \"IX\"];\n",
    "    return m[num//1000] + c[(num%1000)//100] + x[(num%100)//10] + i[num%10]\n",
    "\n",
    "int_to_roman(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is Palindrome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Is a string a palindrome - ignore non letters and cases\n",
    "Example: 'A man, a plan, a canal: Panama' = True, 'race a car' = False\n",
    "Note: ask the interviewer about empty strings. Here an empty string is a valid palindrome\n",
    "\"\"\"\n",
    "from string import ascii_letters\n",
    "\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    \n",
    "    return \"\".join(i.lower() for i in s if i in ascii_letters)\n",
    "\n",
    "\n",
    "# O(n) solution\n",
    "def is_palindrome_two_pointers(s):\n",
    "    \n",
    "    i = 0\n",
    "    j = len(s)-1\n",
    "    while i < j:\n",
    "        while i < j and not s[i].isalnum():\n",
    "            i += 1\n",
    "        while i < j and not s[j].isalnum():\n",
    "            j -= 1\n",
    "        if s[i].lower() != s[j].lower():\n",
    "            return False\n",
    "        i, j = i+1, j-1\n",
    "                \n",
    "    return True\n",
    "\n",
    "\n",
    "# variation\n",
    "def is_palindrome_two_pointers2(s):\n",
    "    \n",
    "    s = remove_punctuation(s)\n",
    "    \n",
    "    for i in range(0, len(s)//2):\n",
    "        if (s[i] != s[len(s) - i - 1]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Compare with reverse (time c. O(n) because reversing is 2N with stack?)\n",
    "def is_palindrome_string_reverse(s):\n",
    "    \n",
    "    s = remove_punctuation(s).strip()\n",
    "    return s == s[::-1]\n",
    "\n",
    "\n",
    "# using stack\n",
    "def is_palindrome_stack(s):\n",
    "    \n",
    "    stack = []\n",
    "    s = remove_punctuation(s)\n",
    "\n",
    "    for i in range(len(s)//2, len(s)):\n",
    "        stack.append(s[i])\n",
    "    for i in range(0, len(s)//2):\n",
    "        if s[i] != stack.pop():\n",
    "            return False\n",
    "                \n",
    "    return True\n",
    "\n",
    "\n",
    "a = 'A man, a plan, a canal: Panama'\n",
    "b = 'race a car'\n",
    "\n",
    "print(is_palindrome_two_pointers(a))\n",
    "print(is_palindrome_two_pointers2(a))\n",
    "print(is_palindrome_string_reverse(a))\n",
    "print(is_palindrome_stack(a))\n",
    "\n",
    "print()\n",
    "\n",
    "print(is_palindrome_two_pointers(b))\n",
    "print(is_palindrome_two_pointers2(b))\n",
    "print(is_palindrome_string_reverse(b))\n",
    "print(is_palindrome_stack(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if syllables are rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_rotated(s1, s2):\n",
    "    if len(s1) == len(s2):\n",
    "        return s2 in s1 + s1\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "s1 = 'random'\n",
    "s2 = 'domran'\n",
    "\n",
    "is_rotated(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is isogram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Isogram = word or phrase w/out repeating letters\n",
    "def is_isogram(word):\n",
    "   \n",
    "    letter_list = []                                                         # empty list to append unique letters\n",
    "    for letter in word.lower():\n",
    "        \n",
    "        if letter.isalpha():                                                 # check letters only\n",
    "            if letter in letter_list:\n",
    "                return False\n",
    "            letter_list.append(letter)\n",
    "                        \n",
    "    return True\n",
    "\n",
    "s1 = 'abcdefg'\n",
    "s2 = 'abcbcdefg'\n",
    "\n",
    "print(is_isogram(s1))\n",
    "print(is_isogram(s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is circle?\n",
    "Robot is in position (0, 0) and makes moves R (Right), L (Left), U (Up) and D (down) encoded into a string. Determine if  the robot made a circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def is_circle(moves):\n",
    "    \n",
    "    moves = moves.upper()        \n",
    "    dict_moves = {  'U' : 0,\n",
    "                    'D' : 0,\n",
    "                    'R' : 0,\n",
    "                    'L' : 0  }\n",
    "        \n",
    "    for char in moves:\n",
    "        dict_moves[char] += 1\n",
    "                \n",
    "    return dict_moves['L'] == dict_moves['R'] and dict_moves['U'] == dict_moves['D']\n",
    "\n",
    "\n",
    "moves1 = 'lr'\n",
    "moves2 = 'lurd'\n",
    "moves3 = 'llluluuurdrdrdrd'\n",
    "moves4 = 'lrlrlrlrddddddudududud'\n",
    "\n",
    "for moves in [moves1, moves2, moves3, moves4]:\n",
    "    print(is_circle(moves))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash value of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99111109101032111110"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hash_value(string, base):\n",
    "    \"\"\"Calculate the hash value of a string using base.\n",
    "\n",
    "    Example: 'abc' = 97 x base^2 + 98 x base^1 + 99 x base^0\n",
    "    @param s string to compute hash value for\n",
    "    @param base base to use to compute hash value\n",
    "    @return hash value\n",
    "    \"\"\"\n",
    "    hash_value = 0\n",
    "    power = len(string)-1\n",
    "        \n",
    "    for i in range(len(string)):\n",
    "        hash_value += ord(string[i]) * (base ** power)\n",
    "        power -= 1\n",
    "\n",
    "    return hash_value\n",
    "\n",
    "\n",
    "hash_value('come on',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longest common prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how do you \n"
     ]
    }
   ],
   "source": [
    "def lcp(str1, str2): \n",
    "       \n",
    "    pos = 0                                                                    # index in str2 matching a prefix in str1\n",
    "      \n",
    "    while (len(str1) != 0): \n",
    "  \n",
    "        if str1 not in str2:           \n",
    "            str1 = str1[: len(str1) - 1]                                       # remove the last character \n",
    "        else:\n",
    "            pos = len(str1)                                                    # prefix found \n",
    "            break\n",
    "      \n",
    "    return str1[:pos]\n",
    "  \n",
    "\n",
    "str1 = \"how do you do\"\n",
    "str2 = \"how do you get there\" \n",
    "\n",
    "print(lcp(str1, str2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sentences with dictionary\n",
    "For a given string and a dictionary, how many sentences can you make from the string with all the words from the dictionary.  \n",
    "Example: \"applet\", {app, let, apple, t, applet} => 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def make_sentence(string, dictionaries):\n",
    "        \n",
    "    global count\n",
    "    if len(string) == 0:\n",
    "        return True\n",
    "        \n",
    "    for i in range(0, len(string) + 1):\n",
    "        prefix, suffix = string[0:i], string[i:]\n",
    "        if prefix in dictionaries:\n",
    "            if suffix in dictionaries or make_sentence(suffix, dictionaries):\n",
    "                count += 1\n",
    "                                \n",
    "    return True\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "string = \"applet\"\n",
    "dictionary = {'app', 'let', 'apple', 't', 'applet'}\n",
    "\n",
    "string = 'thing'\n",
    "dictionary = {'thing'}\n",
    "make_sentence(string, dictionary)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is pangram\n",
    "A __pangram__ or holoalphabetic sentence is a sentence using __every letter of a given alphabet at least once__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Naive\n",
    "def is_pangram(string):\n",
    "        \n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    for char in alphabet: \n",
    "        if char not in string.lower(): \n",
    "            return False\n",
    "  \n",
    "    return True\n",
    "\n",
    "\n",
    "my_string = 'the quick brown fox jumps over the lazy dog'\n",
    "print(is_pangram(my_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Using set and string module\n",
    "import string\n",
    "\n",
    "def is_pangram(string): \n",
    "    return set(string.lower()) >= alphabet \n",
    "\n",
    "\n",
    "alphabet = set(string.ascii_lowercase)\n",
    "my_string = \"The quick brown fox jumps over the lazy dog\"\n",
    "print(is_pangram(my_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String = multiple copies of substring?\n",
    "Given non-empty string - check if it is composed of multiple copies of one substring.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Input: \"abab\"  \n",
    "Output: True (\"ab\" twice)\n",
    "\n",
    "Input: \"aba\"  \n",
    "Output: False\n",
    "\n",
    "Input: \"abcabcabcabc\"  \n",
    "Output: True (\"abc\" four times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# cool trick!\n",
    "def repeat_substring(s):   \n",
    "    return s in (s + s)[1:-1]\n",
    "\n",
    "print(repeat_substring('abab'))\n",
    "print(repeat_substring('aba'))\n",
    "print(repeat_substring('abcabcabcabc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRIES from Geeksforgeeks - Top 10 algorithms in Interview Questions (Set 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Break (Famous Google Interview Question) - Trie Solution\n",
    "Can the input string can be segmented into a space-separated sequence of dictionary words - famous Google interview question.\n",
    "\n",
    "Dict: { i, like, sam, sung, samsung, mobile, ice, cream, icecream, man, go, mango}  \n",
    "Input string:  ilikesamsung    \n",
    "Output: Yes \n",
    "The string can be segmented as \"i like samsung\"\n",
    "\n",
    "Extending a DP array-based solution (no Python version) with tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n",
      "Yes\n",
      "Yes\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "class Solution(object): \n",
    "    def wordBreak(self, s, wordDict): \n",
    "        \"\"\" \n",
    "        Author : @amitrajitbose \n",
    "        :type s: str \n",
    "        :type wordDict: List[str] \n",
    "        :rtype: bool \n",
    "        \"\"\"\n",
    "        \"\"\"CREATING THE TRIE CLASS\"\"\"\n",
    "  \n",
    "        class TrieNode(object): \n",
    "              \n",
    "            def __init__(self): \n",
    "                self.children = [] #will be of size = 26 \n",
    "                self.isLeaf = False\n",
    "              \n",
    "            def getNode(self): \n",
    "                p = TrieNode() #new trie node \n",
    "                p.children = [] \n",
    "                for i in range(26): \n",
    "                    p.children.append(None) \n",
    "                p.isLeaf = False\n",
    "                return p \n",
    "              \n",
    "            def insert(self, root, key): \n",
    "                key = str(key) \n",
    "                pCrawl = root \n",
    "                for i in key: \n",
    "                    index = ord(i)-97\n",
    "                    if (pCrawl.children[index] == None): \n",
    "                        # node has to be initialised \n",
    "                        pCrawl.children[index] = self.getNode() \n",
    "                    pCrawl = pCrawl.children[index] \n",
    "                pCrawl.isLeaf = True #marking end of word \n",
    "              \n",
    "            def search(self, root, key): \n",
    "                #print(\"Searching %s\" %key) #DEBUG \n",
    "                pCrawl = root \n",
    "                for i in key: \n",
    "                    index = ord(i)-97\n",
    "                    if (pCrawl.children[index] == None): \n",
    "                        return False\n",
    "                    pCrawl = pCrawl.children[index] \n",
    "                if (pCrawl and pCrawl.isLeaf): \n",
    "                    return True\n",
    "          \n",
    "        def checkWordBreak(strr, root):\n",
    "                        \n",
    "            n = len(strr) \n",
    "            if (n == 0): \n",
    "                return True\n",
    "            for i in range(1,n+1): \n",
    "                if (root.search(root, strr[:i]) and checkWordBreak(strr[i:], root)): \n",
    "                    return True\n",
    "            return False\n",
    "          \n",
    "        \"\"\"IMPLEMENT SOLUTION\"\"\"\n",
    "        root = TrieNode().getNode() \n",
    "        for w in wordDict: \n",
    "            root.insert(root, w) \n",
    "        out = checkWordBreak(s, root) \n",
    "        if(out): \n",
    "            return \"Yes\"\n",
    "        else: \n",
    "            return \"No\"\n",
    "\n",
    "print(Solution().wordBreak(\"thequickbrownfox\", [\"the\", \"quick\", \"fox\", \"brown\"])) \n",
    "print(Solution().wordBreak(\"bedbathandbeyond\", [\"bed\", \"bath\", \"bedbath\", \"and\", \"beyond\"])) \n",
    "print(Solution().wordBreak(\"bedbathandbeyond\", [\"teddy\", \"bath\", \"bedbath\", \"and\", \"beyond\"])) \n",
    "print(Solution().wordBreak(\"bedbathandbeyond\", [\"bed\", \"bath\", \"bedbath\", \"and\", \"away\"])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longest Common Prefix using Trie (see above for word- and char-based solutions)\n",
    "* Insert all the words one by one in the trie\n",
    "* Walk the trie by going deeper until we find a node having more than 1 child (branching) or 0 children (a string gets exhausted). This is because the chars (nodes in trie) which are present in the longest common prefix must be the single child of its parent, i.e. no branching in any of these nodes\n",
    "\n",
    "\n",
    "Time c.: inserting all the words in the trie O(MN) time; performing a walk O(M) where N = # chars in strings & M = length of largest string  \n",
    "Space c. O(26*M*N) ~ O(MN) to store all strings in trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gee\n"
     ]
    }
   ],
   "source": [
    "ALPHABET_SIZE = 26\n",
    "indexs = 0\n",
    "class TrieNode: \n",
    "     \n",
    "    def __init__(self): \n",
    "        self.isLeaf = False\n",
    "        self.children = [None]*ALPHABET_SIZE \n",
    "\n",
    "# if not present, insert the node in the Trie \n",
    "def insert(key, root): \n",
    "    pCrawl = root \n",
    "    for level in range(len(key)): \n",
    "        index = ord(key[level]) - ord('a') \n",
    "        if pCrawl.children[index] == None: \n",
    "            pCrawl.children[index] = TrieNode() \n",
    "        pCrawl = pCrawl.children[index] \n",
    "    pCrawl.isLeaf = True\n",
    "\n",
    "# construct trie \n",
    "def constructTrie(arr, n, root): \n",
    "    for i in range(n): \n",
    "        insert(arr[i], root) \n",
    "\n",
    "# Counts and returns number of children of the node \n",
    "def countChildren(node): \n",
    "    count = 0\n",
    "    for i in range(ALPHABET_SIZE): \n",
    "        if node.children[i] != None: \n",
    "            count +=1\n",
    "            # Keeping track of diversion in the trie \n",
    "            global indexs \n",
    "            indexs = i \n",
    "    return count \n",
    "      \n",
    "# Perform walk on trie and return longest common prefix  \n",
    "def walkTrie(root): \n",
    "    pCrawl = root \n",
    "    prefix = \"\" \n",
    "    while(countChildren(pCrawl) == 1 and pCrawl.isLeaf == False): \n",
    "        pCrawl = pCrawl.children[indexs] \n",
    "        prefix += chr(97 + indexs) \n",
    "    return prefix or -1\n",
    "  \n",
    "# Function that returns longest common prefix  \n",
    "def commonPrefix(arr, n, root): \n",
    "    constructTrie(arr, n, root) \n",
    "    return walkTrie(root) \n",
    "  \n",
    "# Driver code to test the code \n",
    "n = 4\n",
    "arr = [\"geeksforgeeks\", \"geeks\", \"geek\", \"geezer\"] \n",
    "root = TrieNode() \n",
    "print(commonPrefix(arr,n, root)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trie (Insert and Search)\n",
    "Trie is an efficient information reTrieval data structure. Using Trie, search complexities can be brought to optimal limit (key length). If we store keys in binary search tree, a well balanced BST will need time proportional to M * log N, where M is maximum string length and N is number of keys in tree. Using Trie, we can search the key in O(M) time. However the penalty is on Trie storage requirements\n",
    "\n",
    "Every node of Trie consists of multiple branches. Each branch represents a possible character of keys. We need to mark the last node of every key as end of word node. A Trie node field isEndOfWord is used to distinguish the node as end of word node\n",
    "\n",
    "Inserting a key into Trie is a simple approach. Every character of the input key is inserted as an individual Trie node. Note that the children is an array of pointers (or references) to next level trie nodes. The key character acts as an index into the array children. If the input key is new or an extension of the existing key, we need to construct non-existing nodes of the key, and mark end of the word for the last node. If the input key is a prefix of the existing key in Trie, we simply mark the last node of the key as the end of a word. The key length determines Trie depth\n",
    "\n",
    "Searching for a key is similar to insert operation, however, we only compare the characters and move down. The search can terminate due to the end of a string or lack of key in the trie. In the former case, if the isEndofWord field of the last node is true, then the key exists in the trie. In the second case, the search terminates without examining all the characters of the key, since the key is not present in the trie.\n",
    "\n",
    "The following picture explains construction of trie using keys given in the example below\n",
    "\n",
    "In the picture, every character is of type trie_node_t. For example, the root is of type trie_node_t, and it’s children a, b and t are filled, all other nodes of root will be NULL. Similarly, “a” at the next level is having only one child (“n”), all other children are NULL. The leaf nodes are in blue.\n",
    "\n",
    "Recommended: Please solve it on “PRACTICE” first, before moving on to the solution.\n",
    "Insert and search costs O(key_length), however the memory requirements of Trie is O(ALPHABET_SIZE * key_length * N) where N is number of keys in Trie. There are efficient representation of trie nodes (e.g. compressed trie, ternary search tree, etc.) to minimize memory requirements of trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "'''\n",
    "                       root\n",
    "                    /   \\    \\\n",
    "                    t   a     b\n",
    "                    |   |     |\n",
    "                    h   n     y\n",
    "                    |   |  \\  |\n",
    "                    e   s  y  e\n",
    "                 /  |   |\n",
    "                 i  r   w\n",
    "                 |  |   |\n",
    "                 r  e   e\n",
    "                        |\n",
    "                        r\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the ---- Present in trie\n",
      "these ---- Not present in trie\n",
      "their ---- Present in trie\n",
      "thaw ---- Not present in trie\n"
     ]
    }
   ],
   "source": [
    "# Python program for insert and search \n",
    "# operation in a Trie \n",
    "\n",
    "class TrieNode: \n",
    "\n",
    "    # Trie node class \n",
    "    def __init__(self): \n",
    "        self.children = [None]*26\n",
    "  \n",
    "        # isEndOfWord is True if node represent the end of the word \n",
    "        self.isEndOfWord = False\n",
    "\n",
    "class Trie:\n",
    "\n",
    "    # Trie data structure class \n",
    "    def __init__(self): \n",
    "        self.root = self.getNode() \n",
    "  \n",
    "    def getNode(self): \n",
    "      \n",
    "        # Returns new trie node (initialized to NULLs) \n",
    "        return TrieNode() \n",
    "  \n",
    "    def _charToIndex(self,ch): \n",
    "          \n",
    "        # private helper function \n",
    "        # Converts key current character into index \n",
    "        # use only 'a' through 'z' and lower case \n",
    "          \n",
    "        return ord(ch)-ord('a') \n",
    "\n",
    "  \n",
    "    def insert(self,key): \n",
    "          \n",
    "        # If not present, inserts key into trie \n",
    "        # If the key is prefix of trie node,  \n",
    "        # just marks leaf node \n",
    "        pCrawl = self.root \n",
    "        length = len(key) \n",
    "        for level in range(length): \n",
    "            index = self._charToIndex(key[level]) \n",
    "  \n",
    "            # if current character is not present \n",
    "            if not pCrawl.children[index]: \n",
    "                pCrawl.children[index] = self.getNode() \n",
    "            pCrawl = pCrawl.children[index] \n",
    "  \n",
    "        # mark last node as leaf \n",
    "        pCrawl.isEndOfWord = True\n",
    "  \n",
    "    def search(self, key): \n",
    "          \n",
    "        # Search key in the trie \n",
    "        # Returns true if key presents  \n",
    "        # in trie, else false \n",
    "        pCrawl = self.root \n",
    "        length = len(key) \n",
    "        for level in range(length): \n",
    "            index = self._charToIndex(key[level]) \n",
    "            if not pCrawl.children[index]: \n",
    "                return False\n",
    "            pCrawl = pCrawl.children[index] \n",
    "  \n",
    "        return pCrawl != None and pCrawl.isEndOfWord \n",
    "  \n",
    "# driver function \n",
    "def main(): \n",
    "  \n",
    "    # Input keys (use only 'a' through 'z' and lower case) \n",
    "    keys = [\"the\",\"a\",\"there\",\"anaswe\",\"any\", \n",
    "            \"by\",\"their\"] \n",
    "    output = [\"Not present in trie\", \n",
    "              \"Present in trie\"] \n",
    "  \n",
    "    # Trie object \n",
    "    t = Trie() \n",
    "  \n",
    "    # Construct trie \n",
    "    for key in keys: \n",
    "        t.insert(key) \n",
    "  \n",
    "    # Search for different keys \n",
    "    print(\"{} ---- {}\".format(\"the\",output[t.search(\"the\")])) \n",
    "    print(\"{} ---- {}\".format(\"these\",output[t.search(\"these\")])) \n",
    "    print(\"{} ---- {}\".format(\"their\",output[t.search(\"their\")])) \n",
    "    print(\"{} ---- {}\".format(\"thaw\",output[t.search(\"thaw\")])) \n",
    "\n",
    "if __name__ == '__main__': \n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-complete feature using Trie\n",
    "Given trie and a prefix typed in the search query, provide all auto-complete recommendations (trie stores past searches)\n",
    "\n",
    "Example: {“abc”, “abcd”, “aa”, “abbbaba”}, user types “ab”, output = {“abc”, “abcd”, “abbbaba”}.\n",
    "\n",
    "Prerequisite Trie Search and Insert\n",
    "\n",
    "* Search for given query using standard Trie search algorithm.\n",
    "* If query prefix itself is not present, return -1 to indicate the same.\n",
    "* If query is present and is end of word in Trie, print query. This can quickly checked by seeing if last matching node has isEndWord flag set. We use this flag in Trie to mark end of word nodes for purpose of searching.\n",
    "* If last matching node of query has no children, return.\n",
    "* Else recursively print all nodes under subtree of last matching node\n",
    "\n",
    "__Improvements__  \n",
    "The number of matches might just be too large so we have to be selective while displaying them. We can restrict ourselves to display only the relevant results. By relevant, we can consider the past search history and show only the most searched matching strings as relevant results.  \n",
    "Store another value for the each node where isleaf=True which contains the number of hits for that query search. For example if “hat” is searched 10 times, then we store this 10 at the last node for “hat”. Now when we want to show the recommendations, we display the top k matches with the highest hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "help\n",
      "helps\n",
      "helping\n"
     ]
    }
   ],
   "source": [
    "# Python3 program to demonstrate auto-complete  \n",
    "# feature using Trie data structure. \n",
    "# Note: This is a basic implementation of Trie \n",
    "# and not the most optimized one. \n",
    "class TrieNode(): \n",
    "    def __init__(self): \n",
    "          \n",
    "        # Initialising one node for trie \n",
    "        self.children = {} \n",
    "        self.last = False\n",
    "\n",
    "class Trie(): \n",
    "    def __init__(self): \n",
    "          \n",
    "        # Initialising the trie structure. \n",
    "        self.root = TrieNode() \n",
    "        self.word_list = [] \n",
    "  \n",
    "    def formTrie(self, keys): \n",
    "          \n",
    "        # Forms a trie structure with the given set of strings \n",
    "        # if it does not exists already else it merges the key \n",
    "        # into it by extending the structure as required \n",
    "        for key in keys: \n",
    "            self.insert(key) # inserting one key to the trie. \n",
    "  \n",
    "    def insert(self, key): \n",
    "          \n",
    "        # Inserts a key into trie if it does not exist already. \n",
    "        # And if the key is a prefix of the trie node, just  \n",
    "        # marks it as leaf node. \n",
    "        node = self.root \n",
    "  \n",
    "        for a in list(key): \n",
    "            if not node.children.get(a): \n",
    "                node.children[a] = TrieNode() \n",
    "  \n",
    "            node = node.children[a] \n",
    "  \n",
    "        node.last = True\n",
    "  \n",
    "    def search(self, key): \n",
    "          \n",
    "        # Searches the given key in trie for a full match \n",
    "        # and returns True on success else returns False. \n",
    "        node = self.root \n",
    "        found = True\n",
    "  \n",
    "        for a in list(key): \n",
    "            if not node.children.get(a): \n",
    "                found = False\n",
    "                break\n",
    "  \n",
    "            node = node.children[a] \n",
    "  \n",
    "        return node and node.last and found \n",
    "  \n",
    "    def suggestionsRec(self, node, word): \n",
    "          \n",
    "        # Method to recursively traverse the trie \n",
    "        # and return a whole word.  \n",
    "        if node.last: \n",
    "            self.word_list.append(word) \n",
    "  \n",
    "        for a,n in node.children.items(): \n",
    "            self.suggestionsRec(n, word + a) \n",
    "  \n",
    "    def printAutoSuggestions(self, key): \n",
    "          \n",
    "        # Returns all the words in the trie whose common \n",
    "        # prefix is the given key thus listing out all  \n",
    "        # the suggestions for autocomplete. \n",
    "        node = self.root \n",
    "        not_found = False\n",
    "        temp_word = '' \n",
    "  \n",
    "        for a in list(key): \n",
    "            if not node.children.get(a): \n",
    "                not_found = True\n",
    "                break\n",
    "  \n",
    "            temp_word += a \n",
    "            node = node.children[a] \n",
    "  \n",
    "        if not_found: \n",
    "            return 0\n",
    "        elif node.last and not node.children: \n",
    "            return -1\n",
    "  \n",
    "        self.suggestionsRec(node, temp_word) \n",
    "  \n",
    "        for s in self.word_list: \n",
    "            print(s) \n",
    "        return 1\n",
    "    \n",
    "    \n",
    "keys = [\"dog\", \"cat\", \"a\", \"over\", \"help\", \"helps\", \"helping\"]                     # past searches\n",
    "key = \"help\"                                                                       # key for autocomplete suggestions\n",
    "status = [\"Not found\", \"Found\"] \n",
    "  \n",
    "# create trie object \n",
    "t = Trie() \n",
    "  \n",
    "# creating the trie structure with the  \n",
    "# given set of strings. \n",
    "t.formTrie(keys) \n",
    "  \n",
    "# autocompleting the given key using  \n",
    "# our trie structure. \n",
    "comp = t.printAutoSuggestions(key) \n",
    "  \n",
    "if comp == -1: \n",
    "    print(\"No other strings found with this prefix\\n\") \n",
    "elif comp == 0: \n",
    "    print(\"No string found with this prefix\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A Trie/Prefix Tree is a kind of search tree used to provide quick lookup\n",
    "of words/patterns in a set of words. A basic Trie however has O(n^2) space complexity\n",
    "making it impractical in practice. It however provides O(max(search_string, length of longest word)) lookup\n",
    "time making it an optimal approach when space is not an issue.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.nodes = dict()  # Mapping from char to TrieNode\n",
    "        self.is_leaf = False\n",
    "\n",
    "    def insert_many(self, words: [str]):  # noqa: E999 This syntax is Python 3 only\n",
    "        \"\"\"\n",
    "        Inserts a list of words into the Trie\n",
    "        :param words: list of string words\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        for word in words:\n",
    "            self.insert(word)\n",
    "\n",
    "    def insert(self, word: str):  # noqa: E999 This syntax is Python 3 only\n",
    "        \"\"\"\n",
    "        Inserts a word into the Trie\n",
    "        :param word: word to be inserted\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        curr = self\n",
    "        for char in word:\n",
    "            if char not in curr.nodes:\n",
    "                curr.nodes[char] = TrieNode()\n",
    "            curr = curr.nodes[char]\n",
    "        curr.is_leaf = True\n",
    "\n",
    "    def find(self, word: str) -> bool:  # noqa: E999 This syntax is Python 3 only\n",
    "        \"\"\"\n",
    "        Tries to find word in a Trie\n",
    "        :param word: word to look for\n",
    "        :return: Returns True if word is found, False otherwise\n",
    "        \"\"\"\n",
    "        curr = self\n",
    "        for char in word:\n",
    "            if char not in curr.nodes:\n",
    "                return False\n",
    "            curr = curr.nodes[char]\n",
    "        return curr.is_leaf\n",
    "\n",
    "\n",
    "def print_words(node: TrieNode, word: str):  # noqa: E999 This syntax is Python 3 only\n",
    "    \"\"\"\n",
    "    Prints all the words in a Trie\n",
    "    :param node: root node of Trie\n",
    "    :param word: Word variable should be empty at start\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if node.is_leaf:\n",
    "        print(word, end=' ')\n",
    "\n",
    "    for key, value in node.nodes.items():\n",
    "        print_words(value, word + key)\n",
    "\n",
    "\n",
    "def test():\n",
    "    words = ['banana', 'bananas', 'bandana', 'band', 'apple', 'all', 'beast']\n",
    "    root = TrieNode()\n",
    "    root.insert_many(words)\n",
    "    # print_words(root, '')\n",
    "    assert root.find('banana')\n",
    "    assert not root.find('bandanas')\n",
    "    assert not root.find('apps')\n",
    "    assert root.find('apple')\n",
    "\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other algorithms to find a substring in a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knuth-Morris-Pratt Algorithm - returns first found match only\n",
    "def kmp1(pattern, text):\n",
    "    \n",
    "    # preprocess pattern\n",
    "    prefix_array = get_prefix_array(pattern)\n",
    "    print('Pattern {}: array {}'.format(pattern, prefix_array))\n",
    "\n",
    "    # iterate over text\n",
    "    i, j = 0, 0                                                                # index in text, pattern\n",
    "    while i < len(text):\n",
    "        if pattern[j] == text[i]:\n",
    "            if j == (len(pattern) - 1):\n",
    "                return True\n",
    "            j += 1\n",
    "        \n",
    "        elif j > 0:                                                            # if this is prefix in pattern, go back\n",
    "            j = prefix_array[j - 1]\n",
    "            continue\n",
    "        i += 1\n",
    "                \n",
    "    return False\n",
    "\n",
    "\n",
    "# calculate new idx we should go to if comparison fails\n",
    "def get_prefix_array(pattern):\n",
    "    \n",
    "    prefix = [0]\n",
    "    i = 0\n",
    "    j = 1\n",
    "    while j < len(pattern):                                 # Pattern AAAB: array [0, 1, 2, 0]\n",
    "        if pattern[i] == pattern[j]:                        # i,j,[]:  0,1,[0]  1,2,[0,1]  2,3[0,1,2] 1,3[0,1,2]  0,4[0,1,2,0]\n",
    "            i += 1\n",
    "        elif i > 0:\n",
    "            i = prefix[i-1]\n",
    "            continue\n",
    "        j += 1\n",
    "        prefix.append(i)\n",
    "    return prefix\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "# Test 1)\n",
    "pattern = \"abc1abc12\"\n",
    "text1 = \"alskfjaldsabc1abc1abc12k23adsfabcabc\"\n",
    "text2 = \"alskfjaldsk23adsfabcabc\"\n",
    "print(kmp(pattern, text1))\n",
    "print(kmp(pattern, text2))\n",
    "\n",
    "# Test 2)\n",
    "pattern = \"ABABX\"\n",
    "text = \"ABABZABABYABABX\"\n",
    "print(kmp(pattern, text))\n",
    "\n",
    "# Test 3)\n",
    "pattern = \"AAAB\"\n",
    "text = \"ABAAAAAB\"\n",
    "print(kmp(pattern, text))\n",
    "\n",
    "# Test 4)\n",
    "pattern = \"abcdabcy\"\n",
    "text = \"abcxabcdabxabcdabcdabcy\"\n",
    "print(kmp(pattern, text))\n",
    "\n",
    "# Test 5)\n",
    "pattern = \"aaab\"\n",
    "get_prefix_array(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_matching_naive(text='', pattern=''):\n",
    "    \"\"\"Returns positions where pattern is found in text.\n",
    "\n",
    "    We slide the string to match 'pattern' over the text\n",
    "\n",
    "    O((n-m)m)\n",
    "    Example: text = 'ababbababa', pattern = 'aba'\n",
    "                     string_matching_naive(t, s) returns [0, 5, 7]\n",
    "    @param text text to search inside\n",
    "    @param pattern string to search for\n",
    "    @return list containing offsets (shifts) where pattern is found inside text\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(text)\n",
    "    m = len(pattern)\n",
    "    offsets = []\n",
    "    for i in range(n-m+1):\n",
    "        if pattern == text[i:i+m]:\n",
    "            offsets.append(i)\n",
    "\n",
    "    return offsets\n",
    "\n",
    "\n",
    "def string_matching_rabin_karp(text='', pattern='', hash_base=256):\n",
    "    \"\"\"Returns positions where pattern is found in text.\n",
    "\n",
    "    worst case: O(nm)\n",
    "    O(n+m) if the number of valid matches is small and the pattern is large.\n",
    "\n",
    "    Performance: ord() is slow so we shouldn't use it here\n",
    "\n",
    "    Example: text = 'ababbababa', pattern = 'aba'\n",
    "             string_matching_rabin_karp(text, pattern) returns [0, 5, 7]\n",
    "    @param text text to search inside\n",
    "    @param pattern string to search for\n",
    "    @param hash_base base to calculate the hash value\n",
    "    @return list containing offsets (shifts) where pattern is found inside text\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(text)\n",
    "    m = len(pattern)\n",
    "    offsets = []\n",
    "    htext = hash_value(text[:m], hash_base)\n",
    "    hpattern = hash_value(pattern, hash_base)\n",
    "    for i in range(n-m+1):\n",
    "        if htext == hpattern:\n",
    "            if text[i:i+m] == pattern:\n",
    "                offsets.append(i)\n",
    "        if i < n-m:\n",
    "            htext = (hash_base *\n",
    "                     (htext -\n",
    "                      (ord(text[i]) *\n",
    "                       (hash_base ** (m-1))))) + ord(text[i+m])\n",
    "\n",
    "    return offsets\n",
    "\n",
    "\n",
    "def string_matching_boyer_moore_horspool(text='', pattern=''):\n",
    "    \"\"\"Returns positions where pattern is found in text.\n",
    "\n",
    "    O(n)\n",
    "    Performance: ord() is slow so we shouldn't use it here\n",
    "\n",
    "    Example: text = 'ababbababa', pattern = 'aba'\n",
    "         string_matching_boyer_moore_horspool(text, pattern) returns [0, 5, 7]\n",
    "    @param text text to search inside\n",
    "    @param pattern string to search for\n",
    "    @return list containing offsets (shifts) where pattern is found inside text\n",
    "    \"\"\"\n",
    "    m = len(pattern)\n",
    "    n = len(text)\n",
    "    offsets = []\n",
    "    if m > n:\n",
    "        return offsets\n",
    "    skip = []\n",
    "    for k in range(256):\n",
    "        skip.append(m)\n",
    "    for k in range(m-1):\n",
    "        skip[ord(pattern[k])] = m - k - 1\n",
    "    skip = tuple(skip)\n",
    "    k = m - 1\n",
    "    while k < n:\n",
    "        j = m - 1\n",
    "        i = k\n",
    "        while j >= 0 and text[i] == pattern[j]:\n",
    "            j -= 1\n",
    "            i -= 1\n",
    "        if j == -1:\n",
    "            offsets.append(i + 1)\n",
    "        k += skip[ord(text[k])]\n",
    "\n",
    "    return offsets\n",
    "\n",
    "\n",
    "def atoi(s):\n",
    "    \"\"\"Convert string to integer without doing int(s).\n",
    "\n",
    "    '123' -> 123\n",
    "    @param s string to convert.\n",
    "    @returns integer\n",
    "    \"\"\"\n",
    "    if not s:\n",
    "        raise ValueError\n",
    "    i = 0\n",
    "    idx = 0\n",
    "    neg = False\n",
    "    if s[0] == '-':\n",
    "        neg = True\n",
    "        idx += 1\n",
    "\n",
    "    for c in s[idx:]:\n",
    "        i *= 10\n",
    "        i += int(c)\n",
    "\n",
    "    if neg:\n",
    "        i = -i\n",
    "\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following program is the python implementation of\n",
    "# Rabin Karp Algorithm\n",
    "\n",
    "class RollingHash:\n",
    "    def __init__(self, text, size_word):\n",
    "        self.text = text\n",
    "        self.hash = 0\n",
    "        self.size_word = size_word\n",
    "\n",
    "        for i in range(0, size_word):\n",
    "            #ord maps the character to a number\n",
    "            #subtract out the ASCII value of \"a\" to start the indexing at zero\n",
    "            self.hash += (ord(self.text[i]) - ord(\"a\")+1)*(26**(size_word - i -1))\n",
    "\n",
    "        #start index of current window\n",
    "        self.window_start = 0\n",
    "        #end of index window\n",
    "        self.window_end = size_word\n",
    "\n",
    "    def move_window(self):\n",
    "        if self.window_end <= len(self.text) - 1:\n",
    "            #remove left letter from hash value\n",
    "            self.hash -= (ord(self.text[self.window_start]) - ord(\"a\")+1)*26**(self.size_word-1)\n",
    "            self.hash *= 26\n",
    "            self.hash += ord(self.text[self.window_end])- ord(\"a\")+1\n",
    "            self.window_start += 1\n",
    "            self.window_end += 1\n",
    "\n",
    "    def window_text(self):\n",
    "        return self.text[self.window_start:self.window_end]\n",
    "\n",
    "def rabin_karp(word, text):\n",
    "    if word == \"\" or text == \"\":\n",
    "        return None\n",
    "    if len(word) > len(text):\n",
    "        return None\n",
    "\n",
    "    rolling_hash = RollingHash(text, len(word))\n",
    "    word_hash = RollingHash(word, len(word))\n",
    "    #word_hash.move_window()\n",
    "\n",
    "    for i in range(len(text) - len(word) + 1):\n",
    "        if rolling_hash.hash == word_hash.hash:\n",
    "            if rolling_hash.window_text() == word:\n",
    "                return i\n",
    "        rolling_hash.move_window()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rabin_karp(pattern, text):\n",
    "    \"\"\"\n",
    "\n",
    "    The Rabin-Karp Algorithm for finding a pattern within a piece of text\n",
    "    with complexity O(nm), most efficient when it is used with multiple patterns\n",
    "    as it is able to check if any of a set of patterns match a section of text in o(1) given the precomputed hashes.\n",
    "\n",
    "    This will be the simple version which only assumes one pattern is being searched for but it's not hard to modify\n",
    "\n",
    "    1) Calculate pattern hash\n",
    "\n",
    "    2) Step through the text one character at a time passing a window with the same length as the pattern\n",
    "        calculating the hash of the text within the window compare it with the hash of the pattern. Only testing\n",
    "        equality if the hashes match\n",
    "\n",
    "    \"\"\"\n",
    "    p_len = len(pattern)\n",
    "    p_hash = hash(pattern)\n",
    "\n",
    "    for i in range(0, len(text) - (p_len - 1)):\n",
    "\n",
    "        # written like this t\n",
    "        text_hash = hash(text[i:i + p_len])\n",
    "        if text_hash == p_hash and \\\n",
    "                text[i:i + p_len] == pattern:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Test 1)\n",
    "    pattern = \"abc1abc12\"\n",
    "    text1 = \"alskfjaldsabc1abc1abc12k23adsfabcabc\"\n",
    "    text2 = \"alskfjaldsk23adsfabcabc\"\n",
    "    assert rabin_karp(pattern, text1) and not rabin_karp(pattern, text2)\n",
    "\n",
    "    # Test 2)\n",
    "    pattern = \"ABABX\"\n",
    "    text = \"ABABZABABYABABX\"\n",
    "    assert rabin_karp(pattern, text)\n",
    "\n",
    "    # Test 3)\n",
    "    pattern = \"AAAB\"\n",
    "    text = \"ABAAAAAB\"\n",
    "    assert rabin_karp(pattern, text)\n",
    "\n",
    "    # Test 4)\n",
    "    pattern = \"abcdabcy\"\n",
    "    text = \"abcxabcdabxabcdabcdabcy\"\n",
    "    assert rabin_karp(pattern, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a set of words (without duplicates),\n",
    "# find all word squares you can build from them.\n",
    "\n",
    "# A sequence of words forms a valid word square\n",
    "# if the kth row and column read the exact same string,\n",
    "# where 0 ≤ k < max(numRows, numColumns).\n",
    "\n",
    "# For example, the word sequence [\"ball\",\"area\",\"lead\",\"lady\"] forms\n",
    "# a word square because each word reads the same both horizontally\n",
    "# and vertically.\n",
    "\n",
    "# b a l l\n",
    "# a r e a\n",
    "# l e a d\n",
    "# l a d y\n",
    "# Note:\n",
    "# There are at least 1 and at most 1000 words.\n",
    "# All words will have the exact same length.\n",
    "# Word length is at least 1 and at most 5.\n",
    "# Each word contains only lowercase English alphabet a-z.\n",
    "\n",
    "# Example 1:\n",
    "\n",
    "# Input:\n",
    "# [\"area\",\"lead\",\"wall\",\"lady\",\"ball\"]\n",
    "\n",
    "# Output:\n",
    "# [\n",
    "  # [ \"wall\",\n",
    "    # \"area\",\n",
    "    # \"lead\",\n",
    "    # \"lady\"\n",
    "  # ],\n",
    "  # [ \"ball\",\n",
    "    # \"area\",\n",
    "    # \"lead\",\n",
    "    # \"lady\"\n",
    "  # ]\n",
    "# ]\n",
    "\n",
    "# Explanation:\n",
    "# The output consists of two word squares. The order of output does not matter\n",
    "# (just the order of words in each word square matters).\n",
    "\n",
    "import collections\n",
    "\n",
    "def word_squares(words):\n",
    "    n = len(words[0])\n",
    "    fulls = collections.defaultdict(list)\n",
    "    for word in words:\n",
    "        for i in range(n):\n",
    "            fulls[word[:i]].append(word)\n",
    "\n",
    "    def build(square):\n",
    "        if len(square) == n:\n",
    "            squares.append(square)\n",
    "            return\n",
    "        prefix = \"\"\n",
    "        for k in range(len(square)):\n",
    "            prefix += square[k][len(square)]\n",
    "        for word in fulls[prefix]:\n",
    "            build(square + [word])\n",
    "    squares = []\n",
    "    for word in words:\n",
    "        build([word])\n",
    "    return squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morse code transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "International Morse Code defines a standard encoding where each letter is mapped to\n",
    "a series of dots and dashes, as follows: \"a\" maps to \".-\", \"b\" maps to \"-...\", \"c\"\n",
    "maps to \"-.-.\", and so on.\n",
    "\n",
    "For convenience, the full table for the 26 letters of the English alphabet is given below:\n",
    "        'a':\".-\",\n",
    "        'b':\"-...\",\n",
    "        'c':\"-.-.\",\n",
    "        'd': \"-..\",\n",
    "        'e':\".\",\n",
    "        'f':\"..-.\",\n",
    "        'g':\"--.\",\n",
    "        'h':\"....\",\n",
    "        'i':\"..\",\n",
    "        'j':\".---\",\n",
    "        'k':\"-.-\",\n",
    "        'l':\".-..\",\n",
    "        'm':\"--\",\n",
    "        'n':\"-.\",\n",
    "        'o':\"---\",\n",
    "        'p':\".--.\",\n",
    "        'q':\"--.-\",\n",
    "        'r':\".-.\",\n",
    "        's':\"...\",\n",
    "        't':\"-\",\n",
    "        'u':\"..-\",\n",
    "        'v':\"...-\",\n",
    "        'w':\".--\",\n",
    "        'x':\"-..-\",\n",
    "        'y':\"-.--\",\n",
    "        'z':\"--..\"\n",
    "\n",
    "Now, given a list of words, each word can be written as a concatenation of the\n",
    "Morse code of each letter. For example, \"cab\" can be written as \"-.-.-....-\",\n",
    "(which is the concatenation \"-.-.\" + \"-...\" + \".-\"). We'll call such a\n",
    "concatenation, the transformation of a word.\n",
    "\n",
    "Return the number of different transformations among all words we have.\n",
    "Example:\n",
    "Input: words = [\"gin\", \"zen\", \"gig\", \"msg\"]\n",
    "Output: 2\n",
    "Explanation:\n",
    "The transformation of each word is:\n",
    "\"gin\" -> \"--...-.\"\n",
    "\"zen\" -> \"--...-.\"\n",
    "\"gig\" -> \"--...--.\"\n",
    "\"msg\" -> \"--...--.\"\n",
    "\n",
    "There are 2 different transformations, \"--...-.\" and \"--...--.\".\n",
    "\"\"\"\n",
    "\n",
    "morse_code = {\n",
    "    'a':\".-\",\n",
    "    'b':\"-...\",\n",
    "    'c':\"-.-.\",\n",
    "    'd': \"-..\",\n",
    "    'e':\".\",\n",
    "    'f':\"..-.\",\n",
    "    'g':\"--.\",\n",
    "    'h':\"....\",\n",
    "    'i':\"..\",\n",
    "    'j':\".---\",\n",
    "    'k':\"-.-\",\n",
    "    'l':\".-..\",\n",
    "    'm':\"--\",\n",
    "    'n':\"-.\",\n",
    "    'o':\"---\",\n",
    "    'p':\".--.\",\n",
    "    'q':\"--.-\",\n",
    "    'r':\".-.\",\n",
    "    's':\"...\",\n",
    "    't':\"-\",\n",
    "    'u':\"..-\",\n",
    "    'v':\"...-\",\n",
    "    'w':\".--\",\n",
    "    'x':\"-..-\",\n",
    "    'y':\"-.--\",\n",
    "    'z':\"--..\"\n",
    "}\n",
    "def convert_morse_word(word):\n",
    "    morse_word = \"\"\n",
    "    word = word.lower()\n",
    "    for char in word:\n",
    "        morse_word = morse_word + morse_code[char]\n",
    "    return morse_word\n",
    "\n",
    "def unique_morse(words):\n",
    "    unique_morse_word = []\n",
    "    for word in words:\n",
    "        morse_word = convert_morse_word(word)\n",
    "        if morse_word not in unique_morse_word:\n",
    "            unique_morse_word.append(morse_word)\n",
    "    return len(unique_morse_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
