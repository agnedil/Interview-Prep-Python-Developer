{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL w/CV\n",
    "* [Source for this notebook](https://www.machinecurve.com/index.php/2020/02/18/how-to-use-k-fold-cross-validation-with-keras/)\n",
    "* [TIME SERIES FORCASTING WITH TENSORFLOW FROM THE AUTHORS!](https://www.tensorflow.org/tutorials/structured_data/time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.metrics import mean_squared_error as mse\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Bidirectional, LSTM, Dropout, ConvLSTM2D, Flatten, TimeDistributed, RepeatVector\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import Adam\n",
    "from helper import ( prepare_data, train_test_shuffle_split, train_test_seq_split, print_folds_stats )\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')     # 'fivethirtyeight'\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "#mae = tf.keras.losses.MeanAbsoluteError()\n",
    "#mape = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "#msle = tf.keras.losses.MeanSquaredLogarithmicError()        # square(log(y_true + 1.) - log(y_pred + 1.))\n",
    "#cosine_loss = tf.keras.losses.CosineSimilarity(axis=1)      # reduction=tf.keras.losses.Reduction.SUM ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare\n",
    "If the number of features is more than one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of loaded data: (2073, 8) \n",
      "\n",
      "Dropping 1 last row for golden data point\n",
      "Data prepared:\n",
      "\tSize of X = (2068 by 4)\n",
      "\tSize of y = (2068 by 4)\n",
      "\n",
      "TimeSeriesSplit indices:\n",
      "(Train, test): (348, 344)\n",
      "(Train, test): (692, 344)\n",
      "(Train, test): (1036, 344)\n",
      "(Train, test): (1380, 344)\n",
      "(Train, test): (1654, 344)\n",
      "\n",
      "KFold indices:\n",
      "(Train, test): (1654, 414)\n",
      "(Train, test): (1654, 414)\n",
      "(Train, test): (1654, 414)\n",
      "(Train, test): (1655, 413)\n",
      "(Train, test): (1655, 413)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv( 'data/2step_20210329.csv', encoding='utf-8' )\n",
    "print('Shape of loaded data:', df.shape, '\\n')\n",
    "\n",
    "n_steps      = 4\n",
    "random_state = 34\n",
    "features     = ['num1', 'num2', 'num3', 'num4']\n",
    "n_features   = len(features)\n",
    "\n",
    "( X,\n",
    "  y,\n",
    "  goldenx,\n",
    "  goldeny )  = prepare_data( df,\n",
    "                             features,\n",
    "                             n_steps,\n",
    "                             with_intersection=True,\n",
    "                             flatten=False )\n",
    "\n",
    "tscv = TimeSeriesSplit( n_splits=5, max_train_size=int( len(X)*0.8 ) )                    # no random_state\n",
    "\n",
    "X_sh, y_sh = deepcopy(X), deepcopy(y)\n",
    "X_sh, y_sh = shuffle( X_sh, y_sh, random_state=random_state, n_samples=None )\n",
    "kf = KFold( n_splits=5, shuffle=True, random_state=random_state )\n",
    "\n",
    "print_folds_stats( X, X_sh, tscv, kf )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY 1 BiLSTM LAYER, DROPOUT() AS A SEPARATE LAYER  \n",
    "metrics = [ 'mse', 'mae', 'mape', 'msle', 'cosine_similarity' ]  \n",
    "do not use sigmoid or tanh!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_BiLSTM( n_steps, n_features,\n",
    "                    learning_rate=0.005,\n",
    "                    units=750,\n",
    "                    activation='relu',\n",
    "                    dropout1=0,\n",
    "                    dropout2=0,\n",
    "                    dropout3=0,\n",
    "                    optimizer='adam',\n",
    "                    loss=mse,\n",
    "                    print_architecture=False ):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add( Bidirectional( LSTM( units, activation=activation,\n",
    "                                    dropout=dropout1,\n",
    "                                    recurrent_dropout=dropout2,\n",
    "                                    return_sequences=True),\n",
    "                                                          \n",
    "                              input_shape=(n_steps, n_features)\n",
    "                            )\n",
    "             )\n",
    "        \n",
    "    model.add( Bidirectional( LSTM( units, activation=activation ) ) )\n",
    "    model.add(Dropout( dropout3 ))\n",
    "    model.add( Dense( n_features ) )\n",
    "    \n",
    "    # 'mse', mae', 'mape', 'msle', 'cosine_similarity'\n",
    "    model.compile( optimizer=Adam(lr=learning_rate),\n",
    "                   loss=loss,\n",
    "                   metrics=[tf.keras.metrics.LogCoshError()] )     # metrics=['mse'], optimizer=Adam(lr=learning_rate)\n",
    "        \n",
    "    if print_architecture:\n",
    "        print(model.summary())\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 4, 1500)           4530000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1500)              13506000  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 6004      \n",
      "=================================================================\n",
      "Total params: 18,042,004\n",
      "Trainable params: 18,042,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# PRINT AS AN EXAMPLE\n",
    "model = stacked_BiLSTM( n_steps, n_features, print_architecture=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv( X_, y_, cv_folds, ts_flag=False, dropout=0.15, batch_size=32, epochs=6 ):\n",
    "        \n",
    "    print( f'Stacked_BiLSTM, dropout2 {dropout}, cv method {cv_folds.__str__()}' )\n",
    "    print( f'                batch_size {batch_size}, num epochs {epochs}')\n",
    "    verbose = 0\n",
    "    score_per_fold, loss_per_fold = [], []\n",
    "\n",
    "    fold_no = 1\n",
    "    for train_idx, test_idx in cv_folds.split( X_ ):\n",
    "\n",
    "        # Define and compile model\n",
    "        model = stacked_BiLSTM( n_steps, n_features, dropout2=dropout )\n",
    "\n",
    "        print('\\n', '='*100, '\\n', sep='')\n",
    "        print('Training in fold {} ...'.format( fold_no ))\n",
    "\n",
    "        # Fit data to model\n",
    "        if ts_flag:\n",
    "            history = model.fit( X_[train_idx], y_[train_idx],\n",
    "                                 batch_size=batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 shuffle=False,\n",
    "                                 verbose=verbose )\n",
    "        else:\n",
    "            history = model.fit( X_[train_idx], y_[train_idx],\n",
    "                                 batch_size=batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 shuffle=True,\n",
    "                                 verbose=verbose )\n",
    "\n",
    "        # Generate metrics\n",
    "        scores = model.evaluate( X_[test_idx], y_[test_idx], verbose=verbose )\n",
    "        print(f'Score in fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}')\n",
    "        score_per_fold.append( scores[1] )\n",
    "        loss_per_fold.append(  scores[0] )\n",
    "\n",
    "        # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "        \n",
    "    # Average scores\n",
    "    average_loss  = round( np.mean(loss_per_fold), 4 )\n",
    "    average_std   = round( np.std(loss_per_fold), 4 )\n",
    "    average_score = round( np.mean(score_per_fold), 4)\n",
    "    print( '\\n', '='*100, sep='' )\n",
    "    print( f'Average metrics for the run with dropout2 {dropout}, cv method {cv_folds.__str__()}, batch_size {batch_size} and number of epochs {epochs}')\n",
    "    print('Per fold:')\n",
    "    print( '{:>10}{:^10}{:^10}{:^10}{:^10}{:^10}'.format('', 1, 2, 3, 4, 5) )\n",
    "    print( '{:<10}{:^10}{:^10}{:^10}{:^10}{:^10}'.format( 'Loss',  *[ round(i, 4) for i in loss_per_fold  ] ) )\n",
    "    print( '{:<10}{:^10}{:^10}{:^10}{:^10}{:^10}'.format( 'Score', *[ round(i, 4) for i in score_per_fold ] ) )\n",
    "    print( '='*100 )\n",
    "    print(f'Average loss:  {average_loss}  +-{average_std}')\n",
    "    print(f'Average score: {average_score}')\n",
    "    print( '='*100 )\n",
    "    \n",
    "    return average_loss, average_std, average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked_BiLSTM, dropout2 0, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 106.55168914794922; logcosh of 8.280599594116211\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 102.69500732421875; logcosh of 8.040163040161133\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.0307846069336; logcosh of 8.16988754272461\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.66056060791016; logcosh of 8.276382446289062\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 101.78812408447266; logcosh of 8.043107032775879\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       106.5517  102.695   104.0308  107.6606  101.7881 \n",
      "Score       8.2806    8.0402    8.1699    8.2764    8.0431  \n",
      "====================================================================================================\n",
      "Average loss:  104.5452  +-2.237\n",
      "Average score: 8.162\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.05, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 107.41625213623047; logcosh of 8.295905113220215\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.9312973022461; logcosh of 8.091875076293945\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.07907104492188; logcosh of 8.138469696044922\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 105.99533081054688; logcosh of 8.24113655090332\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 102.86318969726562; logcosh of 8.086609840393066\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.05, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       107.4163  104.9313  103.0791  105.9953  102.8632 \n",
      "Score       8.2959    8.0919    8.1385    8.2411    8.0866  \n",
      "====================================================================================================\n",
      "Average loss:  104.857  +-1.7313\n",
      "Average score: 8.1708\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.1, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 105.27951049804688; logcosh of 8.226329803466797\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 109.26471710205078; logcosh of 8.2850923538208\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.40058135986328; logcosh of 8.148321151733398\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.27474212646484; logcosh of 8.29899787902832\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 101.404541015625; logcosh of 8.051443099975586\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.1, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       105.2795  109.2647  103.4006  108.2747  101.4045 \n",
      "Score       8.2263    8.2851    8.1483    8.299     8.0514  \n",
      "====================================================================================================\n",
      "Average loss:  105.5248  +-2.9359\n",
      "Average score: 8.202\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.15, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 109.052490234375; logcosh of 8.343561172485352\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.54903411865234; logcosh of 8.089566230773926\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 105.55532836914062; logcosh of 8.213540077209473\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.21978759765625; logcosh of 8.316155433654785\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 106.6507568359375; logcosh of 8.19538688659668\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.15, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       109.0525  103.549   105.5553  108.2198  106.6508 \n",
      "Score       8.3436    8.0896    8.2135    8.3162    8.1954  \n",
      "====================================================================================================\n",
      "Average loss:  106.6055  +-1.9514\n",
      "Average score: 8.2316\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.2, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 112.94358825683594; logcosh of 8.469673156738281\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.94447326660156; logcosh of 8.10914134979248\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.78614807128906; logcosh of 8.196285247802734\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.52212524414062; logcosh of 8.246725082397461\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.6825180053711; logcosh of 8.157731056213379\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.2, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       112.9436  104.9445  104.7861  106.5221  105.6825 \n",
      "Score       8.4697    8.1091    8.1963    8.2467    8.1577  \n",
      "====================================================================================================\n",
      "Average loss:  106.9758  +-3.0468\n",
      "Average score: 8.2359\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.25, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 105.92447662353516; logcosh of 8.266746520996094\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.41413879394531; logcosh of 8.088902473449707\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.73373413085938; logcosh of 8.193825721740723\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.60639190673828; logcosh of 8.289948463439941\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 103.46598815917969; logcosh of 8.103109359741211\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.25, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       105.9245  103.4141  104.7337  107.6064  103.466  \n",
      "Score       8.2667    8.0889    8.1938    8.2899    8.1031  \n",
      "====================================================================================================\n",
      "Average loss:  105.0289  +-1.5864\n",
      "Average score: 8.1885\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.3, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 106.13871002197266; logcosh of 8.27210807800293\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 102.9019775390625; logcosh of 8.047661781311035\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.42090606689453; logcosh of 8.178529739379883\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 105.74178314208984; logcosh of 8.232510566711426\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 102.30564880371094; logcosh of 8.08325481414795\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.3, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       106.1387  102.902   104.4209  105.7418  102.3056 \n",
      "Score       8.2721    8.0477    8.1785    8.2325    8.0833  \n",
      "====================================================================================================\n",
      "Average loss:  104.3018  +-1.5104\n",
      "Average score: 8.1628\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.35, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 107.37152862548828; logcosh of 8.306023597717285\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 102.71533203125; logcosh of 8.037671089172363\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.72932434082031; logcosh of 8.190074920654297\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 109.90205383300781; logcosh of 8.35326862335205\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 102.19038391113281; logcosh of 8.083539009094238\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.35, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       107.3715  102.7153  104.7293  109.9021  102.1904 \n",
      "Score       8.306     8.0377    8.1901    8.3533    8.0835  \n",
      "====================================================================================================\n",
      "Average loss:  105.3817  +-2.9022\n",
      "Average score: 8.1941\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.4, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 121.13182830810547; logcosh of 8.698214530944824\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.8266372680664; logcosh of 8.137709617614746\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 105.01180267333984; logcosh of 8.20745849609375\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.20008087158203; logcosh of 8.295973777770996\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 116.3699951171875; logcosh of 8.527131080627441\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.4, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       121.1318  104.8266  105.0118  107.2001   116.37  \n",
      "Score       8.6982    8.1377    8.2075    8.296     8.5271  \n",
      "====================================================================================================\n",
      "Average loss:  110.9081  +-6.6311\n",
      "Average score: 8.3733\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.45, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 107.69107818603516; logcosh of 8.307554244995117\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 102.92921447753906; logcosh of 8.021905899047852\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 110.75102233886719; logcosh of 8.368446350097656\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.21884155273438; logcosh of 8.248714447021484\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 103.50056457519531; logcosh of 8.108906745910645\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.45, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       107.6911  102.9292  110.751   106.2188  103.5006 \n",
      "Score       8.3076    8.0219    8.3684    8.2487    8.1089  \n",
      "====================================================================================================\n",
      "Average loss:  106.2181  +-2.8607\n",
      "Average score: 8.2111\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.5, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 105.4117431640625; logcosh of 8.238273620605469\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.3577880859375; logcosh of 8.070332527160645\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 105.92115783691406; logcosh of 8.21831226348877\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.10397338867188; logcosh of 8.280915260314941\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 102.03193664550781; logcosh of 8.071986198425293\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.5, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       105.4117  103.3578  105.9212  107.104   102.0319 \n",
      "Score       8.2383    8.0703    8.2183    8.2809    8.072   \n",
      "====================================================================================================\n",
      "Average loss:  104.7653  +-1.8262\n",
      "Average score: 8.176\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.55, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 107.23968505859375; logcosh of 8.292806625366211\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.77183532714844; logcosh of 8.088821411132812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.77482604980469; logcosh of 8.1881685256958\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 105.93824768066406; logcosh of 8.247111320495605\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 103.96855163574219; logcosh of 8.111684799194336\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.55, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       107.2397  103.7718  104.7748  105.9382  103.9686 \n",
      "Score       8.2928    8.0888    8.1882    8.2471    8.1117  \n",
      "====================================================================================================\n",
      "Average loss:  105.1386  +-1.298\n",
      "Average score: 8.1857\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.6, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 106.0503158569336; logcosh of 8.26807689666748\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.8656005859375; logcosh of 8.102519989013672\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.32992553710938; logcosh of 8.171338081359863\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.08484649658203; logcosh of 8.254006385803223\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 102.20542907714844; logcosh of 8.06847095489502\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.6, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       106.0503  103.8656  104.3299  106.0848  102.2054 \n",
      "Score       8.2681    8.1025    8.1713    8.254     8.0685  \n",
      "====================================================================================================\n",
      "Average loss:  104.5072  +-1.4568\n",
      "Average score: 8.1729\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.65, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 106.52276611328125; logcosh of 8.286247253417969\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.23664855957031; logcosh of 8.098774909973145\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.28181457519531; logcosh of 8.141178131103516\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.50399017333984; logcosh of 8.240032196044922\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 103.26949310302734; logcosh of 8.094219207763672\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.65, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       106.5228  104.2366  103.2818  106.504   103.2695 \n",
      "Score       8.2862    8.0988    8.1412     8.24     8.0942  \n",
      "====================================================================================================\n",
      "Average loss:  104.7629  +-1.4717\n",
      "Average score: 8.1721\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.7, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in fold 1: loss of 105.27674102783203; logcosh of 8.243785858154297\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.1755142211914; logcosh of 8.121256828308105\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.87623596191406; logcosh of 8.137253761291504\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.15128326416016; logcosh of 8.323395729064941\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 107.95166015625; logcosh of 8.264225959777832\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.7, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       105.2767  104.1755  102.8762  108.1513  107.9517 \n",
      "Score       8.2438    8.1213    8.1373    8.3234    8.2642  \n",
      "====================================================================================================\n",
      "Average loss:  105.6863  +-2.0763\n",
      "Average score: 8.218\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 113.0169677734375; logcosh of 8.453984260559082\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.9448013305664; logcosh of 8.16513442993164\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.87586212158203; logcosh of 8.097935676574707\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.91976165771484; logcosh of 8.29083251953125\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.87443542480469; logcosh of 8.170031547546387\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       113.017   104.9448  102.8759  106.9198  104.8744 \n",
      "Score       8.454     8.1651    8.0979    8.2908     8.17   \n",
      "====================================================================================================\n",
      "Average loss:  106.5264  +-3.4882\n",
      "Average score: 8.2356\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.05, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 113.6473388671875; logcosh of 8.436206817626953\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.67273712158203; logcosh of 8.160717964172363\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.8589859008789; logcosh of 8.155521392822266\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.75162506103516; logcosh of 8.276681900024414\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.4687271118164; logcosh of 8.192679405212402\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.05, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       113.6473  104.6727  104.859   106.7516  105.4687 \n",
      "Score       8.4362    8.1607    8.1555    8.2767    8.1927  \n",
      "====================================================================================================\n",
      "Average loss:  107.0799  +-3.3634\n",
      "Average score: 8.2444\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.1, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 111.33051300048828; logcosh of 8.41871452331543\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.37269592285156; logcosh of 8.149977684020996\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.79759216308594; logcosh of 8.127901077270508\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.43561553955078; logcosh of 8.339849472045898\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.15776824951172; logcosh of 8.183481216430664\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.1, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       111.3305  104.3727  103.7976  108.4356  105.1578 \n",
      "Score       8.4187     8.15     8.1279    8.3398    8.1835  \n",
      "====================================================================================================\n",
      "Average loss:  106.6188  +-2.851\n",
      "Average score: 8.244\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.15, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 110.97775268554688; logcosh of 8.414137840270996\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.98526000976562; logcosh of 8.174481391906738\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.61593627929688; logcosh of 8.15555191040039\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.89330291748047; logcosh of 8.282691955566406\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.24044799804688; logcosh of 8.169060707092285\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.15, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       110.9778  104.9853  104.6159  106.8933  105.2404 \n",
      "Score       8.4141    8.1745    8.1556    8.2827    8.1691  \n",
      "====================================================================================================\n",
      "Average loss:  106.5425  +-2.3506\n",
      "Average score: 8.2392\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.2, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 110.11957550048828; logcosh of 8.379663467407227\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 107.2402114868164; logcosh of 8.252398490905762\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.0652847290039; logcosh of 8.048307418823242\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.42805480957031; logcosh of 8.304150581359863\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.42550659179688; logcosh of 8.194835662841797\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.2, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       110.1196  107.2402  102.0653  107.4281  105.4255 \n",
      "Score       8.3797    8.2524    8.0483    8.3042    8.1948  \n",
      "====================================================================================================\n",
      "Average loss:  106.4557  +-2.6579\n",
      "Average score: 8.2359\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.25, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 111.46656036376953; logcosh of 8.370567321777344\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.68963623046875; logcosh of 8.217764854431152\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.3837890625; logcosh of 8.074373245239258\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.65922546386719; logcosh of 8.34700870513916\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.73695373535156; logcosh of 8.160039901733398\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.25, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       111.4666  106.6896  102.3838  108.6592  104.737  \n",
      "Score       8.3706    8.2178    8.0744    8.347      8.16   \n",
      "====================================================================================================\n",
      "Average loss:  106.7872  +-3.1306\n",
      "Average score: 8.234\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.3, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 109.4130630493164; logcosh of 8.36609935760498\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.19084930419922; logcosh of 8.204859733581543\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.84717559814453; logcosh of 8.124516487121582\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.3789291381836; logcosh of 8.26429271697998\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.08447265625; logcosh of 8.171355247497559\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.3, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       109.4131  106.1908  103.8472  106.3789  105.0845 \n",
      "Score       8.3661    8.2049    8.1245    8.2643    8.1714  \n",
      "====================================================================================================\n",
      "Average loss:  106.1829  +-1.8512\n",
      "Average score: 8.2262\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.35, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 110.37702941894531; logcosh of 8.404903411865234\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.28385162353516; logcosh of 8.211379051208496\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.11164855957031; logcosh of 8.10085391998291\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.96817016601562; logcosh of 8.288213729858398\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.85133361816406; logcosh of 8.165138244628906\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.35, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       110.377   106.2839  103.1116  106.9682  104.8513 \n",
      "Score       8.4049    8.2114    8.1009    8.2882    8.1651  \n",
      "====================================================================================================\n",
      "Average loss:  106.3184  +-2.422\n",
      "Average score: 8.2341\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.4, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 111.61451721191406; logcosh of 8.427902221679688\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.03932189941406; logcosh of 8.212669372558594\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.44519805908203; logcosh of 8.118642807006836\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.6817398071289; logcosh of 8.278470039367676\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.50023651123047; logcosh of 8.1581392288208\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.4, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       111.6145  106.0393  103.4452  106.6817  104.5002 \n",
      "Score       8.4279    8.2127    8.1186    8.2785    8.1581  \n",
      "====================================================================================================\n",
      "Average loss:  106.4562  +-2.8187\n",
      "Average score: 8.2392\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.45, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 108.4706039428711; logcosh of 8.341291427612305\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.08773040771484; logcosh of 8.218657493591309\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 101.99217987060547; logcosh of 8.057024955749512\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.47303009033203; logcosh of 8.272245407104492\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.14564514160156; logcosh of 8.183266639709473\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.45, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       108.4706  106.0877  101.9922  106.473   105.1456 \n",
      "Score       8.3413    8.2187    8.057     8.2722    8.1833  \n",
      "====================================================================================================\n",
      "Average loss:  105.6338  +-2.1193\n",
      "Average score: 8.2145\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.6338, 8.2145, 0.45, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.5, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 109.23116302490234; logcosh of 8.33707046508789\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 108.46996307373047; logcosh of 8.268815994262695\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 101.69061279296875; logcosh of 8.037236213684082\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.73020935058594; logcosh of 8.279877662658691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.2088623046875; logcosh of 8.186064720153809\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.5, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       109.2312   108.47   101.6906  106.7302  105.2089 \n",
      "Score       8.3371    8.2688    8.0372    8.2799    8.1861  \n",
      "====================================================================================================\n",
      "Average loss:  106.2662  +-2.6802\n",
      "Average score: 8.2218\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.6338, 8.2145, 0.45, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.2662, 8.2218, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.55, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 111.37348937988281; logcosh of 8.411995887756348\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.56427001953125; logcosh of 8.221837043762207\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.23047637939453; logcosh of 8.046435356140137\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 109.32637786865234; logcosh of 8.367033004760742\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.86146545410156; logcosh of 8.174488067626953\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.55, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       111.3735  106.5643  102.2305  109.3264  104.8615 \n",
      "Score       8.412     8.2218    8.0464    8.367     8.1745  \n",
      "====================================================================================================\n",
      "Average loss:  106.8712  +-3.2239\n",
      "Average score: 8.2444\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.6338, 8.2145, 0.45, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.2662, 8.2218, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8712, 8.2444, 0.55, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.6, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 111.05003356933594; logcosh of 8.428709983825684\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.71045684814453; logcosh of 8.109298706054688\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.00338745117188; logcosh of 8.031842231750488\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.44770050048828; logcosh of 8.333754539489746\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.83224487304688; logcosh of 8.176797866821289\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.6, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss        111.05   103.7105  102.0034  108.4477  104.8322 \n",
      "Score       8.4287    8.1093    8.0318    8.3338    8.1768  \n",
      "====================================================================================================\n",
      "Average loss:  106.0088  +-3.2885\n",
      "Average score: 8.2161\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.6338, 8.2145, 0.45, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.2662, 8.2218, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8712, 8.2444, 0.55, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0088, 8.2161, 0.6, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.65, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 110.04083251953125; logcosh of 8.401792526245117\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.72976684570312; logcosh of 8.158445358276367\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.07359313964844; logcosh of 8.056126594543457\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.82266235351562; logcosh of 8.308663368225098\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.72434997558594; logcosh of 8.17288875579834\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.65, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       110.0408  104.7298  102.0736  107.8227  104.7243 \n",
      "Score       8.4018    8.1584    8.0561    8.3087    8.1729  \n",
      "====================================================================================================\n",
      "Average loss:  105.8782  +-2.7653\n",
      "Average score: 8.2196\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.6338, 8.2145, 0.45, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.2662, 8.2218, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8712, 8.2444, 0.55, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0088, 8.2161, 0.6, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.8782, 8.2196, 0.65, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.7, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 109.30441284179688; logcosh of 8.376189231872559\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.48367309570312; logcosh of 8.219056129455566\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 101.8427505493164; logcosh of 8.02209186553955\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.44043731689453; logcosh of 8.304012298583984\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.41191864013672; logcosh of 8.15402603149414\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.7, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       109.3044  106.4837  101.8428  107.4404  104.4119 \n",
      "Score       8.3762    8.2191    8.0221    8.304     8.154   \n",
      "====================================================================================================\n",
      "Average loss:  105.8966  +-2.5682\n",
      "Average score: 8.2151\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.6338, 8.2145, 0.45, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.2662, 8.2218, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8712, 8.2444, 0.55, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0088, 8.2161, 0.6, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.8782, 8.2196, 0.65, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.8966, 8.2151, 0.7, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "cv_engines = [ kf, tscv ]\n",
    "drpt_list = [ 0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7 ]\n",
    "for cv_engine in cv_engines:\n",
    "    for dropout in drpt_list:\n",
    "        \n",
    "        ts_flag = 'TimeSeriesSplit' in cv_engine.__str__()\n",
    "        if ts_flag:\n",
    "            loss, std, score = run_cv( X, y, cv_engine, ts_flag, dropout=dropout)\n",
    "        else:\n",
    "            loss, std, score = run_cv( X_sh, y_sh, cv_engine, ts_flag, dropout=dropout)\n",
    "                        \n",
    "        metrics.append(( loss, score, dropout, cv_engine.__str__() ))\n",
    "        print('metrics =', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'),\n",
       " (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (105.6338, 8.2145, 0.45, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (106.2662, 8.2218, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (106.8712, 8.2444, 0.55, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (106.0088, 8.2161, 0.6, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (105.8782, 8.2196, 0.65, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'),\n",
       " (105.8966, 8.2151, 0.7, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "65/65 [==============================] - 12s 192ms/step - loss: 42899.6641 - logcosh: 34.6581\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 13s 196ms/step - loss: 108.0683 - logcosh: 8.2658\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 106.7323 - logcosh: 8.2381\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 14s 214ms/step - loss: 107.1601 - logcosh: 8.2435\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 14s 223ms/step - loss: 105.8404 - logcosh: 8.2072\n",
      "Epoch 6/15\n",
      "65/65 [==============================] - 14s 213ms/step - loss: 105.8581 - logcosh: 8.2014\n",
      "Epoch 7/15\n",
      "65/65 [==============================] - 14s 212ms/step - loss: 105.4855 - logcosh: 8.1814\n",
      "Epoch 8/15\n",
      "65/65 [==============================] - 14s 212ms/step - loss: 105.8206 - logcosh: 8.1968\n",
      "Epoch 9/15\n",
      "65/65 [==============================] - 14s 215ms/step - loss: 105.4652 - logcosh: 8.1899\n",
      "Epoch 10/15\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 106.6510 - logcosh: 8.2315\n",
      "Epoch 11/15\n",
      "65/65 [==============================] - 14s 212ms/step - loss: 105.6082 - logcosh: 8.1940\n",
      "Epoch 12/15\n",
      "65/65 [==============================] - 14s 218ms/step - loss: 105.8466 - logcosh: 8.1994\n",
      "Epoch 13/15\n",
      "65/65 [==============================] - 14s 219ms/step - loss: 104.8713 - logcosh: 8.1769\n",
      "Epoch 14/15\n",
      "65/65 [==============================] - 14s 216ms/step - loss: 104.7123 - logcosh: 8.1546\n",
      "Epoch 15/15\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 104.3792 - logcosh: 8.1496\n",
      "Results on the last reserved data point:\n",
      "True:      [25 27 20 17]\n",
      "Predicted: [18. 18. 19. 20.]\n"
     ]
    }
   ],
   "source": [
    "# PREDICT ON GOLDEN DATA POINT\n",
    "def predict_one(model, X_last, loss_func=mse):\n",
    "       \n",
    "    X_last = X_last.reshape((1, n_steps, n_features))\n",
    "    pred = model.predict(X_last, verbose=0)\n",
    "    return np.round( pred[0] )\n",
    "\n",
    "\n",
    "use_tscv   = True\n",
    "batch_size = 32\n",
    "epochs     = 15\n",
    "verbose    = 1\n",
    "\n",
    "# train\n",
    "model = stacked_BiLSTM( n_steps, n_features,\n",
    "                        dropout1 = 0,\n",
    "                        dropout2 = 0,\n",
    "                        dropout3 = 0.15)\n",
    "if use_tscv:\n",
    "    history = model.fit( X, y,\n",
    "                         batch_size=batch_size,\n",
    "                         epochs=epochs,\n",
    "                         shuffle=False,\n",
    "                         verbose=verbose )\n",
    "else:\n",
    "    history = model.fit( X_sh, y_sh,\n",
    "                         batch_size=batch_size,\n",
    "                         epochs=epochs,\n",
    "                         shuffle=True,\n",
    "                         verbose=verbose )\n",
    "    \n",
    "# predict\n",
    "print('Results on the last reserved data point:')\n",
    "print('True:     ', goldeny)\n",
    "print('Predicted:', predict_one( model, goldenx ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:      [18 17  7 15]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [30 23 33  5]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [21 13 22  4]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [12 14  3 24]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [34 11 21 33]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31  7 25 35]\n",
      "Predicted: [20. 20. 19. 22.]\n",
      "=========================\n",
      "True:      [ 4 22 33  6]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [11 19 27 30]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [30  4 32 13]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [27  8  9 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 7 10 22 16]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 16 26  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25  8 32 15]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 7 32 21  9]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [21 16 15 35]\n",
      "Predicted: [19. 20. 19. 21.]\n",
      "=========================\n",
      "True:      [16 31 30  1]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [25 11 31 26]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [32 21 27 30]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [34 29 20  9]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [21 12 32 16]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [10 32 12 21]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [23  6 15 25]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [11 25 30 10]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [17 10 20 25]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [19 14 35 17]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [35  9 29 27]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27 29  3  8]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3 23 21 17]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [10 30 20 18]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [24 31 33 35]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 7 35  5 12]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [21  1  5  8]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [10 17 27 32]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [13  2 24  1]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 1 33 25 27]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 33 11 34]\n",
      "Predicted: [16. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [29 30  7  3]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [21 29 27  4]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3 13 30 32]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [33 28  4 30]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13 17 31 29]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 5 11 30 29]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [30 13 31 20]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3  1 20  6]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 5 14 22  8]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [11 20 29  8]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 21 15 31]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [20 11 12  6]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [32 31 25 19]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 28  9 20]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [20  2 24  4]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 24 28 35]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [ 8 24 20  9]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [35 29  3  1]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [25  3  4 33]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 8 25  4  9]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 6 29  3 33]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [ 2 14 35 27]\n",
      "Predicted: [19. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [12 27 15 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [18 27  5  2]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [20 31 28  9]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [23 20 30 18]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [33 24 29 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [27 18  8 13]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [35  4 18 27]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [13  7 21 15]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [10 24 30 14]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 5 14 28 12]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [31 28 11 12]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [25 19 33 29]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [24  1 17  8]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [10  6 22 28]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [32 22  5  3]\n",
      "Predicted: [19. 19. 19. 20.]\n",
      "=========================\n",
      "True:      [ 5 27 35 28]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 8 33 26 20]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6 25 31 16]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [32  1 18 31]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [20 14  3 23]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [28 17 35 14]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 20  3 14]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33  2 30 19]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [12 19 14 22]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [20 21 10 17]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31 30 15 20]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [13  4  6 29]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [ 3 23 34  4]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [18 17 33 25]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 13 28  3]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32 19  2  9]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33 19  9 21]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [34  8 19 20]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [28  3 20  2]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 13 20 18]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [34 29  4 28]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [27 16 34  9]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12 19 30 28]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8 35 24 21]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6 15 21 17]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [28 12  9  5]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9  6  4 34]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [15 21  4  9]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 13 20 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [15 35 10  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4  6 16  2]\n",
      "Predicted: [19. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 4 19 15 16]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 7 17 11 15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4  7 30 16]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [26 22 17 33]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6 32  3  5]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19  9 18 33]\n",
      "Predicted: [19. 19. 18. 20.]\n",
      "=========================\n",
      "True:      [21 26 25  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8 13 23 30]\n",
      "Predicted: [19. 19. 19. 20.]\n",
      "=========================\n",
      "True:      [24  3 23 11]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [32  3 11 33]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4  1 34 13]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [21 34 25 19]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3  8 17 27]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [12 35  5  6]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [33 30  9 15]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [29 26 25 27]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6 21 22 13]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2  8 13 31]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [16  4 17 33]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [22 17  7 14]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [16 23 33 17]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [ 5 35 12 17]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [22 15  6  4]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [16  6 19  2]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [12 27 34 25]\n",
      "Predicted: [20. 20. 19. 22.]\n",
      "=========================\n",
      "True:      [25 33  8  2]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [13 34 21 24]\n",
      "Predicted: [20. 20. 20. 22.]\n",
      "=========================\n",
      "True:      [28 14 26  5]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8 10 27  7]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [10 29 12 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17 33 25 13]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [28 13  7 32]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [22 16 25 20]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [25  2  1  8]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [17 18 20 28]\n",
      "Predicted: [21. 20. 19. 22.]\n",
      "=========================\n",
      "True:      [ 6 24 16 29]\n",
      "Predicted: [19. 19. 19. 20.]\n",
      "=========================\n",
      "True:      [ 7 29 24 15]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11 34 29 25]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2  1 24 25]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8  1 16 17]\n",
      "Predicted: [19. 19. 20. 21.]\n",
      "=========================\n",
      "True:      [ 5 14 33  8]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9 15  8  7]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [15 24 25 33]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26 24 34 19]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [17 12  7  9]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [14  1  6  7]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13 32 15 12]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15  2 33 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [28 14 34 23]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 6 15 25 26]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [31 17 32  4]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 2 29 24 25]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26 29 19 23]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [19 10  7 16]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [19 12 15  7]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [13 14 21  4]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [18  1 23 28]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6  5 32 20]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [24  2  3 19]\n",
      "Predicted: [21. 20. 20. 22.]\n",
      "=========================\n",
      "True:      [ 7  2 10 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 3 25 35 30]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 33 16 15]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 1 33 31 18]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22 33 20 13]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [15 13 10 25]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [19 35 22 17]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27 33  6 17]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [12 34 30 15]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [14 22  4 20]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [20 30 31 21]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [34  7 12  1]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [16 28 20 33]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [35 19  8 15]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [12  2 17 10]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8 35  2 27]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [ 1  3 20  5]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [13 23 32 21]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [12 20 33 13]\n",
      "Predicted: [17. 16. 17. 19.]\n",
      "=========================\n",
      "True:      [17 11 35 23]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30  9  7 23]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [34 11 19 12]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8 25 33 23]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 5 17  1  4]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [23 34 27 15]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22  7 19 30]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [23  5 19 18]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [29 13  9  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 1 29 26 31]\n",
      "Predicted: [19. 19. 20. 20.]\n",
      "=========================\n",
      "True:      [20 19  3 17]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [10 26 15 22]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 15 21 11]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22 21 18 14]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [28 14  1 17]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22  1 27 15]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [21 11 10  4]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 7  8 10  2]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [10  2 17 12]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13 22 24 27]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6 15  7 18]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 33 27 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [34 18 16 11]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27 24 19 32]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [22  4  1  2]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [30 27 25 35]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [24  6 14 22]\n",
      "Predicted: [16. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [29 35 11 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [33 17 25 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [21 19 18  9]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 12 13 14]\n",
      "Predicted: [16. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [31 29  8 14]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [ 3  5 12 17]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [20 33 31 13]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 7 31  9 30]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [14 27 22  4]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [20 19 35 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [10 11 25  3]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [35 34  3 25]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12  2 20 27]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [21 26 11  1]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [29 33 13  3]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 31  8  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [12  1  4 11]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [29 19 10  2]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 23  8 15]\n",
      "Predicted: [17. 16. 17. 19.]\n",
      "=========================\n",
      "True:      [21 31 11 15]\n",
      "Predicted: [18. 19. 18. 20.]\n",
      "=========================\n",
      "True:      [29  1  4  8]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [ 4 30 13 16]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [20 34 13 30]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [20 33 28 23]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [19 14 32  7]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [12 23 10 32]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 4 12  3 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 15 23 18]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 18 35 26]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [11  5 31 16]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [30 25 33  4]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [34  9  1 33]\n",
      "Predicted: [21. 20. 19. 22.]\n",
      "=========================\n",
      "True:      [21 34 17 25]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [20 15  2 22]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 10 32 21]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [29 26 13 30]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [29 21 26 24]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 16 11 21]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6 27  1 13]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 8 31  4 24]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [21 28 30 24]\n",
      "Predicted: [16. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [16 15 13 30]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [20 27  5 26]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [15 12 18 21]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [21 24  7  4]\n",
      "Predicted: [22. 21. 20. 24.]\n",
      "=========================\n",
      "True:      [30 25 16 23]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [24 20 12 21]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [18 27 29  1]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [34 14  5 10]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [22 23 27 11]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [35 31 23  3]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [34 30 25 20]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [ 4 30 22 14]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [18 31 13  1]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 1 27 25  2]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [14 20 18  3]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [26 23 25 15]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4 16 32 18]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2 24 12 22]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [12 16 25 19]\n",
      "Predicted: [18. 19. 18. 20.]\n",
      "=========================\n",
      "True:      [15 34 17 24]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6 31  2 27]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19 10 20 28]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31 29 21 17]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [23 31  7 27]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [19 29  8  3]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 17 14 18]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19 34  1  7]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8  3 10 12]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29 15 34 12]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [33 12 27  1]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [21 17 12 10]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [23 12 29 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31 10 26 32]\n",
      "Predicted: [19. 19. 19. 20.]\n",
      "=========================\n",
      "True:      [30 13  7 33]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 3 11 24  7]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [20 21 29 24]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [14 24 17  5]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 19 12 23]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [28  7 19 31]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 22 12  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [23 26 31 29]\n",
      "Predicted: [19. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 8  5  2 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 19 24 33]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22 24  3 32]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 32 33 25]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [12 28 17 18]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [23 27 12  7]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [32  3  7  8]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [16  3 30  6]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [20 16 11 24]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4 15  5 30]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 4 31 10  2]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 29 12 14]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [18 10  6 30]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [25  8 30 12]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 30 20  6]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 35 30  2]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [34 17  6 33]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [11 10 30  3]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [12  3 35 33]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [24 20  3  4]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [28 30  6 32]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [12  7 21 18]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11 17  1 10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [29  5 15  4]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 5 23  7 29]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [22  5 34 20]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 7 18 12 26]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6  7 33 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [31 29 27  8]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3  6 34 20]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 4 32  6 25]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [19 12 22 28]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [23 27 32 14]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 25 30  8]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 31 17 10]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4 31 11  6]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 34 29 28]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [29 26 10  1]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [12  8  9 35]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29  1 10 27]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26 17 27 22]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [ 4 21 29  6]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [15 28 22 14]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [28 31 27 15]\n",
      "Predicted: [19. 19. 19. 20.]\n",
      "=========================\n",
      "True:      [20 31 11 23]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8 29 10  4]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [19 25 28  4]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 18  5  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [21 32 23 10]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [30 15 18 11]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [11  9 12  3]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [28 20  4 32]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [11 33 28  1]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [18 21 17 30]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [16  6 19 33]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [ 5 12 26 33]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 29 22  5]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [15 23 19 22]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [32 13 18 31]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 17 20 12]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [31 34 27  5]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [24 22 17  5]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 12 29 27]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [16 26 29 20]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [20 35 24  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [30  7 35 23]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [23 26 12 28]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [32 23 19 14]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [34 16 20 29]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [28 23  5  2]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [21 15 24 32]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17 14 21 27]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [10 16 27 12]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6 10  3 35]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [ 9 11 26 30]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [32 33  1 16]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [18  9 30 26]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [ 2 11  5 30]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [27 19 26 28]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 17 16  7]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 18  4 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31  8 32 34]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [22 19 23 33]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [14 31 13 24]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [13 19 27  7]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12 26 35 31]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 16  8 23]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [10  2 34 16]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [30 22  5  2]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 5 17 29 24]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [14 29 13 26]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [34 32  4 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19 13  1 31]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [26  8 33 23]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [34  6 21 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [35  4  1 17]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3  6 19 12]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 27 24 14]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [26 30 23 11]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 23 20 32]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [26  6 10 24]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [ 1 16 34 11]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [24 18  4 13]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [32 19 33  4]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 5  9 10 24]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [15 13 10 17]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [18 11 10 26]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 28 31  8]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [12 16 29 11]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 4  8 26 10]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [18  9 17 29]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [35  2 34 23]\n",
      "Predicted: [19. 19. 20. 21.]\n",
      "=========================\n",
      "True:      [23 10 26 20]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 18  9 14]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [24  8 26 10]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12 24 13 23]\n",
      "Predicted: [17. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [10 19 31 12]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8 29 20 30]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 9 19 33 12]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33 30 17  9]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [27 23 22 21]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [22 33 14 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 5 35  1 10]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [15 33 21 25]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [24 30 23 20]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 15 26 28]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [34  8  4 21]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [35 27  9 18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [34 18 20 35]\n",
      "Predicted: [18. 17. 19. 20.]\n",
      "=========================\n",
      "True:      [24 18 15  5]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [30 16 32 17]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19 32 23 30]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 2 15 21 32]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22  6 32 27]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [33 31 11 21]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 12 18  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [34 10 25 28]\n",
      "Predicted: [20. 19. 19. 22.]\n",
      "=========================\n",
      "True:      [20 31  4  7]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8 22 10 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [18 13  4 35]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [35 14 23 27]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [16  4  2 13]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 7 26 29 13]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [27  3 14  4]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15 29 16  8]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [14  5  6 17]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32 15 29 16]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [22 13 33 26]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 6  3 19 18]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [10  6  7  1]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 1 21 20 16]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [14 16 26  1]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [35 10  1  4]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 2 10  5 19]\n",
      "Predicted: [16. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [21 20 33 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13  6 15 17]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1  5 25 24]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2 18  9  6]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [22 26 29 34]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [28 13 30 31]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [19 29 25  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [16 33 35  6]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 16 14 20]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 31  7  2]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 5  7 33 28]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [15  6 34 23]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 22  1  4]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [28  2 34  3]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [19  8 26 22]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [29 32 17 30]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [21  6 10  4]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19 14  3  8]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [21 22 19 20]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [28  8  1  7]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [34 18 35 22]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [20 30  9 10]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 4  6 31 33]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [30 13 19 29]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [19  8 11 12]\n",
      "Predicted: [17. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [12 13 16 18]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [35  1 13 12]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [10 14 35  3]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [31  6  1 16]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [21 11  6 31]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12 20 17  6]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [33  4  1 16]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [35  8  3 15]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [21  5 28 20]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [20  3 22 30]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [20  2 12 25]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [29 21 14 31]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [20 12 14 34]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22  7 11  4]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 24 26 12]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [20  1 22  6]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [25 35 30 27]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [10 19 21 23]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [18 28  1 33]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 5 21 13 24]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19 13 35 21]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [21 14  2  9]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [34 24 35  7]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6  1 22 15]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [30  5  1 34]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [11 22 16 18]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [29 21 34 26]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [29  1 34 15]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [30 14 32 26]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [19 20 16 23]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 24  1 28]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 3 28 20 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 1 34 12 31]\n",
      "Predicted: [22. 21. 20. 24.]\n",
      "=========================\n",
      "True:      [ 8 23 25 15]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [18 10 33  5]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3  6 31 32]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13 31 17 15]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8 19 11  9]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32 10 26 19]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [30 31 13 24]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [28  6 24  5]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8 30 11  3]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2  5 24  6]\n",
      "Predicted: [17. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [31  3  8 16]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [23  7 32  1]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [11 27  2 30]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [28  5 21 10]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4 29 32 34]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 1  8 16 25]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6  1  4 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [25  9 19 18]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [35 10 27 29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4 13 14 17]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [24 31 18  1]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [31 35 17  4]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 8  9 26 15]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 18  1 28]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [12  1  9 20]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [34 28 10 31]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [27 19 12 21]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [29 21 12 11]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [32 25 23 30]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [35 31  3  9]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [22  1 17  5]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8 26 28 12]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [28 14 24  2]\n",
      "Predicted: [20. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [ 1  2 29 34]\n",
      "Predicted: [19. 18. 20. 21.]\n",
      "=========================\n",
      "True:      [21  4 24  3]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [35  3 32 13]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [11 20  4  3]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [18  8  7 10]\n",
      "Predicted: [17. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [21  4  1 22]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [14 26  4  6]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4 21 18 25]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [31 23  5 15]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [ 6 12 19  5]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [25 16 34 14]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [20  7  1 16]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [13 24 20 11]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9 18 14 33]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [23  3 26  4]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 23 17 16]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [30 24 11 29]\n",
      "Predicted: [20. 20. 21. 23.]\n",
      "=========================\n",
      "True:      [28  8 22 11]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [14  2 29 24]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 5 33  4 35]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 1 19  2  4]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [19 33 15 27]\n",
      "Predicted: [19. 19. 19. 22.]\n",
      "=========================\n",
      "True:      [16 30  9 15]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [34 25  1 21]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8  5 24  3]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27 16 13 19]\n",
      "Predicted: [21. 21. 20. 23.]\n",
      "=========================\n",
      "True:      [24 13 31 21]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [18  1 26 10]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [12  9 23 24]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [17  1 33 31]\n",
      "Predicted: [17. 17. 16. 18.]\n",
      "=========================\n",
      "True:      [17 11  2 20]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17  2  7  3]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 28 16 24]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [15 23  9 18]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [19 11  3 27]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [23 18 14 13]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 15 24  5]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [34 23 28 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32 22 28 17]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 19 33  7]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27 22 16 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [12 16 35 21]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [11 22 33  1]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 2 15 29 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12  3 33 27]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 4 20 18 10]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19 22  6 13]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [11 27 25 20]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [27 32 28  6]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [ 4  9 21 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13  8 11  1]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [29 15 19 28]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [23 24 17 34]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [18 31  5 14]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2 29  3 11]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17  5 34  9]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [ 1 19  4  9]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [12 33 18 20]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [21 27 12  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [19  9 22  5]\n",
      "Predicted: [17. 16. 17. 19.]\n",
      "=========================\n",
      "True:      [24  8 32  7]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [33 31 22 14]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [18 32 13  7]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [27 19  8  9]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [15 12 32 16]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 7 17  8  3]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11 20 14 16]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 5 31 32  4]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [24 25 33  6]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 5 33 19 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11 26 34 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 2 27  8 31]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [34 31 15 35]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6 16 12  5]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [19  6 12  1]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [35  3 24 29]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 16 27  9]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [13 22  7  2]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [27 14  6 18]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [14  3 19 30]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [33 18 12 28]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [21  1 24 13]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [19 34  6 28]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 8 11 23 13]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [35  6 32 13]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [18  8  1 12]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [32 21  9  6]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 23  9 29]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 3 20 15  8]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [15  7  4 23]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [29 11  7  6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [25  7 32  4]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [19 32 23 35]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [19 20 21  1]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [13  3 24 25]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33 35  6  7]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [12 34 23 30]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [34  3 11  1]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [34 12 33 11]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [15 25 12  9]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [33  5 24  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [35 33 30 13]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 21 17  5]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 30  4 28]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 34  7 15]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 10 13 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [26 12 27 23]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 4 13 22  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22  2 12  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 14 18  9]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 24  2 25]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2  1 30  3]\n",
      "Predicted: [16. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [27 11 13 32]\n",
      "Predicted: [20. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [ 8 21 12 20]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [18 17 12 23]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [17 32  4 22]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [23 35 29  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17  3 20  5]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [30 34 31  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27  2 24 18]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [27 10  9 18]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [23 17 21  1]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 7 16 35 24]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15 30 14 31]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33  8 18  1]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [21 30 27 18]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [23 15 28  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [10 14 30 13]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 18 24 14]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [21 10  6 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [14 26 19  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8  4 13 24]\n",
      "Predicted: [17. 16. 18. 19.]\n",
      "=========================\n",
      "True:      [33 24 28 35]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [19  5 24 18]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 14 34 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [33  3 27 32]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [21 23 28 18]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [18 17 27  4]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [34  6  1 11]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [29 11  6  8]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25  1 13 34]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [ 1 11  9 32]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [35  4 16 11]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [29  8  6 30]\n",
      "Predicted: [20. 19. 20. 21.]\n",
      "=========================\n",
      "True:      [28 13 19 33]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [10  7 18 33]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2 26 10 24]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12 16 13 26]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12 14  3 26]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6 19  7 12]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17  3 18 14]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 35  5 20]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [25 14 26 23]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [11 32  4 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 7 17  2 30]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 12  1 18]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6 32  4 28]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [15  2 33 27]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [27 22  8 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [16  7 29 11]\n",
      "Predicted: [16. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [10 23 15 14]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6 19 25  4]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [22  2  5  8]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [22 17  2  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1 19 23 35]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33 28 31 22]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 30  1  6]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [21 29 32 27]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6  2 12 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1 14 21 31]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [35 20 23 17]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [26 24 31 28]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [15  5  4 22]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [10 24  4 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22 19 34  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [23  3 17 28]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17 35 33 15]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [24 12 22 27]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8 20 21 32]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [3 6 5 8]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [31 18 16 27]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 18 33  5]\n",
      "Predicted: [19. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [11  9 19 16]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [10 13 30 32]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 8 16 27 23]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 6 12 28 20]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2 34  7 30]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [14 34 18  4]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 28 34 12]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2 23 22 26]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2  7 18 15]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9 22 28  7]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [18 35 19 14]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [30 10  6  2]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [34 24 25  2]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [31 13 12 33]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 4 13 24 26]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [16 11 28  4]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 10 25 35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [21  6  1 24]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31  9 18 16]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [12  4 22 34]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [10  8 12 16]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4  2 34 31]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [29  4  3 14]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 27  6 31]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2  9 16 27]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 16 15 13]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 17 32  9]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26 24 21 30]\n",
      "Predicted: [25. 24. 23. 27.]\n",
      "=========================\n",
      "True:      [ 3 18 29 28]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [10 19 28 32]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [31  6  8 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [14 18 24 17]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 17  5 20]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [31 16 13 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 5 33  9 30]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [27 22 21 17]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [21 24 28  4]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [16 24 11 18]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [20 19  2 11]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [21  2 26 13]\n",
      "Predicted: [18. 19. 19. 20.]\n",
      "=========================\n",
      "True:      [11  6  1 29]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [32 19 21  9]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9  5 22 15]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [31 13 18 32]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [10 18  7  5]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 15 14 35]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 32 26  4]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [16 24  4  2]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 25  5 30]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [16 22 34 35]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 31  1  5]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [23 16  5 25]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [16 22 28 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [11 33 23 31]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 8  7 35 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [18 15  8 12]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 29 16 19]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [19 35 29  2]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [28 31 12 13]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 18 23  9]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [30 15 33 34]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [21 16  4 22]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25  4 29 20]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3 15 22 30]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13 27 29  2]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26 28  5 25]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [31 17 10 20]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [23 34 29 30]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 19 17 27]\n",
      "Predicted: [20. 19. 18. 22.]\n",
      "=========================\n",
      "True:      [13 21 15  9]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 4 30 16 26]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 7 32 15 34]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [12 35 25  4]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 16 24 32]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [25 29 15  6]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 5 35 33 19]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [11 33 32 28]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [25 20  9  7]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [23 35 30 24]\n",
      "Predicted: [19. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [15 26 29 30]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [18  6 24 20]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11 26 27 22]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [16 19 30 11]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [17 32 28  3]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [21  4 29 30]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [23 10 20 30]\n",
      "Predicted: [16. 16. 18. 18.]\n",
      "=========================\n",
      "True:      [ 6 16 17 12]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 3 24 28 26]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 13 28 19]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 5 30  8 31]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [29 33 22 25]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33  2 12 31]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26  4  9 23]\n",
      "Predicted: [17. 16. 18. 18.]\n",
      "=========================\n",
      "True:      [23  5 29 30]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 32 30 18]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 3 20 15  5]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6 31 10 15]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4 30  1 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [20 15  3  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 2 19 12 29]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [35 33 11  6]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [21  7  9 14]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [32 27  2 25]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [34 26 29 16]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [20 29 23 26]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9 14 16 10]\n",
      "Predicted: [19. 19. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 17 12 18]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 19 20 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [33 22  3 30]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [12 29 23  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9  6 11 20]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [21 25 23 33]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3  6 33 17]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 8 35  7 16]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17  2 24 16]\n",
      "Predicted: [17. 16. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 20 30  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 3 29 17 12]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [29 19 15 16]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22 31 19  5]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [31 33 12 25]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [25 31 18  4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 12  1  5]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13 23 10 26]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [15 12 17 14]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [10 16 34  2]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 23 18  5]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [24 17  1  2]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [14 34 23  1]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [23 20  5 22]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [16 18 20  3]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [35 19 20  5]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17  7 19 32]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [17 29  2 34]\n",
      "Predicted: [17. 16. 17. 19.]\n",
      "=========================\n",
      "True:      [15 20  4 33]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [22 19 12  3]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [30 17 11 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [24 14 12 31]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [25 18 14 12]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [35 13  1 14]\n",
      "Predicted: [20. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [28 10 24 35]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [10  2  4 23]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [16  7 13 15]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [29 13 25 35]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 7  5  9 14]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [17  6 21  7]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [23  2 18 30]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [18 24  7 26]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 7 18  3 14]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9  2 21 10]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [35  7 22 28]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [25 11  1 17]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [10 11 21 28]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 32  9 24]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [26  4 14 12]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 1 28  9  7]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [24 11 13  4]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22 12 33 31]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [20 22 35 29]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [11 16  3 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [18 22 30 25]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [15  2  6 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11  9  6 14]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [12 35  2 30]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [ 7 15 27 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [21 30  2 33]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15 16  2 17]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 4  3 20  1]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [23 34  4 16]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2  9 30 32]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [30 24 32 26]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [13 18 20 32]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 35 16 17]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [32 25 26 15]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8  5 21 32]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 14 20 13]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [25 11 32 10]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [22 14 29  5]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [21 32 17 14]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3 30  8  6]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [ 6 12 26 23]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [15 12 22 32]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [30 34 29 18]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [18  8 21  4]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [24  3 31 26]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [23  2 29 20]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [16  2 31  1]\n",
      "Predicted: [16. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [ 5 22 10 23]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 20  6 27]\n",
      "Predicted: [18. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [ 8 35 16 19]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 22  2 12]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [12 10 25 15]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [33 12 22 11]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [33 28  7 24]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [33  8 16 20]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [17 34 30  4]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 5  4 10 34]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [19  4 27 14]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [22 17  7 23]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [34 25 28 10]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31 28 25 12]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [10 18 32 24]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8 26  3 20]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9 21 19 32]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [14 25  4  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [30 19  9 34]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [23 17  9 19]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [13 29 31  5]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [ 7 26 23 33]\n",
      "Predicted: [16. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [ 1 25 27 11]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [10 14  6  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 7  3 19 34]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [10 11 30 31]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 12  3 24]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [12  9 23 13]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 10 21 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8 23 20  2]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [35 26  3 18]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6 25 13 35]\n",
      "Predicted: [19. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 6  8 32 22]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [16 10 12 35]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29  6 10 25]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [32 12 23 25]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [30  6  4 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 2  1 10 23]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [35  5 26 16]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7  3 24  1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9  7 21  2]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [23 15 34 21]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1  5 23 34]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15  9 31  2]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22 27 35 17]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [18  1  4 20]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [31 24 34 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26  5 33 25]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [12  8 23 15]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [24 20 13 16]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [21 32 16  1]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [20 11 16 32]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [30 28 31  4]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [22  5 14 34]\n",
      "Predicted: [18. 19. 18. 20.]\n",
      "=========================\n",
      "True:      [35  5  7 30]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [10 28  4 30]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [35  7 16 33]\n",
      "Predicted: [20. 20. 20. 22.]\n",
      "=========================\n",
      "True:      [31  9 34 20]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [15 24 16 17]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9  7 32 12]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [17 27 18  5]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [33 14 34  8]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [25 35 33 28]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [13 15  5 14]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6 29  2 34]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 3  9 28  2]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [12  8 11  2]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [12 24 29  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [35 31 12  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [14  8 11 12]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [16 24 18 15]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [27  9  3 30]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [15  7 14 11]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [26 19 21 14]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [11 12 19  4]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [18  2 20 24]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13  1 28 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4 24  2 16]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [21 30 33 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12 27 32 30]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 2 30 22 17]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [33  4 10 23]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 13 35 22]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25  7 13 32]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8 23 10 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [14 26 19 17]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [ 6 22  4 11]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [21 26 29 11]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6 18 12 15]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [28 19  8 14]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [26  8  3  6]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [12 35  5 19]\n",
      "Predicted: [19. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [20 19 31  9]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17 33 26 31]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 17  7  3]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 7 10 12 21]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [11  1 17 19]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [34 29 12  5]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [19 15  8 27]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32  4  3  5]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [21 29 33 25]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [27  9 11 25]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [21 31 10 15]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [23  4 14 33]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [35 16  3 26]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22  8 35 11]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [17  5 32 31]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12 24  3  7]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [21 22  3 24]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 10 24  6]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 28 23 10]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8 20 23 30]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [27 26 17 33]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [29  5 24 22]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [11 14  9 13]\n",
      "Predicted: [17. 16. 17. 19.]\n",
      "=========================\n",
      "True:      [21 33  2  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6 20 31 15]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [14 24  6 17]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [15 24 19 26]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [14 20 25 18]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [34 19  6 10]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22 16 24 28]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26 19 33  9]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [27 19 11 16]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [12 17 28 13]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 7 24 25 20]\n",
      "Predicted: [18. 19. 19. 20.]\n",
      "=========================\n",
      "True:      [19  4  7 14]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 14  6 27]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [19  4 13 17]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [12 20 17 34]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [15  6 29 19]\n",
      "Predicted: [16. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [22  3 21 20]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 3 15 16 33]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [24 29 18 32]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33 15 19 29]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [31 21 22 17]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [20 33  6  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31 22 12 30]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [20 29 27  4]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [31 18  5  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15 22  1 11]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 19 12  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [33  9 11  1]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [18 28 34 15]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [15  2 34 16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [22 23  4  5]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26 33 15  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [19 20  5  3]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22  4  7 10]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [10  7 17 28]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 9  6 28 12]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 15 14 24]\n",
      "Predicted: [21. 20. 20. 22.]\n",
      "=========================\n",
      "True:      [27  6 28 29]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [10 35  9 15]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [13 17 15  7]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [19 29 14 30]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9 10  5  7]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13 21  4 32]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13 33 34 12]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6  4 33 18]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33 17 28  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8 17 16 18]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [15 28 20 32]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [34 26  9 14]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [30 34  1 11]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 2 34 13 23]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 27  1 12]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 34 15  3]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [23 13  7  2]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 35 13 19]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [17 18 19 31]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 9 33  5 25]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 9 19  8 15]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [32 14  4 31]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 17 12 11]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [16 12  8 10]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [26 20  4 31]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 28 16 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27 24  6  9]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3 28 34 33]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [18 26 29 24]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31 27 24 25]\n",
      "Predicted: [19. 19. 19. 20.]\n",
      "=========================\n",
      "True:      [18 22  4  2]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [19 26  4 24]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [15 34  2 19]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [24 11  5  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25  6 23  5]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [32  1 28  5]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [10 35 16  6]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19 28  4 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32  6  8 31]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22 25  7  1]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [35 19  8 17]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [21  1 27 26]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 6 28 24  5]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [ 2 12 28  3]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [33  1 13 29]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6  9 34 32]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 34 28 27]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33  7 35 16]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 30  3  4]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [15  9 30 20]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [15 16 22 30]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 1 35 24 18]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [15 25 35 23]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32 30 24  3]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [29 28 11 16]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [13 17 12 29]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [25 32 12 24]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [14  8 29 10]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4 28  6  8]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [26  7 32 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8 24  5 28]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [35 22 17 21]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1 35 21  6]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [33  2 18 15]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [30 16  7 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27 14 16 13]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8  6 18 25]\n",
      "Predicted: [20. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [32 17  8 10]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [34 31 19  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [34 13  7 15]\n",
      "Predicted: [19. 19. 20. 20.]\n",
      "=========================\n",
      "True:      [16 33 34 30]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [33 17 20 15]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [16 21 12 20]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 9 16 24 26]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 7 15  1 21]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22  4 13 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11  3 20  5]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [29 27  2 31]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [33 29 26  2]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [13  5  1 10]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [30 27 34 25]\n",
      "Predicted: [20. 19. 19. 22.]\n",
      "=========================\n",
      "True:      [24  5  6  1]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29 26  1 10]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [17  7 21 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [24  7 28 17]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22 21 31 23]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [29 28  7 30]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31 18 10  5]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [12 34 19 35]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [30 26 25 27]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [31 20 18  2]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [35  3 33 18]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [34 33 32 12]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 19  2 27]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [21  3  4  7]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [25 12 29 15]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15  3 10 18]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 4 32 10 17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [ 1 33 28 24]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [30 26 31 14]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [28 11 32  6]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [24 15 16 22]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [13  5 12  2]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [34  5  8 18]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [20 22 18 13]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19 22 13 30]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27 20  9 31]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32 30 12 27]\n",
      "Predicted: [19. 19. 19. 20.]\n",
      "=========================\n",
      "True:      [ 1  7 31  2]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15 30  2 35]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [32 16  5 34]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [32 17  3  1]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [34 24 13 10]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [20  3 35  8]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [22 15  1 23]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [23 12  8 13]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [33 26  9 29]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [32  4  6 12]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [30 24 15 32]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9  6  8 33]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [18  9 24 16]\n",
      "Predicted: [16. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [15 20 26 31]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [ 4 27  5 35]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 7 12 32 14]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [34 18  6 30]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [26  6 21 13]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [35 14  7 25]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 6 22 16 14]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [10 24 18 35]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [30  2 29 18]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29  4 24 20]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26  2 24 34]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [14 10  5 33]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6  9 28 13]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 27 11  8]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 4  7 31 10]\n",
      "Predicted: [19. 19. 20. 21.]\n",
      "=========================\n",
      "True:      [34  9 22  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19  5  4 28]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [33  8  5 34]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22 16  5 26]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [13 23 32  2]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27  7 15 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12 25 26 14]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [31 10 35 19]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [33 17 19  4]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6 14 12 21]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [25 18 24 19]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [12 34  6 29]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [ 8 20 13 24]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 4  3 27 13]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 12 34  2]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [30 28  1  3]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31  6 28 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 26 16 21]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [23  9  8 15]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22 24  6  7]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 5 11 21  6]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [19 25  4 31]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [31 22 11 19]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [31  3  2 15]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6 25 27 21]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6  4 35  9]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6 27 26 30]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [25 13 33 12]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32 25  9 30]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 18 25 24]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 18  9 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [34 15  7 12]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [20  1 26 22]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [32 30 12 17]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6 35 14 34]\n",
      "Predicted: [19. 20. 20. 21.]\n",
      "=========================\n",
      "True:      [32 24  3 19]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 6 15  3 17]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [25  3  4 10]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [28 10 13 23]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8 17 15 29]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6 13  9 27]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [34 16  8 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 4  7 35 20]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [10 22  9 31]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [34  7  9  5]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25 10 32 26]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [24 16  4  8]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [ 8 17 24 29]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [ 6 28 11 21]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [20  4 25 33]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 30 32  4]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [25 10 15  8]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 8 13 32 23]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [17 27 16  5]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [13  5 16 30]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [30 34  8 25]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [23 19 35 22]\n",
      "Predicted: [17. 17. 19. 19.]\n",
      "=========================\n",
      "True:      [10  3 26 18]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [27 29  9 18]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22 17  2 14]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [31  6 28 20]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [23 11 29 18]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8 27  4 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 2 27 10 28]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27 33  4 12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 29 16 33]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 26 10  9]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25  5  2 35]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [32  8  5 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22 19 35 13]\n",
      "Predicted: [20. 19. 19. 22.]\n",
      "=========================\n",
      "True:      [ 8 33 12 10]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [14  3 34 27]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8  1 22 26]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4 18 15 20]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22 25 28 23]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [16 25 26  7]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [13  2 26 24]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [16 20 34  6]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [27 34 29 33]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [34  9 27 11]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [5 6 3 7]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29 22 26 30]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32 18 26  3]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [20 31  8  4]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [30 18 15 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [33 32 23 28]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [14 34  2  6]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [22 17  3 31]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [11  3  4 13]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6 11 32 25]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 2 20 12  4]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [25 20 26 21]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [24  6  9 15]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [34 32 24 20]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [31  6  7 14]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [16 27 28 20]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [17 33 26 27]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [27  7 11 12]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17 25 28 15]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [13  1  5 10]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [14 23 24 18]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 23 16 34]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4  3 17 15]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [15 27 11  5]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [28  6  3 30]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [34 20 18  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 21 13  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2  6  5 32]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 6 27 20  9]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [18  1 16 19]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [26 34 14 17]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 3 27  2 26]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [ 7 30 31 35]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [20  9 26 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6 17 23 33]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [24 14  7 35]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 15  4 27]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25 34 20  1]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17  6 23  8]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33  1 29  9]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 5 27 33 26]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 5 15 35 26]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [13  6 25 31]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [13  8 10 26]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [20 19 21 28]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8 16 17  9]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [13  6 30 27]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [33  7 15 12]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 1  8 18  5]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [11 24 27 25]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [22  7 32 35]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 7 29 22 26]\n",
      "Predicted: [19. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [25  4 26 27]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [24 30  3  2]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29 22  3 33]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [10 34 30  2]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [23 33  5 35]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12 32  3 27]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6 31 27  2]\n",
      "Predicted: [17. 17. 16. 19.]\n",
      "=========================\n",
      "True:      [11 23  1 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 35 22 28]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22 24 20 18]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [35 20  5 26]\n",
      "Predicted: [18. 19. 18. 20.]\n",
      "=========================\n",
      "True:      [33  1 13 28]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [25  1  4  3]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22 11 16  2]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [16 30 21 15]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 6 33  3  2]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [34  3  1 17]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [28 22 27  8]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1 34 20 32]\n",
      "Predicted: [19. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [11 22 30 17]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 16  4  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1 19  8 11]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [11  1 25 26]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 18 11 15]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [18 16 26  2]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [35 32  4 13]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [16 27 11 31]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6  4 30  3]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [13 10 27 30]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [30 21 10  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25 10  1  3]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8  9 28  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [18  2 20 15]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [18  7 19 20]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [25 22 34  7]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [28  8  5 33]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30  3 11 19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [11  8 31  9]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [23 31 34 33]\n",
      "Predicted: [21. 21. 20. 23.]\n",
      "=========================\n",
      "True:      [30  1  7 20]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [11 30  4 26]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 21 16 34]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13 27  6  7]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [20  5 12  8]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [25 12 32 31]\n",
      "Predicted: [20. 20. 20. 22.]\n",
      "=========================\n",
      "True:      [18 21 16 17]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [14 18 35 22]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [22 16 33  4]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [31 17 32 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 33 31 27]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17 27 24 23]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 22  2 16]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [22  5 27  4]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 28 30 19]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [13 21 25 22]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 33 18 14]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [13 30  2 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 7 16 12 31]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [12 18 34 24]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [14 28 15 12]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 15  3  9]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [26 25 18 23]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3 20  6  5]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31 29 27 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 34 28 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 21  6  7]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [23  2 25 14]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [24 11  1 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 2  6 20 19]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [27 35 18 17]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1 28 17  7]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3  1 18 33]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27 30  9  7]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [29 28 21 26]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [23 16 10 30]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [20 34 32 17]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [18 10 29 16]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [31 21 13  8]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [23  2 18  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13 24 12 15]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [23 34 31 14]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [31 13  4 15]\n",
      "Predicted: [17. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [15 35 20 25]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 9 15 34  5]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9 21 34 27]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26  7 11 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15 13 33 10]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [10  3 31 34]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [17  3 10 24]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11  1 19  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [10 35 31  4]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [20  4 32 26]\n",
      "Predicted: [20. 19. 21. 23.]\n",
      "=========================\n",
      "True:      [ 4  1 11 31]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [30  3 11  2]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [19 14 20 15]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [32  4 30  3]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [34 22 25 15]\n",
      "Predicted: [19. 19. 20. 20.]\n",
      "=========================\n",
      "True:      [29 15 28 30]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [13  3  4 21]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 28 20 10]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [24 10 35 22]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [20 16 31 21]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [33 22 32 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1 23 15  6]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [28 26 17 33]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [34 10  2 22]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [35 15 28 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27  6 15 13]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2  7 10 24]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [28 23 22  9]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [15 14 19 26]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [10 27 17 15]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2 23 14 32]\n",
      "Predicted: [17. 16. 17. 19.]\n",
      "=========================\n",
      "True:      [12 23 33 28]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [13 24 29 22]\n",
      "Predicted: [18. 19. 19. 20.]\n",
      "=========================\n",
      "True:      [35  2 23 17]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 25 22 28]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [12 27  4  3]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [30 21 11 26]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [13 19  4 33]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 26  3 14]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [27 15 28  5]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8 11  2 27]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11  8  7  4]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [18 33 13  8]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 4 19 32  7]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [18 33 17 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 5 22 19 15]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29 34  6 23]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [24 26 22 27]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [20 12 16 33]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 7 18  9  8]\n",
      "Predicted: [16. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [35 21 20 34]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [14  1 27 22]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9  7 23 10]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19 29 12 11]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [28  2 17 23]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [31 27  8 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [23 21  4  1]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [20 28 24  2]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [33  7  1 23]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [20 25 22 16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [12 27 28 13]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [32 25 23  1]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 7 33  3 16]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [10  6 11 33]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [26 27 22 32]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [20 30  2  1]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 5 17 16  4]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [18 30 17 16]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [35 13 20 23]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15  1 24 16]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 16 26  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29 26 23 21]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8 15 34 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [18 34 27 14]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 28 32  4]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4  3 33  2]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3  2 18  7]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [28  2 32 13]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [27 25 23 32]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [20  8 25 18]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [27 32 14 30]\n",
      "Predicted: [18. 17. 19. 20.]\n",
      "=========================\n",
      "True:      [30  8 15 13]\n",
      "Predicted: [17. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [10 11 16 27]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 33 26 24]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [33 25 27 26]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [ 4  9 20 24]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [10  5 24 15]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 2 32 22 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12 11  9 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 5 29 35 31]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 5 33 11 27]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 29 26 33]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [28 29 20  7]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [12 10 13 32]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [10  4  7  1]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 23 15 27]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [28  9  3 11]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27 22 11 18]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13  3 34 26]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [32  7 12  1]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [16 34 13 27]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [21 34 17 28]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [31 30  5 13]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [26 12 18 15]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [31 35 12 27]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [19 23  8 35]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 30  3 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6 20 14 28]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 9 34 14  7]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [10 34 24 29]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12 15  6 23]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [28 17 27  7]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [35 18 14  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [14 10 22 13]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [28 32 15  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32 35 17 23]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [16 23  3 30]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [24 10 28 13]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25 30 15  1]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [31  2  1 32]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31 23 22 32]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8  5  3 10]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [10  4 27  9]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22 23 32 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32 21  4 29]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8 33 16 13]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [20 31 15  5]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [35  7 28 34]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [35 16 15 30]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [25 23 16 35]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [29 30  4 14]\n",
      "Predicted: [19. 19. 19. 20.]\n",
      "=========================\n",
      "True:      [ 5 35  2 13]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [15 16 33 30]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [30 13 35 32]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 7 34 10 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32 22 16  8]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [11 25 27 20]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [11 18  1 23]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [15 11 13 24]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [22 29  7 21]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [29  2 28 25]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19 14  2 25]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [29 13 19  8]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [11  3  6 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17  8 24  3]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [14  2 18 24]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [31 20  6 24]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [25 32 33 13]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [28  3  5  4]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8  5 17 34]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [30 32 20  4]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8 30 32 29]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [14  4  6  2]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [25 21 34 26]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 28 20 25]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [25  2 21  6]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 30 27  2]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [34 24 33 17]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [15 28 32 24]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [12 28  5 31]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [23 35 27  8]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [18  6 25 11]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9  3 19 30]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8  7 35  6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [16 28 31 29]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 19 29 13]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9  3 19 23]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6  1 25 11]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 18  2 14]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 3 27 25 14]\n",
      "Predicted: [19. 19. 20. 22.]\n",
      "=========================\n",
      "True:      [33 13 30 29]\n",
      "Predicted: [20. 19. 20. 22.]\n",
      "=========================\n",
      "True:      [21 22  7 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8 15 11 35]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31 17  3 34]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 27 13  6]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8  5 34  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 7 22 12  3]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [19 10 27  9]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6 32  9 13]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [18 26 11 30]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4  8 11 27]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8 33  6 14]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 26 30 15]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 8 27  7  2]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [30  7 25 29]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6  4 33  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [20 24 33 29]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [28 34 25 22]\n",
      "Predicted: [20. 20. 20. 22.]\n",
      "=========================\n",
      "True:      [21 20 31  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [15  2 23 24]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [31 33 30 32]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [10 20 33 32]\n",
      "Predicted: [16. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [ 7 33 25  5]\n",
      "Predicted: [17. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [ 6 18  4 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 26 11 35]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [35 12 11 24]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 10 16 34]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [28  7 34 22]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [26  7  2 20]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [28 22  2 33]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [27 22  5  3]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [12 35 15 21]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 5 15 32 20]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8  7 26 10]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4 12 17 18]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [33 21  6 14]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [35  4 30 32]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [29  7 18 21]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [20 23  9 17]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [10 16  5 27]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [17  3 10 25]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [10 19 29 12]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [16 12 19 29]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [35 33 26 22]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [25  3 27  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [16 25  4 28]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [ 2  4 14 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 22  8 34]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15 22 16 19]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [21  2 28 16]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [15 34 30  9]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8 15 11  5]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [21 33 26 15]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [20 28 27 35]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [32 31 34 25]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [20  1  6 25]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [ 1 15 18 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26 35 31 33]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [25  6  8 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [19 21 26 14]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 30 12 33]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [21 26 18  2]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [32 31  5  7]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [18 22 34 30]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [28 21 11  8]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [23  3 20 27]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [16 12 19  3]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [35 28 10 30]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [27  3 19 15]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7  1 15 26]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [29  8 22 26]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6  1 14  4]\n",
      "Predicted: [17. 16. 18. 18.]\n",
      "=========================\n",
      "True:      [ 9 34 15 32]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [15 21 32 16]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [11  4  6 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [10 12 32 16]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4  1 17 23]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9  4 16 10]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [27  7 32 19]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 28  2 33]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 30 28 22]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [22 25  3 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [15 23 18 14]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [16 30 29  5]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [22 12  4 20]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [16 32  2 34]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19 20 14 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12 30 32  3]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [24  8 20 26]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [14  3 12 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [16 27 35 21]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [30  7 26 10]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [11 29 24 30]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 4 25 27 23]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [23 20  5 28]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [35 15 20 29]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33 14 18 19]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9 10  2 30]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9  8 12 35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [16. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [ 5 21 18  2]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 32 10 21]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2 14 12 26]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6 35 10 25]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [21 10 31  6]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11  6 19  2]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9  4 14 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 4 18 29 15]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22 28 32 12]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [33 27  3 35]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 11 10 21]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [20 28 15 22]\n",
      "Predicted: [18. 19. 19. 20.]\n",
      "=========================\n",
      "True:      [15 16 30 29]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [32 33 14 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 10 35  5]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1  9 19 27]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25 18  5  7]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15 27  8  6]\n",
      "Predicted: [16. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [15 18  5  1]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 9 13  3 32]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [34  4 13 21]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25 15  1 21]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [27  4 29 10]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9 10  7 32]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26 33  6 25]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3  9 28 16]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [33 19 23 10]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [23  2 13 17]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 2  3 13 14]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29 28 11 25]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 23  4 28]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 5  6 25 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [13 25  7  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [24 18 23 26]\n",
      "Predicted: [17. 17. 16. 19.]\n",
      "=========================\n",
      "True:      [17 19 28 34]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 19 11 35]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [35 13  3 17]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [22  3  8 25]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [10 28 17  1]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [27 17 31 30]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 5 21 24 25]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 20 32 33]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [11 21  3 25]\n",
      "Predicted: [16. 16. 16. 18.]\n",
      "=========================\n",
      "True:      [11  5  8 10]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [16 25 12 30]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [21 31 10 16]\n",
      "Predicted: [17. 17. 16. 19.]\n",
      "=========================\n",
      "True:      [ 6  1 27 16]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [19  6  5 14]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [12 35  4  1]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [31 25 17 10]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8 35  6 17]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [13 27 15 28]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27 33 20 14]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 2 34 11 27]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [30 33 19 11]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [23 21  7 25]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22 23 19  7]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 26 31  2]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [27 17  1  8]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [18 15 31 13]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [16 26 20 31]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [14  8 22 35]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 7  4 30 15]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3 25 34 17]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27  8  9 12]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [19 25  8  2]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29 34 10 17]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31  5 27  4]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26  4 21 15]\n",
      "Predicted: [20. 19. 19. 22.]\n",
      "=========================\n",
      "True:      [17  1  6 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [33 15  6 27]\n",
      "Predicted: [22. 21. 21. 24.]\n",
      "=========================\n",
      "True:      [ 7 11 23 24]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 8 29 16 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [24  4  1 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [25 33  4 13]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [10 31 28 11]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [20 27 14 34]\n",
      "Predicted: [19. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [26 17 32 13]\n",
      "Predicted: [22. 22. 21. 24.]\n",
      "=========================\n",
      "True:      [32 26 28  9]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [23  6 32 27]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9  6  4 35]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19  5 26 22]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22 34 11 15]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 4 10 26 14]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 6 28 12 20]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6  4 22  7]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 9 18 13 24]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1  2 12 34]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 33 13  3]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [27 21 14 30]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [17 27 26  4]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [34 25 24  6]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [33  9 28 12]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [23 25  3 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [13  9  1  6]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [21 30 19 18]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3 35 31 32]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [16 10 13 20]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [29 23 16  5]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 1  9 29  5]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [11 28 24 31]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5 31 22  1]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 9 27  1 32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 4  6 17 16]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 7  8 25 11]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [35 23 26 12]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [12 22 17 33]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 6 18 12 30]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15 29 26  3]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11 26 24 14]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [29  9 26 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [24 18 30 26]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [ 4 23  9  8]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [33 19 30  6]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [32 22 11 29]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [ 5 14 28 11]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26 17 24 18]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [19  3 27 29]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 11 31 28]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 14 30 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [13 32  9 29]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [23  8  1  4]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 7 22 14  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [14 13 15 33]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 32 10  6]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25 10 27  7]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [21 34 35 13]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [27 33 15  3]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [32 16 22 30]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22 34  6 33]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [22 27 16  5]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [25 26 20  8]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [30 25 21 35]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [35 33  9 15]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [28 20 32 10]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25 30 23  5]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [22 25  8 23]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 22 18 19]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [34 15 12 27]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26  6 19 18]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [14 35 32 15]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [12 26 27 25]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [26  9 10 27]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [34  2 12 24]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [10 30 34 16]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [24 13 23 21]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [17  2 24 20]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [11 30  7 12]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31 32 26  2]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 9 22 27  3]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [21 13 11 28]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1  6 15 16]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [17 34 24  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [15 35 31 17]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [28 25 16 23]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [27 31 20 26]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [16 27 31 18]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [22 31  7  6]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [32  4 25 31]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 31 32 13]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [34 12  4 24]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26  3  6 21]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 25 10  6]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [30 25  5 15]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [34 24 14 23]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [ 5 30 12  6]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6 31 27  4]\n",
      "Predicted: [19. 18. 19. 21.]\n",
      "=========================\n",
      "True:      [10  2 20 19]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [22 21 26 33]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [16  7 28 17]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 2 32 12 10]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [15 28  6  2]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25 33 15 30]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [10 11 16 28]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [11 17 34 28]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 7  2 34 17]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [19 10  1 35]\n",
      "Predicted: [17. 16. 17. 19.]\n",
      "=========================\n",
      "True:      [18 34 30 27]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [33 17 34 23]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [31 21 19 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32 31 21 23]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [28 30 16  4]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 3 27 17  4]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [12  7 17  1]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13 32  2 34]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6 17 29 25]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [14 30  2 31]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [22  6 34  7]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17  6 33 25]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [30 25 35  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17 35 31 15]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [35 31 27 17]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [22 20  8 35]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [19 23  5 28]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [13 33 12  5]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 1  9 31 34]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 21 31  1]\n",
      "Predicted: [19. 18. 18. 21.]\n",
      "=========================\n",
      "True:      [26 21 35 18]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [17  2 32 13]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [27  2 33 20]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [21 15 28 14]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [10 13 35 14]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3 25 30 15]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [18  7 34 26]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [22 13 16 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 8 18 16 23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [10  8 28  1]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2 20  6 17]\n",
      "Predicted: [16. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [13 16 27 26]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [ 3 10  7  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 1 23 13 25]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26  3  8 25]\n",
      "Predicted: [19. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [25  3 34 21]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [17 26 31  7]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [35  4 16 23]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [25 19 15  7]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [26 29 15 32]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [34 35  9 29]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [10 24 13  2]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [34 31 17  7]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [19 18 24 34]\n",
      "Predicted: [18. 18. 19. 19.]\n",
      "=========================\n",
      "True:      [21 16 26 13]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 7 21 25 10]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 9 12 34 35]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [10 30 21  4]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8 26 20  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1 20  5 26]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [30  6  9 28]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 7 29 30 14]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 12 13 35]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [25 19 24  6]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1 11  2 27]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2 29 11 24]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [32 35  6 19]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [ 8 18 25 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 5 30 18  2]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 23  8 21]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [ 3 21  5 13]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [ 1 22 31 25]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [32  3 22 15]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 4 19 14 23]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [18 15 21 28]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [34 11  5 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [32 16 17  6]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 3 28  4 25]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [21 32  8 23]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [25 20  2 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [31 33 19 17]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [11 33  6 31]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [22 23 24 34]\n",
      "Predicted: [20. 20. 20. 22.]\n",
      "=========================\n",
      "True:      [11  5 23 22]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1 34 26  8]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33 19  2 20]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [14 13 22  9]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [21  2 24 35]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [25  5  4 24]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [13 14 30 35]\n",
      "Predicted: [20. 19. 20. 21.]\n",
      "=========================\n",
      "True:      [ 4 33 35 27]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [22 27 13 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [12  3  7 34]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [17 16  8 31]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [35 14 19 30]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [20 33 17 18]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 26 32 35]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [17  1  9 33]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [34 19 15  1]\n",
      "Predicted: [20. 19. 19. 22.]\n",
      "=========================\n",
      "True:      [ 7 21 24  8]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17 28 11 26]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 1 35 28  2]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 2 14  3 30]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 35 27 29]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6 29 34 10]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [14  1 23  9]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [24 18  9 28]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [33 25  6 19]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [20 16 13 30]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [14 19 35 22]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8 18 22 19]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 2  6 15 24]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [25 11 16 20]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 2 32 14 34]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8 16  6  2]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 8 31 32 21]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [35 28  8 20]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 26 11 35]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [33 10 31 15]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26  3  5  9]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 6 20 16 17]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 24  4  2]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [25 35  7 30]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [27  2 17 28]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [18  2 19 25]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [35  4 21 27]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31  6 30 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26  5 10 30]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [17 34 33 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17 22  2 14]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29 34 27 26]\n",
      "Predicted: [20. 19. 19. 22.]\n",
      "=========================\n",
      "True:      [12 22 32 18]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [32 11 10 23]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [19  3 23 30]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [ 5  7 30 26]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 7 33  2 19]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [25 19  9 29]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [ 8 30  2 18]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [18 14 25  3]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [ 4 24 27  2]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 1  4 29 10]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [19 30 22 18]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [13 31 33 20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [18 20  1 35]\n",
      "Predicted: [21. 20. 19. 22.]\n",
      "=========================\n",
      "True:      [34 27  3 14]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [12 33  4  7]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [31 16 23 35]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29 27 21 19]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11 10 13 18]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [27 17  9 14]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [26 27 16 25]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [32  5 23 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26 31 24 23]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [32  4 28 34]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [29 32  1 19]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [ 7  2 16 28]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [25 10 24 31]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11 28  9  2]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [1 5 9 4]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [15 33  9  1]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 5 15 10  8]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [ 3 18 15 20]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 27 34  1]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [10 26  4 29]\n",
      "Predicted: [17. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [10  5 30 24]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [21 33  5 28]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [25  6 19 15]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [18 29 12  7]\n",
      "Predicted: [18. 18. 17. 19.]\n",
      "=========================\n",
      "True:      [ 7 13  6 14]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [33 23 14 18]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [26  6 12 35]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 8  9 35 34]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 7  2 18 21]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [29 13 16 26]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [24  3 35 22]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [24 34 16 30]\n",
      "Predicted: [18. 18. 17. 20.]\n",
      "=========================\n",
      "True:      [30 26  8 20]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [30 34  1  8]\n",
      "Predicted: [19. 19. 18. 21.]\n",
      "=========================\n",
      "True:      [19 31  1 33]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30  8 29  5]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [18 24 15 32]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17 35  8 12]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 24 21 29]\n",
      "Predicted: [18. 17. 18. 20.]\n",
      "=========================\n",
      "True:      [11 14 19 16]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [34  3  6 31]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [25 32  7  4]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [11 32 23 22]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 3 26 20 17]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [32 27 23  8]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [ 4 32 19 26]\n",
      "Predicted: [18. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [17  4 26 34]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [19 31 22  9]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [10  4 15  8]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [16 23 31 12]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [23 18 14 24]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [21 28 32 10]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [17 34 33 12]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [11  5 20 17]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [24  2 16 14]\n",
      "Predicted: [17. 17. 17. 18.]\n",
      "=========================\n",
      "True:      [27 29 34 25]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [34 15  2  3]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [17 24  9  5]\n",
      "Predicted: [17. 17. 18. 18.]\n",
      "=========================\n",
      "True:      [ 7 11 33 20]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [34 27  2  6]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [11 30 17 22]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [26  4 22  3]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 1 12 20 33]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [ 9 24 28  6]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [23  4 28  1]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [17 25 22 29]\n",
      "Predicted: [19. 19. 19. 21.]\n",
      "=========================\n",
      "True:      [11 14 30 29]\n",
      "Predicted: [17. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [16 30  5  2]\n",
      "Predicted: [16. 16. 17. 18.]\n",
      "=========================\n",
      "True:      [23  1 15 29]\n",
      "Predicted: [18. 18. 19. 20.]\n",
      "=========================\n",
      "True:      [31 22 18 20]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [32 22 17 28]\n",
      "Predicted: [18. 17. 17. 20.]\n",
      "=========================\n",
      "True:      [11 20 27 26]\n",
      "Predicted: [21. 21. 20. 23.]\n",
      "=========================\n",
      "True:      [ 6  4 35 18]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [30 35 11  4]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [ 4 32 18 29]\n",
      "Predicted: [18. 18. 18. 20.]\n",
      "=========================\n",
      "True:      [13 32  2 33]\n",
      "Predicted: [18. 18. 18. 19.]\n",
      "=========================\n",
      "True:      [ 5  3 23 17]\n",
      "Predicted: [17. 17. 17. 19.]\n",
      "=========================\n",
      "True:      [33 29  6 24]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [35 31 22 23]\n",
      "Predicted: [21. 20. 19. 22.]\n",
      "=========================\n",
      "True:      [16 29 23 35]\n",
      "Predicted: [18. 17. 18. 19.]\n",
      "=========================\n",
      "True:      [29 25 22 10]\n",
      "Predicted: [22. 21. 21. 23.]\n",
      "=========================\n",
      "True:      [25 24 18  2]\n",
      "Predicted: [17. 17. 18. 19.]\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "# PREDICT ON TRAIN SET\n",
    "def predict_train( model, X_, y_ ):\n",
    "    \n",
    "    for feature_set, target in zip( X_, y_ ):\n",
    "        print('True:     ', target)\n",
    "        print('Predicted:', predict_one( model, feature_set ))\n",
    "        print('='*25)\n",
    "        \n",
    "predict_train( model, X_sh, y_sh )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE scores: [104.5452, 104.857, 105.5248, 106.6055, 106.9758, 105.0289, 104.3018, 105.3817, 110.9081, 106.2181, 104.7653, 105.1386, 104.5072, 104.7629, 105.6863]\n",
      "Log cosh scores: [8.162, 8.1708, 8.202, 8.2316, 8.2359, 8.1885, 8.1628, 8.1941, 8.3733, 8.2111, 8.176, 8.1857, 8.1729, 8.1721, 8.218]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#metrics = metrics[:]\n",
    "y1 = [i[0] for i in metrics if 'KFold' in i[3]]\n",
    "y2 = [i[1] for i in metrics if 'KFold' in i[3]]\n",
    "print('MSE scores:', y1)\n",
    "print('Log cosh scores:', y2)\n",
    "x = range(0,len(y1))\n",
    "xtick_labels = [i[2] for i in metrics if 'KFold' in i[3]]\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(y1)\n",
    "plt.xticks(x, xtick_labels)\n",
    "plt.title('HP Gridsearch: Dropout2 (KFold)')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(y2)\n",
    "plt.xticks(x, xtick_labels)\n",
    "plt.title('HP Gridsearch: Dropout2 (KFold)')\n",
    "plt.ylabel('Logcosh')\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26708"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other n_steps (not 4) with the best hp\n",
    "Predict one, predict all five\n",
    "Cubic, quadratic linear regr  \n",
    "Also, possible features:\n",
    "* number of even numbers\n",
    "* number of simple, fibbonachi numbers\n",
    "* number of any other numbers - Types of integer numbers at https://en.wikipedia.org/wiki/List_of_types_of_numbers\n",
    "* binary or any other base numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Searching for best number of units in LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv( X_, y_, cv_folds, ts_flag=False, units=500, batch_size=32, epochs=6 ):\n",
    "        \n",
    "    print( f'Stacked_BiLSTM, units {units}, cv method {cv_folds.__str__()}' )\n",
    "    print( f'                batch_size {batch_size}, num epochs {epochs}')\n",
    "    verbose = 0\n",
    "    score_per_fold, loss_per_fold = [], []\n",
    "\n",
    "    fold_no = 1\n",
    "    for train_idx, test_idx in cv_folds.split( X_ ):\n",
    "\n",
    "        # Define and compile model\n",
    "        model = stacked_BiLSTM( n_steps, n_features, units=units )\n",
    "\n",
    "        print('\\n', '='*100, '\\n', sep='')\n",
    "        print('Training in fold {} ...'.format( fold_no ))\n",
    "\n",
    "        # Fit data to model\n",
    "        if ts_flag:\n",
    "            history = model.fit( X_[train_idx], y_[train_idx],\n",
    "                                 batch_size=batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 shuffle=False,\n",
    "                                 verbose=verbose )\n",
    "        else:\n",
    "            history = model.fit( X_[train_idx], y_[train_idx],\n",
    "                                 batch_size=batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 shuffle=True,\n",
    "                                 verbose=verbose )\n",
    "\n",
    "        # Generate metrics\n",
    "        scores = model.evaluate( X_[test_idx], y_[test_idx], verbose=verbose )\n",
    "        print(f'Score in fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}')\n",
    "        score_per_fold.append( scores[1] )\n",
    "        loss_per_fold.append(  scores[0] )\n",
    "\n",
    "        # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "        \n",
    "    # Average scores\n",
    "    average_loss  = round( np.mean(loss_per_fold), 4 )\n",
    "    average_std   = round( np.std(loss_per_fold), 4 )\n",
    "    average_score = round( np.mean(score_per_fold), 4)\n",
    "    print( '\\n', '='*100, sep='' )\n",
    "    print( f'Average metrics for the run with {units} units, cv method {cv_folds.__str__()}, batch_size {batch_size} and number of epochs {epochs}')\n",
    "    print('Per fold:')\n",
    "    print( '{:>10}{:^10}{:^10}{:^10}{:^10}{:^10}'.format('', 1, 2, 3, 4, 5) )\n",
    "    print( '{:<10}{:^10}{:^10}{:^10}{:^10}{:^10}'.format( 'Loss',  *[ round(i, 4) for i in loss_per_fold  ] ) )\n",
    "    print( '{:<10}{:^10}{:^10}{:^10}{:^10}{:^10}'.format( 'Score', *[ round(i, 4) for i in score_per_fold ] ) )\n",
    "    print( '='*100 )\n",
    "    print(f'Average loss:  {average_loss}  +-{average_std}')\n",
    "    print(f'Average score: {average_score}')\n",
    "    print( '='*100 )\n",
    "    \n",
    "    return average_loss, average_std, average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "cv_engines = [ tscv, kf ]\n",
    "num_units_list = [ 25, 50, 100, 200, 400, 500, 750, 1000, 1500, 2000, 3000, 4000, 5000, 7000 ]\n",
    "for cv_engine in cv_engines:\n",
    "    for num_units in num_units_list:\n",
    "        \n",
    "        ts_flag = 'TimeSeriesSplit' in cv_engine.__str__()\n",
    "        if ts_flag:\n",
    "            loss, std, score = run_cv( X, y, cv_engine, ts_flag, units=num_units)\n",
    "        else:\n",
    "            loss, std, score = run_cv( X_sh, y_sh, cv_engine, ts_flag, units=num_units)\n",
    "                        \n",
    "        metrics.append(( loss, score, num_units, cv_engine.__str__() ))\n",
    "        print('metrics =', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Searching for the best LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv( X_, y_, cv_folds, ts_flag=False, learning_rate=0.001, batch_size=32, epochs=6 ):\n",
    "        \n",
    "    print( f'Stacked_BiLSTM, learning_rate {learning_rate}, cv method {cv_folds.__str__()}' )\n",
    "    print( f'                batch_size {batch_size}, num epochs {epochs}')\n",
    "    verbose = 0\n",
    "    score_per_fold, loss_per_fold = [], []\n",
    "\n",
    "    fold_no = 1\n",
    "    for train_idx, test_idx in cv_folds.split( X_ ):\n",
    "\n",
    "        # Define and compile model\n",
    "        model = stacked_BiLSTM( n_steps, n_features, learning_rate=learning_rate )\n",
    "\n",
    "        print('\\n', '='*100, '\\n', sep='')\n",
    "        print('Training in fold {} ...'.format( fold_no ))\n",
    "\n",
    "        # Fit data to model\n",
    "        if ts_flag:\n",
    "            history = model.fit( X_[train_idx], y_[train_idx],\n",
    "                                 batch_size=batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 shuffle=False,\n",
    "                                 verbose=verbose )\n",
    "        else:\n",
    "            history = model.fit( X_[train_idx], y_[train_idx],\n",
    "                                 batch_size=batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 shuffle=True,\n",
    "                                 verbose=verbose )\n",
    "\n",
    "        # Generate metrics\n",
    "        scores = model.evaluate( X_[test_idx], y_[test_idx], verbose=verbose )\n",
    "        print(f'Score in fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}')\n",
    "        score_per_fold.append( scores[1] )\n",
    "        loss_per_fold.append(  scores[0] )\n",
    "\n",
    "        # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "        \n",
    "    # Average scores\n",
    "    average_loss  = round( np.mean(loss_per_fold), 4 )\n",
    "    average_std   = round( np.std(loss_per_fold), 4 )\n",
    "    average_score = round( np.mean(score_per_fold), 4)\n",
    "    print( '\\n', '='*100, sep='' )\n",
    "    print( f'Average metrics for the run with learning_rate {learning_rate}, cv method {cv_folds.__str__()}, batch_size {batch_size} and number of epochs {epochs}')\n",
    "    print('Per fold:')\n",
    "    print( '{:>10}{:^10}{:^10}{:^10}{:^10}{:^10}'.format('', 1, 2, 3, 4, 5) )\n",
    "    print( '{:<10}{:^10}{:^10}{:^10}{:^10}{:^10}'.format( 'Loss',  *[ round(i, 4) for i in loss_per_fold  ] ) )\n",
    "    print( '{:<10}{:^10}{:^10}{:^10}{:^10}{:^10}'.format( 'Score', *[ round(i, 4) for i in score_per_fold ] ) )\n",
    "    print( '='*100 )\n",
    "    print(f'Average loss:  {average_loss}  +-{average_std}')\n",
    "    print(f'Average score: {average_score}')\n",
    "    print( '='*100 )\n",
    "    \n",
    "    return average_loss, average_std, average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked_BiLSTM, learning_rate 0.5, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.5, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss         nan       nan       nan       nan       nan    \n",
      "Score        nan       nan       nan       nan       nan    \n",
      "====================================================================================================\n",
      "Average loss:  nan  +-nan\n",
      "Average score: nan\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 0.1, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.1, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss         nan       nan       nan       nan       nan    \n",
      "Score        nan       nan       nan       nan       nan    \n",
      "====================================================================================================\n",
      "Average loss:  nan  +-nan\n",
      "Average score: nan\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 0.05, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 238.26144409179688; logcosh of 12.046204566955566\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 111.7806625366211; logcosh of 8.350887298583984\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 111.2759780883789; logcosh of 8.227836608886719\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 129.28640747070312; logcosh of 8.959047317504883\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 107.62639617919922; logcosh of 8.238895416259766\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.05, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       238.2614  111.7807  111.276   129.2864  107.6264 \n",
      "Score      12.0462    8.3509    8.2278    8.959     8.2389  \n",
      "====================================================================================================\n",
      "Average loss:  139.6462  +-49.8777\n",
      "Average score: 9.1646\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 0.01, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 108.53181457519531; logcosh of 8.343819618225098\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.44126892089844; logcosh of 8.139719009399414\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 105.52467346191406; logcosh of 8.209612846374512\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.91162109375; logcosh of 8.316987991333008\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.9525146484375; logcosh of 8.175243377685547\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.01, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       108.5318  103.4413  105.5247  107.9116  104.9525 \n",
      "Score       8.3438    8.1397    8.2096    8.317     8.1752  \n",
      "====================================================================================================\n",
      "Average loss:  106.0724  +-1.8925\n",
      "Average score: 8.2371\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 0.005, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 109.48739624023438; logcosh of 8.34374713897705\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in fold 2: loss of 106.45098876953125; logcosh of 8.203845024108887\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.68387603759766; logcosh of 8.08864688873291\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.08666229248047; logcosh of 8.32175350189209\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.97423553466797; logcosh of 8.181370735168457\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.005, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       109.4874  106.451   102.6839  108.0867  104.9742 \n",
      "Score       8.3437    8.2038    8.0886    8.3218    8.1814  \n",
      "====================================================================================================\n",
      "Average loss:  106.3366  +-2.3749\n",
      "Average score: 8.2279\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 0.001, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 109.61918640136719; logcosh of 8.388102531433105\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.83737182617188; logcosh of 8.179863929748535\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.47686004638672; logcosh of 8.132969856262207\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.15608978271484; logcosh of 8.248964309692383\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 107.37228393554688; logcosh of 8.230302810668945\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.001, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       109.6192  106.8374  104.4769  106.1561  107.3723 \n",
      "Score       8.3881    8.1799    8.133     8.249     8.2303  \n",
      "====================================================================================================\n",
      "Average loss:  106.8924  +-1.676\n",
      "Average score: 8.236\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 0.0005, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 110.12086486816406; logcosh of 8.37507152557373\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 107.17984771728516; logcosh of 8.196575164794922\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 105.02462768554688; logcosh of 8.14013671875\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 105.58919525146484; logcosh of 8.227079391479492\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.8335952758789; logcosh of 8.188935279846191\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.0005, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       110.1209  107.1798  105.0246  105.5892  105.8336 \n",
      "Score       8.3751    8.1966    8.1401    8.2271    8.1889  \n",
      "====================================================================================================\n",
      "Average loss:  106.7496  +-1.8282\n",
      "Average score: 8.2256\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 0.0001, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 115.25186157226562; logcosh of 8.52528190612793\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 105.8456039428711; logcosh of 8.156290054321289\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.95807647705078; logcosh of 8.106749534606934\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.11630249023438; logcosh of 8.240338325500488\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 107.29440307617188; logcosh of 8.23220443725586\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.0001, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       115.2519  105.8456  103.9581  106.1163  107.2944 \n",
      "Score       8.5253    8.1563    8.1067    8.2403    8.2322  \n",
      "====================================================================================================\n",
      "Average loss:  107.6932  +-3.9279\n",
      "Average score: 8.2522\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 5e-05, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 118.67880249023438; logcosh of 8.619885444641113\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 108.08759307861328; logcosh of 8.212772369384766\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 105.0899658203125; logcosh of 8.160932540893555\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.84686279296875; logcosh of 8.265060424804688\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 107.29280090332031; logcosh of 8.241986274719238\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 5e-05, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       118.6788  108.0876   105.09   106.8469  107.2928 \n",
      "Score       8.6199    8.2128    8.1609    8.2651    8.242   \n",
      "====================================================================================================\n",
      "Average loss:  109.1992  +-4.8405\n",
      "Average score: 8.3001\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 1e-05, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 358.90325927734375; logcosh of 15.332452774047852\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 132.4338836669922; logcosh of 8.936198234558105\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 116.93327331542969; logcosh of 8.505659103393555\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 113.22477722167969; logcosh of 8.484859466552734\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 113.91851043701172; logcosh of 8.429458618164062\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 1e-05, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       358.9033  132.4339  116.9333  113.2248  113.9185 \n",
      "Score      15.3325    8.9362    8.5057    8.4849    8.4295  \n",
      "====================================================================================================\n",
      "Average loss:  167.0827  +-96.1642\n",
      "Average score: 9.9377\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 5e-06, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 413.0169982910156; logcosh of 16.843280792236328\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 342.3728332519531; logcosh of 15.020635604858398\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 219.3359375; logcosh of 11.248483657836914\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 119.56926727294922; logcosh of 8.663108825683594\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 119.40897369384766; logcosh of 8.570865631103516\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 5e-06, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       413.017   342.3728  219.3359  119.5693  119.409  \n",
      "Score      16.8433   15.0206   11.2485    8.6631    8.5709  \n",
      "====================================================================================================\n",
      "Average loss:  242.7408  +-118.195\n",
      "Average score: 12.0693\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 1e-06, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 430.1340026855469; logcosh of 17.317054748535156\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in fold 2: loss of 435.4546813964844; logcosh of 17.59618377685547\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 385.1512451171875; logcosh of 16.185821533203125\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 393.0223083496094; logcosh of 16.356016159057617\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 380.2164001464844; logcosh of 15.96224308013916\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 1e-06, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       430.134   435.4547  385.1512  393.0223  380.2164 \n",
      "Score      17.3171   17.5962   16.1858    16.356   15.9622  \n",
      "====================================================================================================\n",
      "Average loss:  404.7957  +-23.2837\n",
      "Average score: 16.6835\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 5e-07, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 427.1650695800781; logcosh of 17.231225967407227\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 446.43505859375; logcosh of 17.8934383392334\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 384.2265319824219; logcosh of 16.15959358215332\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 424.7583923339844; logcosh of 17.239604949951172\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 405.9132385253906; logcosh of 16.688127517700195\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 5e-07, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       427.1651  446.4351  384.2265  424.7584  405.9132 \n",
      "Score      17.2312   17.8934   16.1596   17.2396   16.6881  \n",
      "====================================================================================================\n",
      "Average loss:  417.6997  +-21.0927\n",
      "Average score: 17.0424\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 1e-07, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 438.74237060546875; logcosh of 17.545682907104492\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 448.0445251464844; logcosh of 17.93428611755371\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 398.8598327636719; logcosh of 16.58365821838379\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 432.99908447265625; logcosh of 17.467300415039062\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 406.76397705078125; logcosh of 16.7177677154541\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 1e-07, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       438.7424  448.0445  398.8598  432.9991  406.764  \n",
      "Score      17.5457   17.9343   16.5837   17.4673   16.7178  \n",
      "====================================================================================================\n",
      "Average loss:  425.082  +-18.9722\n",
      "Average score: 17.2497\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, learning_rate 0.5, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.5, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss         nan       nan       nan       nan       nan    \n",
      "Score        nan       nan       nan       nan       nan    \n",
      "====================================================================================================\n",
      "Average loss:  nan  +-nan\n",
      "Average score: nan\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, learning_rate 0.1, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of nan; logcosh of nan\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.1, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss         nan       nan       nan       nan       nan    \n",
      "Score        nan       nan       nan       nan       nan    \n",
      "====================================================================================================\n",
      "Average loss:  nan  +-nan\n",
      "Average score: nan\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (nan, nan, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, learning_rate 0.05, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 111.31134796142578; logcosh of 8.432792663574219\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 112.63285827636719; logcosh of 8.362203598022461\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 119.95361328125; logcosh of 8.589438438415527\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 123.84813690185547; logcosh of 8.818315505981445\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 112.38566589355469; logcosh of 8.400145530700684\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.05, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       111.3113  112.6329  119.9536  123.8481  112.3857 \n",
      "Score       8.4328    8.3622    8.5894    8.8183    8.4001  \n",
      "====================================================================================================\n",
      "Average loss:  116.0263  +-4.972\n",
      "Average score: 8.5206\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (nan, nan, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (116.0263, 8.5206, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, learning_rate 0.01, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 107.66251373291016; logcosh of 8.328526496887207\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.319091796875; logcosh of 8.066643714904785\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 108.68247985839844; logcosh of 8.308956146240234\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.15628051757812; logcosh of 8.262124061584473\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 102.42111206054688; logcosh of 8.07724380493164\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.01, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       107.6625  103.3191  108.6825  106.1563  102.4211 \n",
      "Score       8.3285    8.0666    8.309     8.2621    8.0772  \n",
      "====================================================================================================\n",
      "Average loss:  105.6483  +-2.4233\n",
      "Average score: 8.2087\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (nan, nan, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (116.0263, 8.5206, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6483, 8.2087, 0.01, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, learning_rate 0.005, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 106.27617645263672; logcosh of 8.264941215515137\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.59310913085938; logcosh of 8.060259819030762\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.93461608886719; logcosh of 8.166275978088379\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.80693054199219; logcosh of 8.305181503295898\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.3052749633789; logcosh of 8.129793167114258\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.005, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       106.2762  103.5931  103.9346  107.8069  104.3053 \n",
      "Score       8.2649    8.0603    8.1663    8.3052    8.1298  \n",
      "====================================================================================================\n",
      "Average loss:  105.1832  +-1.6085\n",
      "Average score: 8.1853\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (nan, nan, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (116.0263, 8.5206, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6483, 8.2087, 0.01, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1832, 8.1853, 0.005, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, learning_rate 0.001, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 112.31792449951172; logcosh of 8.429262161254883\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 110.98921203613281; logcosh of 8.358238220214844\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.45430755615234; logcosh of 8.169978141784668\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.0859375; logcosh of 8.281391143798828\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 103.05290222167969; logcosh of 8.110638618469238\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.001, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       112.3179  110.9892  104.4543  107.0859  103.0529 \n",
      "Score       8.4293    8.3582     8.17     8.2814    8.1106  \n",
      "====================================================================================================\n",
      "Average loss:  107.5801  +-3.5939\n",
      "Average score: 8.2699\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (nan, nan, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (116.0263, 8.5206, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6483, 8.2087, 0.01, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1832, 8.1853, 0.005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.5801, 8.2699, 0.001, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, learning_rate 0.0005, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 109.73755645751953; logcosh of 8.355958938598633\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.0240707397461; logcosh of 8.03890323638916\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 109.2991943359375; logcosh of 8.31516170501709\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 112.63462829589844; logcosh of 8.4439058303833\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 103.93792724609375; logcosh of 8.11541748046875\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.0005, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       109.7376  103.0241  109.2992  112.6346  103.9379 \n",
      "Score       8.356     8.0389    8.3152    8.4439    8.1154  \n",
      "====================================================================================================\n",
      "Average loss:  107.7267  +-3.6626\n",
      "Average score: 8.2539\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (nan, nan, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (116.0263, 8.5206, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6483, 8.2087, 0.01, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1832, 8.1853, 0.005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.5801, 8.2699, 0.001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.7267, 8.2539, 0.0005, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, learning_rate 0.0001, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 107.83773803710938; logcosh of 8.332240104675293\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.76911926269531; logcosh of 8.075559616088867\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.99609375; logcosh of 8.198639869689941\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.15345764160156; logcosh of 8.266581535339355\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 103.3357162475586; logcosh of 8.085138320922852\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 0.0001, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       107.8377  103.7691  104.9961  107.1535  103.3357 \n",
      "Score       8.3322    8.0756    8.1986    8.2666    8.0851  \n",
      "====================================================================================================\n",
      "Average loss:  105.4184  +-1.7944\n",
      "Average score: 8.1916\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (nan, nan, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (116.0263, 8.5206, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6483, 8.2087, 0.01, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1832, 8.1853, 0.005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.5801, 8.2699, 0.001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.7267, 8.2539, 0.0005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.4184, 8.1916, 0.0001, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, learning_rate 5e-05, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 107.31083679199219; logcosh of 8.297629356384277\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.85658264160156; logcosh of 8.107593536376953\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 105.60271453857422; logcosh of 8.208514213562012\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.57809448242188; logcosh of 8.303559303283691\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 103.36613464355469; logcosh of 8.10080337524414\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 5e-05, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       107.3108  104.8566  105.6027  108.5781  103.3661 \n",
      "Score       8.2976    8.1076    8.2085    8.3036    8.1008  \n",
      "====================================================================================================\n",
      "Average loss:  105.9429  +-1.8304\n",
      "Average score: 8.2036\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (nan, nan, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (116.0263, 8.5206, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6483, 8.2087, 0.01, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1832, 8.1853, 0.005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.5801, 8.2699, 0.001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.7267, 8.2539, 0.0005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.4184, 8.1916, 0.0001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.9429, 8.2036, 5e-05, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, learning_rate 1e-05, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 116.29220581054688; logcosh of 8.583023071289062\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 113.63667297363281; logcosh of 8.3953275680542\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 108.47217559814453; logcosh of 8.24968433380127\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 115.36315155029297; logcosh of 8.50232982635498\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 111.49397277832031; logcosh of 8.330081939697266\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 1e-05, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       116.2922  113.6367  108.4722  115.3632  111.494  \n",
      "Score       8.583     8.3953    8.2497    8.5023    8.3301  \n",
      "====================================================================================================\n",
      "Average loss:  113.0516  +-2.8137\n",
      "Average score: 8.4121\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (nan, nan, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (116.0263, 8.5206, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6483, 8.2087, 0.01, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1832, 8.1853, 0.005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.5801, 8.2699, 0.001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.7267, 8.2539, 0.0005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.4184, 8.1916, 0.0001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.9429, 8.2036, 5e-05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (113.0516, 8.4121, 1e-05, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, learning_rate 5e-06, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 121.15042114257812; logcosh of 8.709833145141602\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 118.74028015136719; logcosh of 8.51618766784668\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 114.51736450195312; logcosh of 8.389981269836426\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 121.6849594116211; logcosh of 8.69114875793457\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 120.32166290283203; logcosh of 8.571712493896484\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 5e-06, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       121.1504  118.7403  114.5174  121.685   120.3217 \n",
      "Score       8.7098    8.5162     8.39     8.6911    8.5717  \n",
      "====================================================================================================\n",
      "Average loss:  119.2829  +-2.5823\n",
      "Average score: 8.5758\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (nan, nan, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (116.0263, 8.5206, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6483, 8.2087, 0.01, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1832, 8.1853, 0.005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.5801, 8.2699, 0.001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.7267, 8.2539, 0.0005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.4184, 8.1916, 0.0001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.9429, 8.2036, 5e-05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (113.0516, 8.4121, 1e-05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (119.2829, 8.5758, 5e-06, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, learning_rate 1e-06, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 381.9247131347656; logcosh of 16.006858825683594\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 393.83740234375; logcosh of 16.41590118408203\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 399.14605712890625; logcosh of 16.54375648498535\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in fold 4: loss of 402.6661376953125; logcosh of 16.575836181640625\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 400.27850341796875; logcosh of 16.622310638427734\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 1e-06, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       381.9247  393.8374  399.1461  402.6661  400.2785 \n",
      "Score      16.0069   16.4159   16.5438   16.5758   16.6223  \n",
      "====================================================================================================\n",
      "Average loss:  395.5706  +-7.4096\n",
      "Average score: 16.4329\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (nan, nan, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (116.0263, 8.5206, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6483, 8.2087, 0.01, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1832, 8.1853, 0.005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.5801, 8.2699, 0.001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.7267, 8.2539, 0.0005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.4184, 8.1916, 0.0001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.9429, 8.2036, 5e-05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (113.0516, 8.4121, 1e-05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (119.2829, 8.5758, 5e-06, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (395.5706, 16.4329, 1e-06, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, learning_rate 5e-07, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 391.4836120605469; logcosh of 16.272083282470703\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 408.47259521484375; logcosh of 16.82304573059082\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 419.9880676269531; logcosh of 17.121219635009766\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 409.8128662109375; logcosh of 16.77859878540039\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 419.3702697753906; logcosh of 17.150535583496094\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 5e-07, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       391.4836  408.4726  419.9881  409.8129  419.3703 \n",
      "Score      16.2721    16.823   17.1212   16.7786   17.1505  \n",
      "====================================================================================================\n",
      "Average loss:  409.8255  +-10.3212\n",
      "Average score: 16.8291\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (nan, nan, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (116.0263, 8.5206, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6483, 8.2087, 0.01, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1832, 8.1853, 0.005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.5801, 8.2699, 0.001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.7267, 8.2539, 0.0005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.4184, 8.1916, 0.0001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.9429, 8.2036, 5e-05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (113.0516, 8.4121, 1e-05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (119.2829, 8.5758, 5e-06, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (395.5706, 16.4329, 1e-06, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (409.8255, 16.8291, 5e-07, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, learning_rate 1e-07, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 415.8422546386719; logcosh of 16.973115921020508\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 414.25543212890625; logcosh of 16.99170684814453\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 430.9714660644531; logcosh of 17.42275047302246\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 445.5419921875; logcosh of 17.761131286621094\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 434.7525634765625; logcosh of 17.574485778808594\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with learning_rate 1e-07, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       415.8423  414.2554  430.9715  445.542   434.7526 \n",
      "Score      16.9731   16.9917   17.4228   17.7611   17.5745  \n",
      "====================================================================================================\n",
      "Average loss:  428.2727  +-11.8195\n",
      "Average score: 17.3446\n",
      "====================================================================================================\n",
      "metrics = [(nan, nan, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (139.6462, 9.1646, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0724, 8.2371, 0.01, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3366, 8.2279, 0.005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8924, 8.236, 0.001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7496, 8.2256, 0.0005, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.6932, 8.2522, 0.0001, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (109.1992, 8.3001, 5e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (167.0827, 9.9377, 1e-05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (242.7408, 12.0693, 5e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (404.7957, 16.6835, 1e-06, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (417.6997, 17.0424, 5e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (425.082, 17.2497, 1e-07, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (nan, nan, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (nan, nan, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (116.0263, 8.5206, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6483, 8.2087, 0.01, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1832, 8.1853, 0.005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.5801, 8.2699, 0.001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (107.7267, 8.2539, 0.0005, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.4184, 8.1916, 0.0001, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.9429, 8.2036, 5e-05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (113.0516, 8.4121, 1e-05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (119.2829, 8.5758, 5e-06, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (395.5706, 16.4329, 1e-06, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (409.8255, 16.8291, 5e-07, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (428.2727, 17.3446, 1e-07, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "cv_engines = [ tscv, kf ]\n",
    "lr_list = [ 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001, 0.000005, 0.000001, 0.0000005, 0.0000001 ]\n",
    "for cv_engine in cv_engines:\n",
    "    for lr_value in lr_list:\n",
    "        \n",
    "        ts_flag = 'TimeSeriesSplit' in cv_engine.__str__()\n",
    "        if ts_flag:\n",
    "            loss, std, score = run_cv( X, y, cv_engine, ts_flag, learning_rate=lr_value)\n",
    "        else:\n",
    "            loss, std, score = run_cv( X_sh, y_sh, cv_engine, ts_flag, learning_rate=lr_value)\n",
    "                        \n",
    "        metrics.append(( loss, score, lr_value, cv_engine.__str__() ))\n",
    "        print('metrics =', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for best dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv( X_, y_, cv_folds, ts_flag=False, dropout=0.15, batch_size=32, epochs=6 ):\n",
    "        \n",
    "    print( f'Stacked_BiLSTM, dropout2 {dropout}, cv method {cv_folds.__str__()}' )\n",
    "    print( f'                batch_size {batch_size}, num epochs {epochs}')\n",
    "    verbose = 0\n",
    "    score_per_fold, loss_per_fold = [], []\n",
    "\n",
    "    fold_no = 1\n",
    "    for train_idx, test_idx in cv_folds.split( X_ ):\n",
    "\n",
    "        # Define and compile model\n",
    "        model = stacked_BiLSTM( n_steps, n_features, dropout2=dropout )\n",
    "\n",
    "        print('\\n', '='*100, '\\n', sep='')\n",
    "        print('Training in fold {} ...'.format( fold_no ))\n",
    "\n",
    "        # Fit data to model\n",
    "        if ts_flag:\n",
    "            history = model.fit( X_[train_idx], y_[train_idx],\n",
    "                                 batch_size=batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 shuffle=False,\n",
    "                                 verbose=verbose )\n",
    "        else:\n",
    "            history = model.fit( X_[train_idx], y_[train_idx],\n",
    "                                 batch_size=batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 shuffle=True,\n",
    "                                 verbose=verbose )\n",
    "\n",
    "        # Generate metrics\n",
    "        scores = model.evaluate( X_[test_idx], y_[test_idx], verbose=verbose )\n",
    "        print(f'Score in fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}')\n",
    "        score_per_fold.append( scores[1] )\n",
    "        loss_per_fold.append(  scores[0] )\n",
    "\n",
    "        # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "        \n",
    "    # Average scores\n",
    "    average_loss  = round( np.mean(loss_per_fold), 4 )\n",
    "    average_std   = round( np.std(loss_per_fold), 4 )\n",
    "    average_score = round( np.mean(score_per_fold), 4)\n",
    "    print( '\\n', '='*100, sep='' )\n",
    "    print( f'Average metrics for the run with dropout2 {dropout}, cv method {cv_folds.__str__()}, batch_size {batch_size} and number of epochs {epochs}')\n",
    "    print('Per fold:')\n",
    "    print( '{:>10}{:^10}{:^10}{:^10}{:^10}{:^10}'.format('', 1, 2, 3, 4, 5) )\n",
    "    print( '{:<10}{:^10}{:^10}{:^10}{:^10}{:^10}'.format( 'Loss',  *[ round(i, 4) for i in loss_per_fold  ] ) )\n",
    "    print( '{:<10}{:^10}{:^10}{:^10}{:^10}{:^10}'.format( 'Score', *[ round(i, 4) for i in score_per_fold ] ) )\n",
    "    print( '='*100 )\n",
    "    print(f'Average loss:  {average_loss}  +-{average_std}')\n",
    "    print(f'Average score: {average_score}')\n",
    "    print( '='*100 )\n",
    "    \n",
    "    return average_loss, average_std, average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked_BiLSTM, dropout2 0, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 106.55168914794922; logcosh of 8.280599594116211\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 102.69500732421875; logcosh of 8.040163040161133\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.0307846069336; logcosh of 8.16988754272461\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.66056060791016; logcosh of 8.276382446289062\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 101.78812408447266; logcosh of 8.043107032775879\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       106.5517  102.695   104.0308  107.6606  101.7881 \n",
      "Score       8.2806    8.0402    8.1699    8.2764    8.0431  \n",
      "====================================================================================================\n",
      "Average loss:  104.5452  +-2.237\n",
      "Average score: 8.162\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.05, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 107.41625213623047; logcosh of 8.295905113220215\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.9312973022461; logcosh of 8.091875076293945\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.07907104492188; logcosh of 8.138469696044922\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 105.99533081054688; logcosh of 8.24113655090332\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 102.86318969726562; logcosh of 8.086609840393066\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.05, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       107.4163  104.9313  103.0791  105.9953  102.8632 \n",
      "Score       8.2959    8.0919    8.1385    8.2411    8.0866  \n",
      "====================================================================================================\n",
      "Average loss:  104.857  +-1.7313\n",
      "Average score: 8.1708\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.1, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 105.27951049804688; logcosh of 8.226329803466797\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 109.26471710205078; logcosh of 8.2850923538208\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.40058135986328; logcosh of 8.148321151733398\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.27474212646484; logcosh of 8.29899787902832\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 101.404541015625; logcosh of 8.051443099975586\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.1, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       105.2795  109.2647  103.4006  108.2747  101.4045 \n",
      "Score       8.2263    8.2851    8.1483    8.299     8.0514  \n",
      "====================================================================================================\n",
      "Average loss:  105.5248  +-2.9359\n",
      "Average score: 8.202\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.15, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 109.052490234375; logcosh of 8.343561172485352\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.54903411865234; logcosh of 8.089566230773926\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 105.55532836914062; logcosh of 8.213540077209473\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.21978759765625; logcosh of 8.316155433654785\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 106.6507568359375; logcosh of 8.19538688659668\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.15, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       109.0525  103.549   105.5553  108.2198  106.6508 \n",
      "Score       8.3436    8.0896    8.2135    8.3162    8.1954  \n",
      "====================================================================================================\n",
      "Average loss:  106.6055  +-1.9514\n",
      "Average score: 8.2316\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.2, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 112.94358825683594; logcosh of 8.469673156738281\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.94447326660156; logcosh of 8.10914134979248\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.78614807128906; logcosh of 8.196285247802734\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.52212524414062; logcosh of 8.246725082397461\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.6825180053711; logcosh of 8.157731056213379\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.2, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       112.9436  104.9445  104.7861  106.5221  105.6825 \n",
      "Score       8.4697    8.1091    8.1963    8.2467    8.1577  \n",
      "====================================================================================================\n",
      "Average loss:  106.9758  +-3.0468\n",
      "Average score: 8.2359\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.25, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 105.92447662353516; logcosh of 8.266746520996094\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.41413879394531; logcosh of 8.088902473449707\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.73373413085938; logcosh of 8.193825721740723\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.60639190673828; logcosh of 8.289948463439941\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 103.46598815917969; logcosh of 8.103109359741211\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.25, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       105.9245  103.4141  104.7337  107.6064  103.466  \n",
      "Score       8.2667    8.0889    8.1938    8.2899    8.1031  \n",
      "====================================================================================================\n",
      "Average loss:  105.0289  +-1.5864\n",
      "Average score: 8.1885\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.3, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 106.13871002197266; logcosh of 8.27210807800293\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 102.9019775390625; logcosh of 8.047661781311035\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.42090606689453; logcosh of 8.178529739379883\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 105.74178314208984; logcosh of 8.232510566711426\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 102.30564880371094; logcosh of 8.08325481414795\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.3, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       106.1387  102.902   104.4209  105.7418  102.3056 \n",
      "Score       8.2721    8.0477    8.1785    8.2325    8.0833  \n",
      "====================================================================================================\n",
      "Average loss:  104.3018  +-1.5104\n",
      "Average score: 8.1628\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.35, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 107.37152862548828; logcosh of 8.306023597717285\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 102.71533203125; logcosh of 8.037671089172363\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.72932434082031; logcosh of 8.190074920654297\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 109.90205383300781; logcosh of 8.35326862335205\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 102.19038391113281; logcosh of 8.083539009094238\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.35, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       107.3715  102.7153  104.7293  109.9021  102.1904 \n",
      "Score       8.306     8.0377    8.1901    8.3533    8.0835  \n",
      "====================================================================================================\n",
      "Average loss:  105.3817  +-2.9022\n",
      "Average score: 8.1941\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.4, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 121.13182830810547; logcosh of 8.698214530944824\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.8266372680664; logcosh of 8.137709617614746\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 105.01180267333984; logcosh of 8.20745849609375\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.20008087158203; logcosh of 8.295973777770996\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 116.3699951171875; logcosh of 8.527131080627441\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.4, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       121.1318  104.8266  105.0118  107.2001   116.37  \n",
      "Score       8.6982    8.1377    8.2075    8.296     8.5271  \n",
      "====================================================================================================\n",
      "Average loss:  110.9081  +-6.6311\n",
      "Average score: 8.3733\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.45, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 107.69107818603516; logcosh of 8.307554244995117\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 102.92921447753906; logcosh of 8.021905899047852\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 110.75102233886719; logcosh of 8.368446350097656\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.21884155273438; logcosh of 8.248714447021484\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 103.50056457519531; logcosh of 8.108906745910645\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.45, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       107.6911  102.9292  110.751   106.2188  103.5006 \n",
      "Score       8.3076    8.0219    8.3684    8.2487    8.1089  \n",
      "====================================================================================================\n",
      "Average loss:  106.2181  +-2.8607\n",
      "Average score: 8.2111\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.5, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 105.4117431640625; logcosh of 8.238273620605469\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.3577880859375; logcosh of 8.070332527160645\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 105.92115783691406; logcosh of 8.21831226348877\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.10397338867188; logcosh of 8.280915260314941\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 102.03193664550781; logcosh of 8.071986198425293\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.5, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       105.4117  103.3578  105.9212  107.104   102.0319 \n",
      "Score       8.2383    8.0703    8.2183    8.2809    8.072   \n",
      "====================================================================================================\n",
      "Average loss:  104.7653  +-1.8262\n",
      "Average score: 8.176\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.55, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 107.23968505859375; logcosh of 8.292806625366211\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.77183532714844; logcosh of 8.088821411132812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.77482604980469; logcosh of 8.1881685256958\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 105.93824768066406; logcosh of 8.247111320495605\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 103.96855163574219; logcosh of 8.111684799194336\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.55, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       107.2397  103.7718  104.7748  105.9382  103.9686 \n",
      "Score       8.2928    8.0888    8.1882    8.2471    8.1117  \n",
      "====================================================================================================\n",
      "Average loss:  105.1386  +-1.298\n",
      "Average score: 8.1857\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.6, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 106.0503158569336; logcosh of 8.26807689666748\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.8656005859375; logcosh of 8.102519989013672\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.32992553710938; logcosh of 8.171338081359863\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.08484649658203; logcosh of 8.254006385803223\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 102.20542907714844; logcosh of 8.06847095489502\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.6, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       106.0503  103.8656  104.3299  106.0848  102.2054 \n",
      "Score       8.2681    8.1025    8.1713    8.254     8.0685  \n",
      "====================================================================================================\n",
      "Average loss:  104.5072  +-1.4568\n",
      "Average score: 8.1729\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.65, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 106.52276611328125; logcosh of 8.286247253417969\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.23664855957031; logcosh of 8.098774909973145\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.28181457519531; logcosh of 8.141178131103516\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.50399017333984; logcosh of 8.240032196044922\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 103.26949310302734; logcosh of 8.094219207763672\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.65, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       106.5228  104.2366  103.2818  106.504   103.2695 \n",
      "Score       8.2862    8.0988    8.1412     8.24     8.0942  \n",
      "====================================================================================================\n",
      "Average loss:  104.7629  +-1.4717\n",
      "Average score: 8.1721\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0.7, cv method KFold(n_splits=5, random_state=34, shuffle=True)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in fold 1: loss of 105.27674102783203; logcosh of 8.243785858154297\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.1755142211914; logcosh of 8.121256828308105\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.87623596191406; logcosh of 8.137253761291504\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.15128326416016; logcosh of 8.323395729064941\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 107.95166015625; logcosh of 8.264225959777832\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.7, cv method KFold(n_splits=5, random_state=34, shuffle=True), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       105.2767  104.1755  102.8762  108.1513  107.9517 \n",
      "Score       8.2438    8.1213    8.1373    8.3234    8.2642  \n",
      "====================================================================================================\n",
      "Average loss:  105.6863  +-2.0763\n",
      "Average score: 8.218\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)')]\n",
      "Stacked_BiLSTM, dropout2 0, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 113.0169677734375; logcosh of 8.453984260559082\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.9448013305664; logcosh of 8.16513442993164\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.87586212158203; logcosh of 8.097935676574707\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.91976165771484; logcosh of 8.29083251953125\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.87443542480469; logcosh of 8.170031547546387\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       113.017   104.9448  102.8759  106.9198  104.8744 \n",
      "Score       8.454     8.1651    8.0979    8.2908     8.17   \n",
      "====================================================================================================\n",
      "Average loss:  106.5264  +-3.4882\n",
      "Average score: 8.2356\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.05, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 113.6473388671875; logcosh of 8.436206817626953\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.67273712158203; logcosh of 8.160717964172363\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.8589859008789; logcosh of 8.155521392822266\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.75162506103516; logcosh of 8.276681900024414\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.4687271118164; logcosh of 8.192679405212402\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.05, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       113.6473  104.6727  104.859   106.7516  105.4687 \n",
      "Score       8.4362    8.1607    8.1555    8.2767    8.1927  \n",
      "====================================================================================================\n",
      "Average loss:  107.0799  +-3.3634\n",
      "Average score: 8.2444\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.1, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 111.33051300048828; logcosh of 8.41871452331543\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.37269592285156; logcosh of 8.149977684020996\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.79759216308594; logcosh of 8.127901077270508\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.43561553955078; logcosh of 8.339849472045898\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.15776824951172; logcosh of 8.183481216430664\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.1, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       111.3305  104.3727  103.7976  108.4356  105.1578 \n",
      "Score       8.4187     8.15     8.1279    8.3398    8.1835  \n",
      "====================================================================================================\n",
      "Average loss:  106.6188  +-2.851\n",
      "Average score: 8.244\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.15, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 110.97775268554688; logcosh of 8.414137840270996\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.98526000976562; logcosh of 8.174481391906738\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 104.61593627929688; logcosh of 8.15555191040039\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.89330291748047; logcosh of 8.282691955566406\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.24044799804688; logcosh of 8.169060707092285\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.15, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       110.9778  104.9853  104.6159  106.8933  105.2404 \n",
      "Score       8.4141    8.1745    8.1556    8.2827    8.1691  \n",
      "====================================================================================================\n",
      "Average loss:  106.5425  +-2.3506\n",
      "Average score: 8.2392\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.2, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 110.11957550048828; logcosh of 8.379663467407227\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 107.2402114868164; logcosh of 8.252398490905762\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.0652847290039; logcosh of 8.048307418823242\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.42805480957031; logcosh of 8.304150581359863\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.42550659179688; logcosh of 8.194835662841797\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.2, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       110.1196  107.2402  102.0653  107.4281  105.4255 \n",
      "Score       8.3797    8.2524    8.0483    8.3042    8.1948  \n",
      "====================================================================================================\n",
      "Average loss:  106.4557  +-2.6579\n",
      "Average score: 8.2359\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.25, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 111.46656036376953; logcosh of 8.370567321777344\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.68963623046875; logcosh of 8.217764854431152\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.3837890625; logcosh of 8.074373245239258\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.65922546386719; logcosh of 8.34700870513916\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.73695373535156; logcosh of 8.160039901733398\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.25, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       111.4666  106.6896  102.3838  108.6592  104.737  \n",
      "Score       8.3706    8.2178    8.0744    8.347      8.16   \n",
      "====================================================================================================\n",
      "Average loss:  106.7872  +-3.1306\n",
      "Average score: 8.234\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.3, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 109.4130630493164; logcosh of 8.36609935760498\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.19084930419922; logcosh of 8.204859733581543\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.84717559814453; logcosh of 8.124516487121582\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.3789291381836; logcosh of 8.26429271697998\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.08447265625; logcosh of 8.171355247497559\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.3, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       109.4131  106.1908  103.8472  106.3789  105.0845 \n",
      "Score       8.3661    8.2049    8.1245    8.2643    8.1714  \n",
      "====================================================================================================\n",
      "Average loss:  106.1829  +-1.8512\n",
      "Average score: 8.2262\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.35, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 110.37702941894531; logcosh of 8.404903411865234\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.28385162353516; logcosh of 8.211379051208496\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.11164855957031; logcosh of 8.10085391998291\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.96817016601562; logcosh of 8.288213729858398\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.85133361816406; logcosh of 8.165138244628906\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.35, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       110.377   106.2839  103.1116  106.9682  104.8513 \n",
      "Score       8.4049    8.2114    8.1009    8.2882    8.1651  \n",
      "====================================================================================================\n",
      "Average loss:  106.3184  +-2.422\n",
      "Average score: 8.2341\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.4, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 111.61451721191406; logcosh of 8.427902221679688\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.03932189941406; logcosh of 8.212669372558594\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 103.44519805908203; logcosh of 8.118642807006836\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.6817398071289; logcosh of 8.278470039367676\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.50023651123047; logcosh of 8.1581392288208\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.4, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       111.6145  106.0393  103.4452  106.6817  104.5002 \n",
      "Score       8.4279    8.2127    8.1186    8.2785    8.1581  \n",
      "====================================================================================================\n",
      "Average loss:  106.4562  +-2.8187\n",
      "Average score: 8.2392\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.45, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 108.4706039428711; logcosh of 8.341291427612305\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.08773040771484; logcosh of 8.218657493591309\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 101.99217987060547; logcosh of 8.057024955749512\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.47303009033203; logcosh of 8.272245407104492\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.14564514160156; logcosh of 8.183266639709473\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.45, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       108.4706  106.0877  101.9922  106.473   105.1456 \n",
      "Score       8.3413    8.2187    8.057     8.2722    8.1833  \n",
      "====================================================================================================\n",
      "Average loss:  105.6338  +-2.1193\n",
      "Average score: 8.2145\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.6338, 8.2145, 0.45, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.5, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 109.23116302490234; logcosh of 8.33707046508789\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 108.46996307373047; logcosh of 8.268815994262695\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 101.69061279296875; logcosh of 8.037236213684082\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 106.73020935058594; logcosh of 8.279877662658691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 105.2088623046875; logcosh of 8.186064720153809\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.5, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       109.2312   108.47   101.6906  106.7302  105.2089 \n",
      "Score       8.3371    8.2688    8.0372    8.2799    8.1861  \n",
      "====================================================================================================\n",
      "Average loss:  106.2662  +-2.6802\n",
      "Average score: 8.2218\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.6338, 8.2145, 0.45, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.2662, 8.2218, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.55, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 111.37348937988281; logcosh of 8.411995887756348\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.56427001953125; logcosh of 8.221837043762207\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.23047637939453; logcosh of 8.046435356140137\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 109.32637786865234; logcosh of 8.367033004760742\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.86146545410156; logcosh of 8.174488067626953\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.55, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       111.3735  106.5643  102.2305  109.3264  104.8615 \n",
      "Score       8.412     8.2218    8.0464    8.367     8.1745  \n",
      "====================================================================================================\n",
      "Average loss:  106.8712  +-3.2239\n",
      "Average score: 8.2444\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.6338, 8.2145, 0.45, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.2662, 8.2218, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8712, 8.2444, 0.55, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.6, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 111.05003356933594; logcosh of 8.428709983825684\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 103.71045684814453; logcosh of 8.109298706054688\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.00338745117188; logcosh of 8.031842231750488\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 108.44770050048828; logcosh of 8.333754539489746\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.83224487304688; logcosh of 8.176797866821289\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.6, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss        111.05   103.7105  102.0034  108.4477  104.8322 \n",
      "Score       8.4287    8.1093    8.0318    8.3338    8.1768  \n",
      "====================================================================================================\n",
      "Average loss:  106.0088  +-3.2885\n",
      "Average score: 8.2161\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.6338, 8.2145, 0.45, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.2662, 8.2218, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8712, 8.2444, 0.55, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0088, 8.2161, 0.6, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.65, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 110.04083251953125; logcosh of 8.401792526245117\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 104.72976684570312; logcosh of 8.158445358276367\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 102.07359313964844; logcosh of 8.056126594543457\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.82266235351562; logcosh of 8.308663368225098\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.72434997558594; logcosh of 8.17288875579834\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.65, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       110.0408  104.7298  102.0736  107.8227  104.7243 \n",
      "Score       8.4018    8.1584    8.0561    8.3087    8.1729  \n",
      "====================================================================================================\n",
      "Average loss:  105.8782  +-2.7653\n",
      "Average score: 8.2196\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.6338, 8.2145, 0.45, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.2662, 8.2218, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8712, 8.2444, 0.55, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0088, 8.2161, 0.6, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.8782, 8.2196, 0.65, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n",
      "Stacked_BiLSTM, dropout2 0.7, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5)\n",
      "                batch_size 32, num epochs 6\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 1 ...\n",
      "Score in fold 1: loss of 109.30441284179688; logcosh of 8.376189231872559\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 2 ...\n",
      "Score in fold 2: loss of 106.48367309570312; logcosh of 8.219056129455566\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 3 ...\n",
      "Score in fold 3: loss of 101.8427505493164; logcosh of 8.02209186553955\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 4 ...\n",
      "Score in fold 4: loss of 107.44043731689453; logcosh of 8.304012298583984\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Training in fold 5 ...\n",
      "Score in fold 5: loss of 104.41191864013672; logcosh of 8.15402603149414\n",
      "\n",
      "====================================================================================================\n",
      "Average metrics for the run with dropout2 0.7, cv method TimeSeriesSplit(max_train_size=1654, n_splits=5), batch_size 32 and number of epochs 6\n",
      "Per fold:\n",
      "              1         2         3         4         5     \n",
      "Loss       109.3044  106.4837  101.8428  107.4404  104.4119 \n",
      "Score       8.3762    8.2191    8.0221    8.304     8.154   \n",
      "====================================================================================================\n",
      "Average loss:  105.8966  +-2.5682\n",
      "Average score: 8.2151\n",
      "====================================================================================================\n",
      "metrics = [(104.5452, 8.162, 0, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.857, 8.1708, 0.05, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.5248, 8.202, 0.1, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.6055, 8.2316, 0.15, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.9758, 8.2359, 0.2, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.0289, 8.1885, 0.25, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.3018, 8.1628, 0.3, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.3817, 8.1941, 0.35, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (110.9081, 8.3733, 0.4, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.2181, 8.2111, 0.45, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7653, 8.176, 0.5, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.1386, 8.1857, 0.55, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.5072, 8.1729, 0.6, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (104.7629, 8.1721, 0.65, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (105.6863, 8.218, 0.7, 'KFold(n_splits=5, random_state=34, shuffle=True)'), (106.5264, 8.2356, 0, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (107.0799, 8.2444, 0.05, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.6188, 8.244, 0.1, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.5425, 8.2392, 0.15, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4557, 8.2359, 0.2, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.7872, 8.234, 0.25, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.1829, 8.2262, 0.3, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.3184, 8.2341, 0.35, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.4562, 8.2392, 0.4, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.6338, 8.2145, 0.45, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.2662, 8.2218, 0.5, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.8712, 8.2444, 0.55, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (106.0088, 8.2161, 0.6, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.8782, 8.2196, 0.65, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)'), (105.8966, 8.2151, 0.7, 'TimeSeriesSplit(max_train_size=1654, n_splits=5)')]\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "cv_engines = [ kf, tscv ]\n",
    "drpt_list = [ 0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7 ]\n",
    "for cv_engine in cv_engines:\n",
    "    for dropout in drpt_list:\n",
    "        \n",
    "        ts_flag = 'TimeSeriesSplit' in cv_engine.__str__()\n",
    "        if ts_flag:\n",
    "            loss, std, score = run_cv( X, y, cv_engine, ts_flag, dropout=dropout)\n",
    "        else:\n",
    "            loss, std, score = run_cv( X_sh, y_sh, cv_engine, ts_flag, dropout=dropout)\n",
    "                        \n",
    "        metrics.append(( loss, score, dropout, cv_engine.__str__() ))\n",
    "        print('metrics =', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
